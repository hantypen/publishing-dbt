[0m01:56:37.849118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107293f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10677a810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fa6c10>]}


============================== 01:56:37.851870 | 04d9de44-51da-4e03-ba4c-27cad9a61083 ==============================
[0m01:56:37.851870 [info ] [MainThread]: Running with dbt=1.6.0
[0m01:56:37.852202 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt source freshness', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m01:56:37.948942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '04d9de44-51da-4e03-ba4c-27cad9a61083', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107293d50>]}
[0m01:56:37.953104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '04d9de44-51da-4e03-ba4c-27cad9a61083', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10753bf10>]}
[0m01:56:37.953584 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m01:56:37.960469 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m01:56:37.980996 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:56:37.981209 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:56:37.981471 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m01:56:37.985315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '04d9de44-51da-4e03-ba4c-27cad9a61083', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fa5bd0>]}
[0m01:56:37.991484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '04d9de44-51da-4e03-ba4c-27cad9a61083', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10756bb50>]}
[0m01:56:37.991753 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m01:56:37.991921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04d9de44-51da-4e03-ba4c-27cad9a61083', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d91b50>]}
[0m01:56:37.992859 [info ] [MainThread]: 
[0m01:56:37.993341 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:56:37.993906 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m01:56:38.002706 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m01:56:38.002950 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m01:56:38.003096 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:56:38.003616 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:56:38.003765 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:56:38.453921 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:56:38.455294 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m01:56:38.456368 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m01:56:38.552008 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:56:38.556873 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m01:56:38.641103 [debug] [ThreadPool]: On list_dev_public: Close
[0m01:56:38.656629 [debug] [MainThread]: Using redshift connection "master"
[0m01:56:38.657211 [debug] [MainThread]: On master: BEGIN
[0m01:56:38.657619 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:56:38.658258 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:56:38.658674 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:56:39.042402 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:56:39.043593 [debug] [MainThread]: Using redshift connection "master"
[0m01:56:39.044694 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m01:56:39.173403 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:56:39.177268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04d9de44-51da-4e03-ba4c-27cad9a61083', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10677ab50>]}
[0m01:56:39.178662 [debug] [MainThread]: On master: ROLLBACK
[0m01:56:39.275754 [debug] [MainThread]: On master: Close
[0m01:56:39.279098 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:56:39.280412 [info ] [MainThread]: 
[0m01:56:39.285972 [debug] [Thread-1 (]: Began running node source.dbt_remote.starlink.starlink_satellites
[0m01:56:39.286676 [info ] [Thread-1 (]: 1 of 1 START freshness of starlink.starlink_satellites ......................... [RUN]
[0m01:56:39.287740 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now source.dbt_remote.starlink.starlink_satellites)
[0m01:56:39.288274 [debug] [Thread-1 (]: Began compiling node source.dbt_remote.starlink.starlink_satellites
[0m01:56:39.288875 [debug] [Thread-1 (]: Timing info for source.dbt_remote.starlink.starlink_satellites (compile): 01:56:39.288608 => 01:56:39.288620
[0m01:56:39.289337 [debug] [Thread-1 (]: Began executing node source.dbt_remote.starlink.starlink_satellites
[0m01:56:39.290274 [debug] [Thread-1 (]: Using redshift connection "source.dbt_remote.starlink.starlink_satellites"
[0m01:56:39.290515 [debug] [Thread-1 (]: On source.dbt_remote.starlink.starlink_satellites: BEGIN
[0m01:56:39.290716 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:56:39.291398 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:56:39.291647 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:56:39.671997 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:56:39.673247 [debug] [Thread-1 (]: On source.dbt_remote.starlink.starlink_satellites: COMMIT
[0m01:56:39.674167 [debug] [Thread-1 (]: Using redshift connection "source.dbt_remote.starlink.starlink_satellites"
[0m01:56:39.674626 [debug] [Thread-1 (]: On source.dbt_remote.starlink.starlink_satellites: COMMIT
[0m01:56:39.752689 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:56:39.768577 [debug] [Thread-1 (]: Using redshift connection "source.dbt_remote.starlink.starlink_satellites"
[0m01:56:39.769330 [debug] [Thread-1 (]: On source.dbt_remote.starlink.starlink_satellites: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "source.dbt_remote.starlink.starlink_satellites"} */
select
      max(spacetrack.launch_date::timestamp) as max_loaded_at,
      getdate() as snapshotted_at
    from "dev"."raw"."starlink_satellites"
[0m01:56:40.983050 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:56:40.987465 [debug] [Thread-1 (]: On source.dbt_remote.starlink.starlink_satellites: Close
[0m01:56:40.990209 [debug] [Thread-1 (]: Timing info for source.dbt_remote.starlink.starlink_satellites (execute): 01:56:39.289694 => 01:56:40.989667
[0m01:56:40.991815 [error] [Thread-1 (]: 1 of 1 ERROR STALE freshness of starlink.starlink_satellites ................... [[31mERROR STALE[0m in 1.70s]
[0m01:56:40.993254 [debug] [Thread-1 (]: Finished running node source.dbt_remote.starlink.starlink_satellites
[0m01:56:40.995655 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:56:40.996117 [debug] [MainThread]: Connection 'source.dbt_remote.starlink.starlink_satellites' was properly closed.
[0m01:56:41.011891 [info ] [MainThread]: 
[0m01:56:41.012344 [info ] [MainThread]: Done.
[0m01:56:41.013123 [debug] [MainThread]: Command `dbt source freshness` failed at 01:56:41.012991 after 3.17 seconds
[0m01:56:41.013578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072c0310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c19010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072935d0>]}
[0m01:56:41.014049 [debug] [MainThread]: Flushing usage events
[0m02:01:17.962181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11abddc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119ff3910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11abeb650>]}


============================== 02:01:17.965288 | 0df35285-0574-4405-a66c-68a7ad4f1eb2 ==============================
[0m02:01:17.965288 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:01:17.965652 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'debug': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt source freshness', 'send_anonymous_usage_stats': 'True'}
[0m02:01:18.065575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0df35285-0574-4405-a66c-68a7ad4f1eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119d24490>]}
[0m02:01:18.069810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0df35285-0574-4405-a66c-68a7ad4f1eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11afa4250>]}
[0m02:01:18.070281 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:01:18.077116 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:01:18.097843 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:01:18.098229 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:01:18.128221 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:01:18.130899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0df35285-0574-4405-a66c-68a7ad4f1eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11abf3d10>]}
[0m02:01:18.137029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0df35285-0574-4405-a66c-68a7ad4f1eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b223bd0>]}
[0m02:01:18.137391 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:01:18.137584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0df35285-0574-4405-a66c-68a7ad4f1eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106af5ad0>]}
[0m02:01:18.138714 [info ] [MainThread]: 
[0m02:01:18.139266 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:01:18.139856 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m02:01:18.147875 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:01:18.148057 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:01:18.148191 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:01:18.148682 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:01:18.148826 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:01:18.689727 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:01:18.691114 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:01:18.692168 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:01:18.787661 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:18.792396 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:01:18.877171 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:01:18.893766 [debug] [MainThread]: Using redshift connection "master"
[0m02:01:18.894328 [debug] [MainThread]: On master: BEGIN
[0m02:01:18.894719 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:01:18.895363 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:01:18.895788 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:01:19.280421 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:19.281780 [debug] [MainThread]: Using redshift connection "master"
[0m02:01:19.282810 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:01:19.416301 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:19.418989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0df35285-0574-4405-a66c-68a7ad4f1eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a891490>]}
[0m02:01:19.420259 [debug] [MainThread]: On master: ROLLBACK
[0m02:01:19.520042 [debug] [MainThread]: On master: Close
[0m02:01:19.522617 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:01:19.523582 [info ] [MainThread]: 
[0m02:01:19.528953 [debug] [Thread-1 (]: Began running node source.dbt_remote.starlink.starlink_satellites
[0m02:01:19.529781 [info ] [Thread-1 (]: 1 of 1 START freshness of starlink.starlink_satellites ......................... [RUN]
[0m02:01:19.530873 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now source.dbt_remote.starlink.starlink_satellites)
[0m02:01:19.531357 [debug] [Thread-1 (]: Began compiling node source.dbt_remote.starlink.starlink_satellites
[0m02:01:19.531927 [debug] [Thread-1 (]: Timing info for source.dbt_remote.starlink.starlink_satellites (compile): 02:01:19.531675 => 02:01:19.531684
[0m02:01:19.532372 [debug] [Thread-1 (]: Began executing node source.dbt_remote.starlink.starlink_satellites
[0m02:01:19.533622 [debug] [Thread-1 (]: Using redshift connection "source.dbt_remote.starlink.starlink_satellites"
[0m02:01:19.534042 [debug] [Thread-1 (]: On source.dbt_remote.starlink.starlink_satellites: BEGIN
[0m02:01:19.534256 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:01:19.534679 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:01:19.534914 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:01:19.905883 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:19.907166 [debug] [Thread-1 (]: On source.dbt_remote.starlink.starlink_satellites: COMMIT
[0m02:01:19.907901 [debug] [Thread-1 (]: Using redshift connection "source.dbt_remote.starlink.starlink_satellites"
[0m02:01:19.908480 [debug] [Thread-1 (]: On source.dbt_remote.starlink.starlink_satellites: COMMIT
[0m02:01:19.983000 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:19.999282 [debug] [Thread-1 (]: Using redshift connection "source.dbt_remote.starlink.starlink_satellites"
[0m02:01:19.999964 [debug] [Thread-1 (]: On source.dbt_remote.starlink.starlink_satellites: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "source.dbt_remote.starlink.starlink_satellites"} */
select
      max(spacetrack.launch_date::timestamp) as max_loaded_at,
      getdate() as snapshotted_at
    from "dev"."raw"."starlink_satellites"
[0m02:01:21.096781 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:01:21.101261 [debug] [Thread-1 (]: On source.dbt_remote.starlink.starlink_satellites: Close
[0m02:01:21.103975 [debug] [Thread-1 (]: Timing info for source.dbt_remote.starlink.starlink_satellites (execute): 02:01:19.532707 => 02:01:21.103430
[0m02:01:21.105594 [error] [Thread-1 (]: 1 of 1 ERROR STALE freshness of starlink.starlink_satellites ................... [[31mERROR STALE[0m in 1.58s]
[0m02:01:21.106673 [debug] [Thread-1 (]: Finished running node source.dbt_remote.starlink.starlink_satellites
[0m02:01:21.109778 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:01:21.110310 [debug] [MainThread]: Connection 'source.dbt_remote.starlink.starlink_satellites' was properly closed.
[0m02:01:21.122247 [info ] [MainThread]: 
[0m02:01:21.122721 [info ] [MainThread]: Done.
[0m02:01:21.123887 [debug] [MainThread]: Command `dbt source freshness` failed at 02:01:21.123730 after 3.18 seconds
[0m02:01:21.124383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a8cfcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105121090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a8910d0>]}
[0m02:01:21.124838 [debug] [MainThread]: Flushing usage events
[0m02:01:31.465559 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10962ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10936d810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10990ffd0>]}


============================== 02:01:31.468241 | 41875be9-220b-467d-a2e2-c0bfe86d8882 ==============================
[0m02:01:31.468241 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:01:31.468547 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt source freshness', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:01:31.551730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '41875be9-220b-467d-a2e2-c0bfe86d8882', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10937eed0>]}
[0m02:01:31.556046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '41875be9-220b-467d-a2e2-c0bfe86d8882', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109bb27d0>]}
[0m02:01:31.556464 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:01:31.562104 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:01:31.586177 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:01:31.586674 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:01:31.615400 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:01:31.618300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '41875be9-220b-467d-a2e2-c0bfe86d8882', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108340cd0>]}
[0m02:01:31.624158 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '41875be9-220b-467d-a2e2-c0bfe86d8882', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f55490>]}
[0m02:01:31.624455 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:01:31.624620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41875be9-220b-467d-a2e2-c0bfe86d8882', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5181d0>]}
[0m02:01:31.625457 [info ] [MainThread]: 
[0m02:01:31.625845 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:01:31.626334 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m02:01:31.634695 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:01:31.634932 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:01:31.635070 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:01:31.635635 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:01:31.635811 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:01:32.072100 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:32.073455 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:01:32.074475 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:01:32.167883 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:32.172752 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:01:32.252793 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:01:32.268597 [debug] [MainThread]: Using redshift connection "master"
[0m02:01:32.269198 [debug] [MainThread]: On master: BEGIN
[0m02:01:32.269587 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:01:32.270182 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:01:32.270625 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:01:32.650888 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:32.651399 [debug] [MainThread]: Using redshift connection "master"
[0m02:01:32.651816 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:01:32.779110 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:32.783203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41875be9-220b-467d-a2e2-c0bfe86d8882', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109be1190>]}
[0m02:01:32.784345 [debug] [MainThread]: On master: ROLLBACK
[0m02:01:32.881889 [debug] [MainThread]: On master: Close
[0m02:01:32.884681 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:01:32.886137 [info ] [MainThread]: 
[0m02:01:32.891665 [debug] [Thread-1 (]: Began running node source.dbt_remote.starlink.starlink_satellites
[0m02:01:32.892409 [info ] [Thread-1 (]: 1 of 1 START freshness of starlink.starlink_satellites ......................... [RUN]
[0m02:01:32.893519 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now source.dbt_remote.starlink.starlink_satellites)
[0m02:01:32.894048 [debug] [Thread-1 (]: Began compiling node source.dbt_remote.starlink.starlink_satellites
[0m02:01:32.894626 [debug] [Thread-1 (]: Timing info for source.dbt_remote.starlink.starlink_satellites (compile): 02:01:32.894378 => 02:01:32.894387
[0m02:01:32.895088 [debug] [Thread-1 (]: Began executing node source.dbt_remote.starlink.starlink_satellites
[0m02:01:32.896408 [debug] [Thread-1 (]: Using redshift connection "source.dbt_remote.starlink.starlink_satellites"
[0m02:01:32.896890 [debug] [Thread-1 (]: On source.dbt_remote.starlink.starlink_satellites: BEGIN
[0m02:01:32.897314 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:01:32.897980 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:01:32.898488 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:01:33.277090 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:33.278761 [debug] [Thread-1 (]: On source.dbt_remote.starlink.starlink_satellites: COMMIT
[0m02:01:33.279965 [debug] [Thread-1 (]: Using redshift connection "source.dbt_remote.starlink.starlink_satellites"
[0m02:01:33.281115 [debug] [Thread-1 (]: On source.dbt_remote.starlink.starlink_satellites: COMMIT
[0m02:01:33.358670 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:33.375989 [debug] [Thread-1 (]: Using redshift connection "source.dbt_remote.starlink.starlink_satellites"
[0m02:01:33.376637 [debug] [Thread-1 (]: On source.dbt_remote.starlink.starlink_satellites: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "source.dbt_remote.starlink.starlink_satellites"} */
select
      max(spacetrack.launch_date::timestamp) as max_loaded_at,
      getdate() as snapshotted_at
    from "dev"."raw"."starlink_satellites"
[0m02:01:34.572813 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:01:34.577177 [debug] [Thread-1 (]: On source.dbt_remote.starlink.starlink_satellites: Close
[0m02:01:34.579904 [debug] [Thread-1 (]: Timing info for source.dbt_remote.starlink.starlink_satellites (execute): 02:01:32.895402 => 02:01:34.579296
[0m02:01:34.581391 [error] [Thread-1 (]: 1 of 1 ERROR STALE freshness of starlink.starlink_satellites ................... [[31mERROR STALE[0m in 1.69s]
[0m02:01:34.582392 [debug] [Thread-1 (]: Finished running node source.dbt_remote.starlink.starlink_satellites
[0m02:01:34.585931 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:01:34.586393 [debug] [MainThread]: Connection 'source.dbt_remote.starlink.starlink_satellites' was properly closed.
[0m02:01:34.596998 [info ] [MainThread]: 
[0m02:01:34.597450 [info ] [MainThread]: Done.
[0m02:01:34.598330 [debug] [MainThread]: Command `dbt source freshness` failed at 02:01:34.598202 after 3.14 seconds
[0m02:01:34.598812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10962e610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d6b050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10518d0d0>]}
[0m02:01:34.599282 [debug] [MainThread]: Flushing usage events
[0m02:01:39.339825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052fdb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051e64d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10551a150>]}


============================== 02:01:39.342119 | 11151a65-39b4-4834-9598-648b308430d0 ==============================
[0m02:01:39.342119 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:01:39.342431 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:01:39.419289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '11151a65-39b4-4834-9598-648b308430d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10522c550>]}
[0m02:01:39.423465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '11151a65-39b4-4834-9598-648b308430d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fffa90>]}
[0m02:01:39.423780 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:01:39.430024 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:01:39.444261 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:01:39.444487 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:01:39.444759 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:01:39.447941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '11151a65-39b4-4834-9598-648b308430d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10552e110>]}
[0m02:01:39.453050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '11151a65-39b4-4834-9598-648b308430d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057fa450>]}
[0m02:01:39.453496 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:01:39.453706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '11151a65-39b4-4834-9598-648b308430d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105518950>]}
[0m02:01:39.454617 [info ] [MainThread]: 
[0m02:01:39.455126 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:01:39.455674 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:01:39.463585 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:01:39.463770 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:01:39.463915 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:01:39.464484 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:01:39.464627 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:01:39.904683 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:39.909178 [debug] [ThreadPool]: On list_dev: Close
[0m02:01:39.913103 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public)
[0m02:01:39.924661 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:01:39.925180 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:01:39.925505 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:01:39.926009 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:01:39.926356 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:01:40.301675 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:40.303094 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:01:40.304473 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:01:40.397061 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:40.401556 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:01:40.484989 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:01:40.501190 [debug] [MainThread]: Using redshift connection "master"
[0m02:01:40.501764 [debug] [MainThread]: On master: BEGIN
[0m02:01:40.502137 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:01:40.502725 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:01:40.503130 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:01:40.898954 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:40.900382 [debug] [MainThread]: Using redshift connection "master"
[0m02:01:40.901500 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:01:41.028696 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:41.032589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '11151a65-39b4-4834-9598-648b308430d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105247f50>]}
[0m02:01:41.033825 [debug] [MainThread]: On master: ROLLBACK
[0m02:01:41.131814 [debug] [MainThread]: Using redshift connection "master"
[0m02:01:41.133161 [debug] [MainThread]: On master: BEGIN
[0m02:01:41.173889 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:41.175271 [debug] [MainThread]: On master: COMMIT
[0m02:01:41.176540 [debug] [MainThread]: Using redshift connection "master"
[0m02:01:41.177689 [debug] [MainThread]: On master: COMMIT
[0m02:01:41.255695 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:41.257057 [debug] [MainThread]: On master: Close
[0m02:01:41.259362 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:01:41.260442 [info ] [MainThread]: 
[0m02:01:41.265247 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:01:41.266106 [info ] [Thread-1 (]: 1 of 1 START sql table model public.stg_starlink_sattelite ..................... [RUN]
[0m02:01:41.267230 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:01:41.267728 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:01:41.275578 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:01:41.276704 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:01:41.268060 => 02:01:41.276447
[0m02:01:41.277133 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:01:41.323635 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:01:41.326024 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:01:41.326276 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:01:41.326484 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:01:41.326833 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:01:41.327055 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:01:41.686806 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:41.688537 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:01:41.690010 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public"."stg_starlink_sattelite__dbt_tmp"
    
    
    
  as (
    

with max_ingested(
    select
        spacetrack.object_id,
        max(export_date) as last_ingested_date
    from "dev"."raw"."starlink_satellites")
select
    s.spacetrack.object_id,
    s.spacetrack.object_name,
    s.launch as launch_id,
    s.version as version_id,
    s.latitude,
    s.longitude,
    s.velocity_kms,
    s.spacetrack.center_name,
    s.spacetrack.time_system,
    s.spacetrack.launch_date,
    case when m.last_ingested_date != s.export_date the true else false end as deleted_flag,
    s.export_date,
    row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s
left join max_ingested m
on m.object_id = s.spacetrack.object_id
  );
[0m02:01:41.731857 [debug] [Thread-1 (]: Redshift adapter: Redshift error: syntax error at or near "select"
[0m02:01:41.733735 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:01:41.812433 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:01:41.277401 => 02:01:41.811605
[0m02:01:41.813902 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:01:41.825008 [debug] [Thread-1 (]: Database Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)
  syntax error at or near "select"
  compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:01:41.825956 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11151a65-39b4-4834-9598-648b308430d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10577e550>]}
[0m02:01:41.826793 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public.stg_starlink_sattelite ............ [[31mERROR[0m in 0.56s]
[0m02:01:41.827763 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:01:41.831165 [debug] [MainThread]: Using redshift connection "master"
[0m02:01:41.831760 [debug] [MainThread]: On master: BEGIN
[0m02:01:41.832122 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:01:41.832621 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:01:41.832985 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:01:42.202314 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:42.203875 [debug] [MainThread]: On master: COMMIT
[0m02:01:42.205370 [debug] [MainThread]: Using redshift connection "master"
[0m02:01:42.206180 [debug] [MainThread]: On master: COMMIT
[0m02:01:42.283264 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:01:42.284871 [debug] [MainThread]: On master: Close
[0m02:01:42.287101 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:01:42.288036 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:01:42.288544 [info ] [MainThread]: 
[0m02:01:42.289026 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 2.83 seconds (2.83s).
[0m02:01:42.290363 [debug] [MainThread]: Command end result
[0m02:01:42.305871 [info ] [MainThread]: 
[0m02:01:42.306434 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m02:01:42.306795 [info ] [MainThread]: 
[0m02:01:42.307131 [error] [MainThread]: [33mDatabase Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)[0m
[0m02:01:42.307453 [error] [MainThread]:   syntax error at or near "select"
[0m02:01:42.307763 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:01:42.308071 [info ] [MainThread]: 
[0m02:01:42.308435 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:01:42.309231 [debug] [MainThread]: Command `dbt run` failed at 02:01:42.309078 after 2.98 seconds
[0m02:01:42.309727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100cf49d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100cf4090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100cf4d10>]}
[0m02:01:42.310162 [debug] [MainThread]: Flushing usage events
[0m02:02:01.988740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108518410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108735a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087f6b90>]}


============================== 02:02:01.991245 | fa85a2fa-f304-44cd-9e04-77750b7c132e ==============================
[0m02:02:01.991245 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:02:01.991600 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:02:02.067996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fa85a2fa-f304-44cd-9e04-77750b7c132e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108518450>]}
[0m02:02:02.072123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fa85a2fa-f304-44cd-9e04-77750b7c132e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085e3450>]}
[0m02:02:02.072447 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:02:02.078312 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:02:02.092869 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:02:02.093236 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:02:02.122095 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:02:02.124884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fa85a2fa-f304-44cd-9e04-77750b7c132e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10964e810>]}
[0m02:02:02.129504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fa85a2fa-f304-44cd-9e04-77750b7c132e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090fb990>]}
[0m02:02:02.129747 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:02:02.129913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fa85a2fa-f304-44cd-9e04-77750b7c132e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096cdbd0>]}
[0m02:02:02.130651 [info ] [MainThread]: 
[0m02:02:02.131055 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:02:02.131596 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:02:02.139852 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:02:02.140109 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:02:02.140259 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:02:02.141046 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:02:02.141204 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:02:02.594537 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:02.596062 [debug] [ThreadPool]: On list_dev: Close
[0m02:02:02.597525 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public)
[0m02:02:02.603675 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:02:02.604006 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:02:02.604217 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:02:02.604559 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:02:02.604782 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:02:02.967548 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:02.968079 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:02:02.968372 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:02:03.065066 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:03.066457 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:02:03.150004 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:02:03.158832 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:03.159165 [debug] [MainThread]: On master: BEGIN
[0m02:02:03.159377 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:02:03.159706 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:02:03.159934 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:02:03.532371 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:03.532811 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:03.533092 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:02:03.662510 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:03.664259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fa85a2fa-f304-44cd-9e04-77750b7c132e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d7e3d0>]}
[0m02:02:03.664831 [debug] [MainThread]: On master: ROLLBACK
[0m02:02:03.763919 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:03.764519 [debug] [MainThread]: On master: BEGIN
[0m02:02:03.803817 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:03.804665 [debug] [MainThread]: On master: COMMIT
[0m02:02:03.805320 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:03.805824 [debug] [MainThread]: On master: COMMIT
[0m02:02:03.885607 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:03.886154 [debug] [MainThread]: On master: Close
[0m02:02:03.887238 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:02:03.887578 [info ] [MainThread]: 
[0m02:02:03.890664 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:02:03.891129 [info ] [Thread-1 (]: 1 of 1 START sql table model public.stg_starlink_sattelite ..................... [RUN]
[0m02:02:03.891803 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:02:03.892120 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:02:03.895315 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:02:03.896010 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:02:03.892315 => 02:02:03.895844
[0m02:02:03.896315 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:02:03.930467 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:02:03.932465 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:02:03.932666 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:02:03.932841 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:02:03.933153 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:02:03.933341 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:02:04.285330 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:04.285955 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:02:04.286420 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public"."stg_starlink_sattelite__dbt_tmp"
    
    
    
  as (
    

with max_ingesteda as (
    select
        spacetrack.object_id,
        max(export_date) as last_ingested_date
    from "dev"."raw"."starlink_satellites")

select
    s.spacetrack.object_id,
    s.spacetrack.object_name,
    s.launch as launch_id,
    s.version as version_id,
    s.latitude,
    s.longitude,
    s.velocity_kms,
    s.spacetrack.center_name,
    s.spacetrack.time_system,
    s.spacetrack.launch_date,
    case when m.last_ingested_date != s.export_date the true else false end as deleted_flag,
    s.export_date,
    row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s
left join max_ingested m
on m.object_id = s.spacetrack.object_id
  );
[0m02:02:04.325820 [debug] [Thread-1 (]: Redshift adapter: Redshift error: syntax error at or near "the"
[0m02:02:04.326414 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:02:04.402793 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:02:03.896506 => 02:02:04.402079
[0m02:02:04.403951 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:02:04.413691 [debug] [Thread-1 (]: Database Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)
  syntax error at or near "the"
  compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:02:04.414467 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fa85a2fa-f304-44cd-9e04-77750b7c132e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090e5790>]}
[0m02:02:04.415292 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public.stg_starlink_sattelite ............ [[31mERROR[0m in 0.52s]
[0m02:02:04.416086 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:02:04.418934 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:04.419354 [debug] [MainThread]: On master: BEGIN
[0m02:02:04.419654 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:02:04.420165 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:02:04.420535 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:02:04.783599 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:04.784216 [debug] [MainThread]: On master: COMMIT
[0m02:02:04.784734 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:04.785147 [debug] [MainThread]: On master: COMMIT
[0m02:02:04.860830 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:04.861452 [debug] [MainThread]: On master: Close
[0m02:02:04.862743 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:02:04.863177 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:02:04.863594 [info ] [MainThread]: 
[0m02:02:04.864056 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 2.73 seconds (2.73s).
[0m02:02:04.865219 [debug] [MainThread]: Command end result
[0m02:02:04.880049 [info ] [MainThread]: 
[0m02:02:04.880550 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m02:02:04.880928 [info ] [MainThread]: 
[0m02:02:04.881387 [error] [MainThread]: [33mDatabase Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)[0m
[0m02:02:04.881767 [error] [MainThread]:   syntax error at or near "the"
[0m02:02:04.882086 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:02:04.882404 [info ] [MainThread]: 
[0m02:02:04.882768 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:02:04.883389 [debug] [MainThread]: Command `dbt run` failed at 02:02:04.883290 after 2.90 seconds
[0m02:02:04.883762 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087cb050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042a4990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042a4890>]}
[0m02:02:04.884115 [debug] [MainThread]: Flushing usage events
[0m02:02:23.550895 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070eefd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e10290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b6b510>]}


============================== 02:02:23.553810 | af14dc1c-785a-4912-9204-aebf77c561e7 ==============================
[0m02:02:23.553810 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:02:23.554182 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:02:23.633367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'af14dc1c-785a-4912-9204-aebf77c561e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070f7190>]}
[0m02:02:23.637821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'af14dc1c-785a-4912-9204-aebf77c561e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107119c50>]}
[0m02:02:23.638218 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:02:23.643518 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:02:23.658227 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:02:23.658625 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:02:23.687440 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:02:23.690308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'af14dc1c-785a-4912-9204-aebf77c561e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c65750>]}
[0m02:02:23.695656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'af14dc1c-785a-4912-9204-aebf77c561e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10772d750>]}
[0m02:02:23.695943 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:02:23.696114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'af14dc1c-785a-4912-9204-aebf77c561e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107741550>]}
[0m02:02:23.696900 [info ] [MainThread]: 
[0m02:02:23.697325 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:02:23.697844 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:02:23.706430 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:02:23.706796 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:02:23.706964 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:02:23.707561 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:02:23.707707 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:02:24.132837 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:24.134606 [debug] [ThreadPool]: On list_dev: Close
[0m02:02:24.136415 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public)
[0m02:02:24.143699 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:02:24.144092 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:02:24.144328 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:02:24.144713 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:02:24.144971 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:02:24.506273 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:24.506705 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:02:24.506993 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:02:24.599327 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:24.601499 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:02:24.683529 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:02:24.702755 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:24.703318 [debug] [MainThread]: On master: BEGIN
[0m02:02:24.703708 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:02:24.704277 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:02:24.704633 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:02:25.084864 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:25.085816 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:25.086791 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:02:25.213800 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:25.218050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'af14dc1c-785a-4912-9204-aebf77c561e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107753290>]}
[0m02:02:25.219573 [debug] [MainThread]: On master: ROLLBACK
[0m02:02:25.319132 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:25.320539 [debug] [MainThread]: On master: BEGIN
[0m02:02:25.360076 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:25.361522 [debug] [MainThread]: On master: COMMIT
[0m02:02:25.362575 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:25.363095 [debug] [MainThread]: On master: COMMIT
[0m02:02:25.444426 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:25.445850 [debug] [MainThread]: On master: Close
[0m02:02:25.448596 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:02:25.449555 [info ] [MainThread]: 
[0m02:02:25.454145 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:02:25.455046 [info ] [Thread-1 (]: 1 of 1 START sql table model public.stg_starlink_sattelite ..................... [RUN]
[0m02:02:25.456219 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:02:25.456813 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:02:25.460633 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:02:25.461318 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:02:25.457181 => 02:02:25.461179
[0m02:02:25.461563 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:02:25.501634 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:02:25.504452 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:02:25.504715 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:02:25.504932 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:02:25.505279 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:02:25.505520 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:02:25.882771 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:25.883620 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:02:25.884232 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public"."stg_starlink_sattelite__dbt_tmp"
    
    
    
  as (
    

with max_ingesteda as (
    select
        spacetrack.object_id,
        max(export_date) as last_ingested_date
    from "dev"."raw"."starlink_satellites")

select
    s.spacetrack.object_id,
    s.spacetrack.object_name,
    s.launch as launch_id,
    s.version as version_id,
    s.latitude,
    s.longitude,
    s.velocity_kms,
    s.spacetrack.center_name,
    s.spacetrack.time_system,
    s.spacetrack.launch_date,
    case when m.last_ingested_date != s.export_date then true else false end as deleted_flag,
    s.export_date,
    row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s

left join max_ingested m
on m.object_id = s.spacetrack.object_id
  );
[0m02:02:26.304912 [debug] [Thread-1 (]: Redshift adapter: Redshift error: column "starlink_satellites.*" must appear in the GROUP BY clause or be used in an aggregate function
[0m02:02:26.305597 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:02:26.384050 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:02:25.461714 => 02:02:26.383458
[0m02:02:26.384945 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:02:26.392613 [debug] [Thread-1 (]: Database Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)
  column "starlink_satellites.*" must appear in the GROUP BY clause or be used in an aggregate function
  compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:02:26.393379 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af14dc1c-785a-4912-9204-aebf77c561e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077ad010>]}
[0m02:02:26.394206 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public.stg_starlink_sattelite ............ [[31mERROR[0m in 0.94s]
[0m02:02:26.395007 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:02:26.398081 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:26.398617 [debug] [MainThread]: On master: BEGIN
[0m02:02:26.399004 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:02:26.399602 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:02:26.400011 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:02:26.772661 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:26.774400 [debug] [MainThread]: On master: COMMIT
[0m02:02:26.775762 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:26.776451 [debug] [MainThread]: On master: COMMIT
[0m02:02:26.855195 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:26.855611 [debug] [MainThread]: On master: Close
[0m02:02:26.856383 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:02:26.856634 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:02:26.856894 [info ] [MainThread]: 
[0m02:02:26.857173 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 3.16 seconds (3.16s).
[0m02:02:26.857804 [debug] [MainThread]: Command end result
[0m02:02:26.867391 [info ] [MainThread]: 
[0m02:02:26.867764 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m02:02:26.868105 [info ] [MainThread]: 
[0m02:02:26.868403 [error] [MainThread]: [33mDatabase Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)[0m
[0m02:02:26.868690 [error] [MainThread]:   column "starlink_satellites.*" must appear in the GROUP BY clause or be used in an aggregate function
[0m02:02:26.868946 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:02:26.869237 [info ] [MainThread]: 
[0m02:02:26.869503 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:02:26.869974 [debug] [MainThread]: Command `dbt run` failed at 02:02:26.869894 after 3.33 seconds
[0m02:02:26.870293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b6b510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dca9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a8c6d0>]}
[0m02:02:26.870594 [debug] [MainThread]: Flushing usage events
[0m02:02:43.459407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a8cb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a1a4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065a49d0>]}


============================== 02:02:43.461852 | 2e04127d-3af7-451d-b509-4d7be767f3ee ==============================
[0m02:02:43.461852 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:02:43.462158 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'profiles_dir': '/Users/annaantypenko/.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:02:43.541530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2e04127d-3af7-451d-b509-4d7be767f3ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10709b750>]}
[0m02:02:43.545863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2e04127d-3af7-451d-b509-4d7be767f3ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10708e290>]}
[0m02:02:43.546242 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:02:43.551738 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:02:43.566834 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:02:43.567227 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:02:43.597653 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:02:43.600439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2e04127d-3af7-451d-b509-4d7be767f3ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069fb290>]}
[0m02:02:43.606392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2e04127d-3af7-451d-b509-4d7be767f3ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107339110>]}
[0m02:02:43.606737 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:02:43.606906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2e04127d-3af7-451d-b509-4d7be767f3ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107911010>]}
[0m02:02:43.607600 [info ] [MainThread]: 
[0m02:02:43.607988 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:02:43.608584 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:02:43.616766 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:02:43.617009 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:02:43.617152 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:02:43.617739 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:02:43.617898 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:02:44.111196 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:44.115569 [debug] [ThreadPool]: On list_dev: Close
[0m02:02:44.118998 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public)
[0m02:02:44.130161 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:02:44.130623 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:02:44.130942 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:02:44.131441 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:02:44.131793 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:02:44.505415 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:44.507191 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:02:44.508349 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:02:44.601482 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:44.605555 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:02:44.688335 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:02:44.707920 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:44.708516 [debug] [MainThread]: On master: BEGIN
[0m02:02:44.708876 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:02:44.709364 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:02:44.709703 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:02:45.079020 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:45.080604 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:45.081943 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:02:45.210645 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:45.212865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2e04127d-3af7-451d-b509-4d7be767f3ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073a5250>]}
[0m02:02:45.213681 [debug] [MainThread]: On master: ROLLBACK
[0m02:02:45.308894 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:45.309304 [debug] [MainThread]: On master: BEGIN
[0m02:02:45.346985 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:45.347457 [debug] [MainThread]: On master: COMMIT
[0m02:02:45.347882 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:45.348213 [debug] [MainThread]: On master: COMMIT
[0m02:02:45.423761 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:45.424690 [debug] [MainThread]: On master: Close
[0m02:02:45.426771 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:02:45.427707 [info ] [MainThread]: 
[0m02:02:45.431961 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:02:45.432812 [info ] [Thread-1 (]: 1 of 1 START sql table model public.stg_starlink_sattelite ..................... [RUN]
[0m02:02:45.433905 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:02:45.434413 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:02:45.439713 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:02:45.440873 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:02:45.434753 => 02:02:45.440632
[0m02:02:45.441325 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:02:45.486338 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:02:45.488844 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:02:45.489097 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:02:45.489313 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:02:45.489657 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:02:45.489903 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:02:45.847580 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:45.849146 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:02:45.850257 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public"."stg_starlink_sattelite__dbt_tmp"
    
    
    
  as (
    

with max_ingesteda as (
    select
        spacetrack.object_id,
        max(export_date) as last_ingested_date
    from "dev"."raw"."starlink_satellites"
    group  by 1)

select
    s.spacetrack.object_id,
    s.spacetrack.object_name,
    s.launch as launch_id,
    s.version as version_id,
    s.latitude,
    s.longitude,
    s.velocity_kms,
    s.spacetrack.center_name,
    s.spacetrack.time_system,
    s.spacetrack.launch_date,
    case when m.last_ingested_date != s.export_date then true else false end as deleted_flag,
    s.export_date,
    row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s

left join max_ingested m
on m.object_id = s.spacetrack.object_id
  );
[0m02:02:46.253018 [debug] [Thread-1 (]: Redshift adapter: Redshift error: relation "max_ingested" does not exist
[0m02:02:46.254633 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:02:46.330869 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:02:45.441608 => 02:02:46.329895
[0m02:02:46.332279 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:02:46.341042 [debug] [Thread-1 (]: Database Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)
  relation "max_ingested" does not exist
  compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:02:46.341856 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e04127d-3af7-451d-b509-4d7be767f3ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a18390>]}
[0m02:02:46.342674 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public.stg_starlink_sattelite ............ [[31mERROR[0m in 0.91s]
[0m02:02:46.343477 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:02:46.346322 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:46.346786 [debug] [MainThread]: On master: BEGIN
[0m02:02:46.347152 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:02:46.347737 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:02:46.348146 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:02:46.719201 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:46.720715 [debug] [MainThread]: On master: COMMIT
[0m02:02:46.721849 [debug] [MainThread]: Using redshift connection "master"
[0m02:02:46.722664 [debug] [MainThread]: On master: COMMIT
[0m02:02:46.798797 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:02:46.800209 [debug] [MainThread]: On master: Close
[0m02:02:46.802508 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:02:46.803478 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:02:46.804304 [info ] [MainThread]: 
[0m02:02:46.804998 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 3.20 seconds (3.20s).
[0m02:02:46.806677 [debug] [MainThread]: Command end result
[0m02:02:46.822018 [info ] [MainThread]: 
[0m02:02:46.822652 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m02:02:46.822991 [info ] [MainThread]: 
[0m02:02:46.823320 [error] [MainThread]: [33mDatabase Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)[0m
[0m02:02:46.823640 [error] [MainThread]:   relation "max_ingested" does not exist
[0m02:02:46.823942 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:02:46.824619 [info ] [MainThread]: 
[0m02:02:46.825135 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:02:46.825978 [debug] [MainThread]: Command `dbt run` failed at 02:02:46.825855 after 3.38 seconds
[0m02:02:46.826460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069eb7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cd9610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cd8190>]}
[0m02:02:46.826892 [debug] [MainThread]: Flushing usage events
[0m02:03:09.149490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107357a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10761d950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101e7e90>]}


============================== 02:03:09.151776 | ad243ea0-2986-44e2-8228-e7c292a2e690 ==============================
[0m02:03:09.151776 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:03:09.152078 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:03:09.228782 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ad243ea0-2986-44e2-8228-e7c292a2e690', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073ce510>]}
[0m02:03:09.232928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ad243ea0-2986-44e2-8228-e7c292a2e690', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101d3d90>]}
[0m02:03:09.233243 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:03:09.239118 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:03:09.253760 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:03:09.254190 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:03:09.282795 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:03:09.285684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ad243ea0-2986-44e2-8228-e7c292a2e690', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d90210>]}
[0m02:03:09.291093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ad243ea0-2986-44e2-8228-e7c292a2e690', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107c5e10>]}
[0m02:03:09.291383 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:03:09.291552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ad243ea0-2986-44e2-8228-e7c292a2e690', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d9dd10>]}
[0m02:03:09.292309 [info ] [MainThread]: 
[0m02:03:09.292716 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:03:09.293240 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:03:09.301142 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:03:09.301354 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:03:09.301498 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:03:09.302102 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:09.302265 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:09.732716 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:09.736601 [debug] [ThreadPool]: On list_dev: Close
[0m02:03:09.740461 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public)
[0m02:03:09.751933 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:03:09.752512 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:03:09.752896 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:03:09.753422 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:09.753770 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:10.133838 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:10.135306 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:03:10.136431 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:03:10.231892 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:10.236411 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:03:10.320991 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:03:10.340259 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:10.340794 [debug] [MainThread]: On master: BEGIN
[0m02:03:10.341198 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:03:10.341760 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:10.342113 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:10.715874 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:10.717378 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:10.718912 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:03:10.848615 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:10.850994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ad243ea0-2986-44e2-8228-e7c292a2e690', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110809590>]}
[0m02:03:10.851913 [debug] [MainThread]: On master: ROLLBACK
[0m02:03:10.948682 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:10.950135 [debug] [MainThread]: On master: BEGIN
[0m02:03:10.990080 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:10.990907 [debug] [MainThread]: On master: COMMIT
[0m02:03:10.991683 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:10.992297 [debug] [MainThread]: On master: COMMIT
[0m02:03:11.071137 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:11.072267 [debug] [MainThread]: On master: Close
[0m02:03:11.074627 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:03:11.075694 [info ] [MainThread]: 
[0m02:03:11.081057 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:03:11.082136 [info ] [Thread-1 (]: 1 of 1 START sql table model public.stg_starlink_sattelite ..................... [RUN]
[0m02:03:11.083309 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:03:11.083947 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:03:11.087778 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:11.088912 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:03:11.084330 => 02:03:11.088590
[0m02:03:11.089455 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:03:11.136099 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:11.138598 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:11.138858 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:03:11.139088 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:03:11.139484 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:11.139733 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:11.496993 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:11.498612 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:11.499834 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public"."stg_starlink_sattelite__dbt_tmp"
    
    
    
  as (
    

with max_ingested as (
    select
        spacetrack.object_id,
        max(export_date) as last_ingested_date
    from "dev"."raw"."starlink_satellites"
    group  by 1)

select
    s.spacetrack.object_id,
    s.spacetrack.object_name,
    s.launch as launch_id,
    s.version as version_id,
    s.latitude,
    s.longitude,
    s.velocity_kms,
    s.spacetrack.center_name,
    s.spacetrack.time_system,
    s.spacetrack.launch_date,
    case when m.last_ingested_date != s.export_date then true else false end as deleted_flag,
    s.export_date,
    row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s

left join max_ingested m
on m.object_id = s.spacetrack.object_id
  );
[0m02:03:11.820519 [debug] [Thread-1 (]: Redshift adapter: Redshift error: Spectrum nested query error
[0m02:03:11.822072 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:03:11.900231 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:03:11.089788 => 02:03:11.899197
[0m02:03:11.901940 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:03:11.910879 [debug] [Thread-1 (]: Database Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)
  Spectrum nested query error
  compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:03:11.911714 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad243ea0-2986-44e2-8228-e7c292a2e690', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110cdaf50>]}
[0m02:03:11.912541 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public.stg_starlink_sattelite ............ [[31mERROR[0m in 0.83s]
[0m02:03:11.913519 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:03:11.916337 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:11.916869 [debug] [MainThread]: On master: BEGIN
[0m02:03:11.917276 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:03:11.917899 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:11.918334 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:12.286800 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:12.288187 [debug] [MainThread]: On master: COMMIT
[0m02:03:12.289624 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:12.290420 [debug] [MainThread]: On master: COMMIT
[0m02:03:12.367914 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:12.369423 [debug] [MainThread]: On master: Close
[0m02:03:12.372085 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:03:12.373018 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:03:12.373602 [info ] [MainThread]: 
[0m02:03:12.374187 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 3.08 seconds (3.08s).
[0m02:03:12.375328 [debug] [MainThread]: Command end result
[0m02:03:12.391064 [info ] [MainThread]: 
[0m02:03:12.391619 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m02:03:12.391981 [info ] [MainThread]: 
[0m02:03:12.392425 [error] [MainThread]: [33mDatabase Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)[0m
[0m02:03:12.392844 [error] [MainThread]:   Spectrum nested query error
[0m02:03:12.393180 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:03:12.393509 [info ] [MainThread]: 
[0m02:03:12.393889 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:03:12.394562 [debug] [MainThread]: Command `dbt run` failed at 02:03:12.394451 after 3.25 seconds
[0m02:03:12.395000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10767be50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10518bf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107347a90>]}
[0m02:03:12.395414 [debug] [MainThread]: Flushing usage events
[0m02:03:39.784154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106933550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069463d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bf87d0>]}


============================== 02:03:39.786632 | f979db1a-3cef-4121-ae59-6633237038b0 ==============================
[0m02:03:39.786632 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:03:39.786939 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:03:39.863204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f979db1a-3cef-4121-ae59-6633237038b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106939d10>]}
[0m02:03:39.867339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f979db1a-3cef-4121-ae59-6633237038b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106933f90>]}
[0m02:03:39.867657 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:03:39.873658 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:03:39.887747 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:03:39.888151 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:03:39.916528 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:03:39.919424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f979db1a-3cef-4121-ae59-6633237038b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106beb5d0>]}
[0m02:03:39.925065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f979db1a-3cef-4121-ae59-6633237038b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107639f50>]}
[0m02:03:39.925341 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:03:39.925504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f979db1a-3cef-4121-ae59-6633237038b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b786d0>]}
[0m02:03:39.926228 [info ] [MainThread]: 
[0m02:03:39.926630 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:03:39.927141 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:03:39.935004 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:03:39.935233 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:03:39.935380 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:03:39.935983 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:39.936160 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:40.366560 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:40.371872 [debug] [ThreadPool]: On list_dev: Close
[0m02:03:40.375424 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public)
[0m02:03:40.386879 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:03:40.387423 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:03:40.387762 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:03:40.388261 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:40.388631 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:40.762534 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:40.764090 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:03:40.765142 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:03:40.855747 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:40.859970 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:03:40.942547 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:03:40.961268 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:40.961808 [debug] [MainThread]: On master: BEGIN
[0m02:03:40.962197 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:03:40.962830 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:40.963258 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:41.338368 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:41.339776 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:41.340930 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:03:41.468028 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:41.472541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f979db1a-3cef-4121-ae59-6633237038b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076d0ed0>]}
[0m02:03:41.473922 [debug] [MainThread]: On master: ROLLBACK
[0m02:03:41.569750 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:41.571400 [debug] [MainThread]: On master: BEGIN
[0m02:03:41.610830 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:41.612165 [debug] [MainThread]: On master: COMMIT
[0m02:03:41.613463 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:41.614702 [debug] [MainThread]: On master: COMMIT
[0m02:03:41.690368 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:41.691780 [debug] [MainThread]: On master: Close
[0m02:03:41.694446 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:03:41.695488 [info ] [MainThread]: 
[0m02:03:41.700680 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:03:41.701573 [info ] [Thread-1 (]: 1 of 1 START sql table model public.stg_starlink_sattelite ..................... [RUN]
[0m02:03:41.702692 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:03:41.703225 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:03:41.707314 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:41.707986 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:03:41.703569 => 02:03:41.707836
[0m02:03:41.708230 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:03:41.750225 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:41.752563 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:41.752882 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:03:41.753107 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:03:41.753502 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:41.753747 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:42.124968 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:42.126410 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:42.127645 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public"."stg_starlink_sattelite__dbt_tmp"
    
    
    
  as (
    

with max_ingested as (
    select
        spacetrack.object_id,
        max(export_date) as last_ingested_date
    from "dev"."raw"."starlink_satellites"
    group  by 1)

select
    s.spacetrack.object_id,
    s.spacetrack.object_name,
    s.launch as launch_id,
    s.version as version_id,
    s.latitude,
    s.longitude,
    s.velocity_kms,
    s.spacetrack.center_name,
    s.spacetrack.time_system,
    s.spacetrack.launch_date,
    -- case when m.last_ingested_date != s.export_date then true else false end as deleted_flag,
    s.export_date,
    row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s

-- left join max_ingested m
-- on m.object_id = s.spacetrack.object_id
  );
[0m02:03:43.842858 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m02:03:43.854789 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:43.855504 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public"."stg_starlink_sattelite" rename to "stg_starlink_sattelite__dbt_backup"
[0m02:03:44.054345 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:44.063176 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:44.063734 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m02:03:44.182328 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:44.215205 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:03:44.215760 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:44.216093 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:03:45.768221 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m02:03:45.771408 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:45.772547 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:03:45.852523 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:45.867480 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:45.868114 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "dev"."public"."stg_starlink_sattelite__dbt_backup" cascade
[0m02:03:45.947651 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:45.950914 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:03:45.952378 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:45.953453 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:03:46.873927 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:03:46.875786 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:46.876969 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:03:46.917378 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:46.921228 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:03:41.708379 => 02:03:46.920411
[0m02:03:46.922404 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:03:47.002340 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:03:47.005765 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f979db1a-3cef-4121-ae59-6633237038b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107625510>]}
[0m02:03:47.007362 [info ] [Thread-1 (]: 1 of 1 OK created sql table model public.stg_starlink_sattelite ................ [[32mSUCCESS[0m in 5.30s]
[0m02:03:47.008659 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:03:47.012451 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:47.013069 [debug] [MainThread]: On master: BEGIN
[0m02:03:47.013467 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:03:47.014096 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:47.014517 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:47.386313 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:47.387935 [debug] [MainThread]: On master: COMMIT
[0m02:03:47.389215 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:47.389989 [debug] [MainThread]: On master: COMMIT
[0m02:03:47.466179 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:47.467718 [debug] [MainThread]: On master: Close
[0m02:03:47.470656 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:03:47.471504 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:03:47.472127 [info ] [MainThread]: 
[0m02:03:47.472922 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 7.55 seconds (7.55s).
[0m02:03:47.474291 [debug] [MainThread]: Command end result
[0m02:03:47.493647 [info ] [MainThread]: 
[0m02:03:47.494203 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:03:47.494798 [info ] [MainThread]: 
[0m02:03:47.495208 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m02:03:47.495878 [debug] [MainThread]: Command `dbt run` succeeded at 02:03:47.495763 after 7.72 seconds
[0m02:03:47.496314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b27050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bb2d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bb2bd0>]}
[0m02:03:47.496700 [debug] [MainThread]: Flushing usage events
[0m02:04:01.338226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e95750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10916cb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10916d250>]}


============================== 02:04:01.340654 | 7dbcedf6-2468-45af-9e73-ba9142c18541 ==============================
[0m02:04:01.340654 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:04:01.340964 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:04:01.416170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7dbcedf6-2468-45af-9e73-ba9142c18541', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10915a0d0>]}
[0m02:04:01.420339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7dbcedf6-2468-45af-9e73-ba9142c18541', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093fed50>]}
[0m02:04:01.420659 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:04:01.426566 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:04:01.440920 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:04:01.441301 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:04:01.470036 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:04:01.473009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7dbcedf6-2468-45af-9e73-ba9142c18541', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e96c50>]}
[0m02:04:01.478168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7dbcedf6-2468-45af-9e73-ba9142c18541', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109798210>]}
[0m02:04:01.478450 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:04:01.478614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7dbcedf6-2468-45af-9e73-ba9142c18541', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d71a10>]}
[0m02:04:01.479330 [info ] [MainThread]: 
[0m02:04:01.479740 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:04:01.480235 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:04:01.488602 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:04:01.488935 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:04:01.489088 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:04:01.489890 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:04:01.490046 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:04:01.996810 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:04:02.001397 [debug] [ThreadPool]: On list_dev: Close
[0m02:04:02.005585 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public)
[0m02:04:02.016930 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:04:02.017427 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:04:02.017798 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:04:02.018327 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:04:02.018661 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:04:02.399921 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:04:02.401011 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:04:02.401785 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:04:02.492911 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:04:02.496549 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:04:02.579519 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:04:02.594060 [debug] [MainThread]: Using redshift connection "master"
[0m02:04:02.594553 [debug] [MainThread]: On master: BEGIN
[0m02:04:02.594882 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:04:02.595384 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:04:02.595735 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:04:02.960418 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:04:02.961350 [debug] [MainThread]: Using redshift connection "master"
[0m02:04:02.962026 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:04:03.086831 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:04:03.089974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7dbcedf6-2468-45af-9e73-ba9142c18541', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097fccd0>]}
[0m02:04:03.091143 [debug] [MainThread]: On master: ROLLBACK
[0m02:04:03.188526 [debug] [MainThread]: Using redshift connection "master"
[0m02:04:03.189219 [debug] [MainThread]: On master: BEGIN
[0m02:04:03.228654 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:04:03.229652 [debug] [MainThread]: On master: COMMIT
[0m02:04:03.230742 [debug] [MainThread]: Using redshift connection "master"
[0m02:04:03.231350 [debug] [MainThread]: On master: COMMIT
[0m02:04:03.309694 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:04:03.311059 [debug] [MainThread]: On master: Close
[0m02:04:03.313496 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:04:03.314598 [info ] [MainThread]: 
[0m02:04:03.319302 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:04:03.320139 [info ] [Thread-1 (]: 1 of 1 START sql table model public.stg_starlink_sattelite ..................... [RUN]
[0m02:04:03.321277 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:04:03.321800 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:04:03.327123 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:04:03.328388 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:04:03.322137 => 02:04:03.328106
[0m02:04:03.328902 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:04:03.374351 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:04:03.376670 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:04:03.376924 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:04:03.377142 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:04:03.377487 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:04:03.377711 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:04:03.748126 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:04:03.749562 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:04:03.750895 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public"."stg_starlink_sattelite__dbt_tmp"
    
    
    
  as (
    

with max_ingested as (
    select
        spacetrack.object_id,
        max(export_date) as last_ingested_date
    from "dev"."raw"."starlink_satellites"
    group  by 1)

select
    s.spacetrack.object_id,
    s.spacetrack.object_name,
    s.launch as launch_id,
    s.version as version_id,
    s.latitude,
    s.longitude,
    s.velocity_kms,
    s.spacetrack.center_name,
    s.spacetrack.time_system,
    s.spacetrack.launch_date,
    -- case when m.last_ingested_date != s.export_date then true else false end as deleted_flag,
    s.export_date,
    row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s

left join max_ingested m
on m.object_id = s.spacetrack.object_id
  );
[0m02:04:04.159512 [debug] [Thread-1 (]: Redshift adapter: Redshift error: Spectrum nested query error
[0m02:04:04.160952 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:04:04.240048 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:04:03.329224 => 02:04:04.239356
[0m02:04:04.241152 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:04:04.249797 [debug] [Thread-1 (]: Database Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)
  Spectrum nested query error
  compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:04:04.250636 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7dbcedf6-2468-45af-9e73-ba9142c18541', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d7bb10>]}
[0m02:04:04.251551 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public.stg_starlink_sattelite ............ [[31mERROR[0m in 0.93s]
[0m02:04:04.252360 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:04:04.255262 [debug] [MainThread]: Using redshift connection "master"
[0m02:04:04.255739 [debug] [MainThread]: On master: BEGIN
[0m02:04:04.256113 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:04:04.256715 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:04:04.257129 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:04:04.627120 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:04:04.628501 [debug] [MainThread]: On master: COMMIT
[0m02:04:04.629843 [debug] [MainThread]: Using redshift connection "master"
[0m02:04:04.630918 [debug] [MainThread]: On master: COMMIT
[0m02:04:04.707797 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:04:04.709140 [debug] [MainThread]: On master: Close
[0m02:04:04.711130 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:04:04.711889 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:04:04.712812 [info ] [MainThread]: 
[0m02:04:04.713871 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 3.23 seconds (3.23s).
[0m02:04:04.715333 [debug] [MainThread]: Command end result
[0m02:04:04.730646 [info ] [MainThread]: 
[0m02:04:04.731274 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m02:04:04.731740 [info ] [MainThread]: 
[0m02:04:04.732107 [error] [MainThread]: [33mDatabase Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)[0m
[0m02:04:04.732448 [error] [MainThread]:   Spectrum nested query error
[0m02:04:04.732762 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:04:04.733076 [info ] [MainThread]: 
[0m02:04:04.733440 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:04:04.734099 [debug] [MainThread]: Command `dbt run` failed at 02:04:04.733987 after 3.40 seconds
[0m02:04:04.734545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10916d190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10916d150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bb37d0>]}
[0m02:04:04.735010 [debug] [MainThread]: Flushing usage events
[0m02:06:27.734655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103b2cb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102e00f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e2c050>]}


============================== 02:06:27.736935 | bfbf0f5c-02ee-42da-9385-d777b1fcf57e ==============================
[0m02:06:27.736935 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:06:27.737250 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:06:27.814238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bfbf0f5c-02ee-42da-9385-d777b1fcf57e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b5aed0>]}
[0m02:06:27.818576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bfbf0f5c-02ee-42da-9385-d777b1fcf57e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053afc90>]}
[0m02:06:27.818936 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:06:27.825068 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:06:27.839668 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:06:27.840047 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:06:27.868605 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:06:27.871361 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bfbf0f5c-02ee-42da-9385-d777b1fcf57e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c64f90>]}
[0m02:06:27.876352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bfbf0f5c-02ee-42da-9385-d777b1fcf57e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105743e10>]}
[0m02:06:27.876631 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:06:27.876817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bfbf0f5c-02ee-42da-9385-d777b1fcf57e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d01a50>]}
[0m02:06:27.877587 [info ] [MainThread]: 
[0m02:06:27.878104 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:06:27.878757 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:06:27.886778 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:06:27.887034 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:06:27.887200 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:06:27.887916 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:06:27.888092 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:06:28.443966 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:06:28.448579 [debug] [ThreadPool]: On list_dev: Close
[0m02:06:28.451975 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public)
[0m02:06:28.463174 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:06:28.463635 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:06:28.463987 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:06:28.464508 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:06:28.464869 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:06:28.840007 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:28.841366 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:06:28.842425 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:06:28.933053 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:28.936688 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:06:29.017718 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:06:29.037115 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:29.037678 [debug] [MainThread]: On master: BEGIN
[0m02:06:29.038066 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:06:29.038664 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:06:29.039071 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:06:29.419784 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:29.421390 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:29.422914 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:06:29.547565 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:29.551310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bfbf0f5c-02ee-42da-9385-d777b1fcf57e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c746d0>]}
[0m02:06:29.552406 [debug] [MainThread]: On master: ROLLBACK
[0m02:06:29.648984 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:29.649431 [debug] [MainThread]: On master: BEGIN
[0m02:06:29.688462 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:29.688908 [debug] [MainThread]: On master: COMMIT
[0m02:06:29.689283 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:29.689554 [debug] [MainThread]: On master: COMMIT
[0m02:06:29.767686 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:29.768301 [debug] [MainThread]: On master: Close
[0m02:06:29.769521 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:06:29.769993 [info ] [MainThread]: 
[0m02:06:29.773437 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:06:29.774127 [info ] [Thread-1 (]: 1 of 1 START sql table model public.stg_starlink_sattelite ..................... [RUN]
[0m02:06:29.775217 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:06:29.775658 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:06:29.779431 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:06:29.780166 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:06:29.775930 => 02:06:29.780031
[0m02:06:29.780422 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:06:29.821274 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:06:29.823996 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:06:29.824222 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:06:29.824416 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:06:29.824725 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:06:29.824945 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:06:30.184391 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:30.185897 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:06:30.187197 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public"."stg_starlink_sattelite__dbt_tmp"
    
    
    
  as (
    

with source as (
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s
),

max_ingested as (
    select
        object_id,
        max(export_date) as last_ingested_date
    from source
    group  by 1)

select
    src.*,
    case when m.last_ingested_date != s.export_date then true else false end as deleted_flag,
    row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from source src

left join max_ingested m
on m.object_id = src.object_id
  );
[0m02:06:30.592150 [debug] [Thread-1 (]: Redshift adapter: Redshift error: relation "s" does not exist
[0m02:06:30.593685 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:06:30.672273 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:06:29.780564 => 02:06:30.671567
[0m02:06:30.673382 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:06:30.682023 [debug] [Thread-1 (]: Database Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)
  relation "s" does not exist
  compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:06:30.682866 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bfbf0f5c-02ee-42da-9385-d777b1fcf57e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10578d010>]}
[0m02:06:30.683695 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public.stg_starlink_sattelite ............ [[31mERROR[0m in 0.91s]
[0m02:06:30.684671 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:06:30.687805 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:30.688273 [debug] [MainThread]: On master: BEGIN
[0m02:06:30.688637 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:06:30.689233 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:06:30.689643 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:06:31.064398 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:31.065884 [debug] [MainThread]: On master: COMMIT
[0m02:06:31.067517 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:31.068489 [debug] [MainThread]: On master: COMMIT
[0m02:06:31.146381 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:31.147942 [debug] [MainThread]: On master: Close
[0m02:06:31.150537 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:06:31.151462 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:06:31.152025 [info ] [MainThread]: 
[0m02:06:31.152631 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 3.27 seconds (3.27s).
[0m02:06:31.153811 [debug] [MainThread]: Command end result
[0m02:06:31.170105 [info ] [MainThread]: 
[0m02:06:31.170668 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m02:06:31.171021 [info ] [MainThread]: 
[0m02:06:31.171369 [error] [MainThread]: [33mDatabase Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)[0m
[0m02:06:31.171711 [error] [MainThread]:   relation "s" does not exist
[0m02:06:31.172010 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:06:31.172309 [info ] [MainThread]: 
[0m02:06:31.172661 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:06:31.173282 [debug] [MainThread]: Command `dbt run` failed at 02:06:31.173175 after 3.45 seconds
[0m02:06:31.173704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ee6510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050efc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b4c490>]}
[0m02:06:31.174103 [debug] [MainThread]: Flushing usage events
[0m02:06:42.366102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089c5350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f63390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10844e890>]}


============================== 02:06:42.368352 | 2380504c-a1a3-473c-844b-a2f46f5bf478 ==============================
[0m02:06:42.368352 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:06:42.368649 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:06:42.441111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2380504c-a1a3-473c-844b-a2f46f5bf478', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089c4890>]}
[0m02:06:42.445242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2380504c-a1a3-473c-844b-a2f46f5bf478', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109206810>]}
[0m02:06:42.445557 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:06:42.451586 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:06:42.465684 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:06:42.466018 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:06:42.496265 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:06:42.499330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2380504c-a1a3-473c-844b-a2f46f5bf478', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d03450>]}
[0m02:06:42.505331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2380504c-a1a3-473c-844b-a2f46f5bf478', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095a2d10>]}
[0m02:06:42.505635 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:06:42.505817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2380504c-a1a3-473c-844b-a2f46f5bf478', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ae77d0>]}
[0m02:06:42.506700 [info ] [MainThread]: 
[0m02:06:42.507165 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:06:42.507785 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:06:42.516430 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:06:42.516705 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:06:42.516859 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:06:42.517570 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:06:42.517761 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:06:42.959478 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:42.964032 [debug] [ThreadPool]: On list_dev: Close
[0m02:06:42.967843 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public)
[0m02:06:42.978957 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:06:42.979483 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:06:42.979802 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:06:42.980304 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:06:42.980665 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:06:43.361206 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:43.362988 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:06:43.363935 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:06:43.456604 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:43.460484 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:06:43.543889 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:06:43.563305 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:43.563874 [debug] [MainThread]: On master: BEGIN
[0m02:06:43.564282 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:06:43.564894 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:06:43.565321 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:06:43.942535 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:43.943966 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:43.945280 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:06:44.069177 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:44.073597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2380504c-a1a3-473c-844b-a2f46f5bf478', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109af5710>]}
[0m02:06:44.074808 [debug] [MainThread]: On master: ROLLBACK
[0m02:06:44.170973 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:44.172411 [debug] [MainThread]: On master: BEGIN
[0m02:06:44.212839 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:44.214167 [debug] [MainThread]: On master: COMMIT
[0m02:06:44.215465 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:44.216685 [debug] [MainThread]: On master: COMMIT
[0m02:06:44.296356 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:44.297729 [debug] [MainThread]: On master: Close
[0m02:06:44.300554 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:06:44.301526 [info ] [MainThread]: 
[0m02:06:44.307304 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:06:44.308149 [info ] [Thread-1 (]: 1 of 1 START sql table model public.stg_starlink_sattelite ..................... [RUN]
[0m02:06:44.309401 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:06:44.310121 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:06:44.313586 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:06:44.314702 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:06:44.310540 => 02:06:44.314410
[0m02:06:44.315228 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:06:44.360574 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:06:44.363497 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:06:44.363751 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:06:44.363978 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:06:44.364357 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:06:44.364603 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:06:44.724019 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:44.725525 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:06:44.726990 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public"."stg_starlink_sattelite__dbt_tmp"
    
    
    
  as (
    

with source as (
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s
),

max_ingested as (
    select
        object_id,
        max(export_date) as last_ingested_date
    from source
    group  by 1)

select
    src.*,
    case when m.last_ingested_date != s.export_date then true else false end as deleted_flag,
    row_number() over (partition by src.object_id order by src.export_date desc) as rnk
from source src

left join max_ingested m
on m.object_id = src.object_id
  );
[0m02:06:45.016740 [debug] [Thread-1 (]: Redshift adapter: Redshift error: relation "s" does not exist
[0m02:06:45.018363 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:06:45.097333 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:06:44.315563 => 02:06:45.096315
[0m02:06:45.098614 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:06:45.108770 [debug] [Thread-1 (]: Database Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)
  relation "s" does not exist
  compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:06:45.109598 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2380504c-a1a3-473c-844b-a2f46f5bf478', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095de5d0>]}
[0m02:06:45.110433 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public.stg_starlink_sattelite ............ [[31mERROR[0m in 0.80s]
[0m02:06:45.111235 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:06:45.114094 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:45.114608 [debug] [MainThread]: On master: BEGIN
[0m02:06:45.115006 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:06:45.115580 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:06:45.115931 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:06:45.481740 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:45.482410 [debug] [MainThread]: On master: COMMIT
[0m02:06:45.482940 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:45.483340 [debug] [MainThread]: On master: COMMIT
[0m02:06:45.561167 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:45.562944 [debug] [MainThread]: On master: Close
[0m02:06:45.565380 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:06:45.566569 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:06:45.567350 [info ] [MainThread]: 
[0m02:06:45.568071 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 3.06 seconds (3.06s).
[0m02:06:45.569881 [debug] [MainThread]: Command end result
[0m02:06:45.585397 [info ] [MainThread]: 
[0m02:06:45.585933 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m02:06:45.586280 [info ] [MainThread]: 
[0m02:06:45.586858 [error] [MainThread]: [33mDatabase Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)[0m
[0m02:06:45.587268 [error] [MainThread]:   relation "s" does not exist
[0m02:06:45.587621 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:06:45.587972 [info ] [MainThread]: 
[0m02:06:45.588372 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:06:45.589158 [debug] [MainThread]: Command `dbt run` failed at 02:06:45.588991 after 3.23 seconds
[0m02:06:45.589684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a54390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089dfd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c75310>]}
[0m02:06:45.590157 [debug] [MainThread]: Flushing usage events
[0m02:06:55.495944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077c9810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076f6790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074309d0>]}


============================== 02:06:55.498534 | e1ec721b-04fe-4600-bf69-a97601ba2bb5 ==============================
[0m02:06:55.498534 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:06:55.498873 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'debug': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:06:55.577951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e1ec721b-04fe-4600-bf69-a97601ba2bb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076f6710>]}
[0m02:06:55.582505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e1ec721b-04fe-4600-bf69-a97601ba2bb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10908e110>]}
[0m02:06:55.583093 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:06:55.589343 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:06:55.604289 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:06:55.604692 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:06:55.635112 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:06:55.638164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e1ec721b-04fe-4600-bf69-a97601ba2bb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093d1890>]}
[0m02:06:55.643208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e1ec721b-04fe-4600-bf69-a97601ba2bb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109339b10>]}
[0m02:06:55.643583 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:06:55.643773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e1ec721b-04fe-4600-bf69-a97601ba2bb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109914f50>]}
[0m02:06:55.644503 [info ] [MainThread]: 
[0m02:06:55.644889 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:06:55.645439 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:06:55.653729 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:06:55.654086 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:06:55.654265 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:06:55.655033 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:06:55.655270 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:06:56.088169 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:56.089634 [debug] [ThreadPool]: On list_dev: Close
[0m02:06:56.091137 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public)
[0m02:06:56.096653 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:06:56.096913 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:06:56.097103 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:06:56.097410 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:06:56.097625 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:06:56.462262 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:56.463740 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:06:56.465335 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:06:56.558370 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:56.561676 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:06:56.645614 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:06:56.663852 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:56.664479 [debug] [MainThread]: On master: BEGIN
[0m02:06:56.664882 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:06:56.665522 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:06:56.665980 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:06:57.034225 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:57.034748 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:57.035123 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:06:57.157516 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:57.158463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e1ec721b-04fe-4600-bf69-a97601ba2bb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10988d7d0>]}
[0m02:06:57.158761 [debug] [MainThread]: On master: ROLLBACK
[0m02:06:57.254165 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:57.254601 [debug] [MainThread]: On master: BEGIN
[0m02:06:57.292279 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:57.292674 [debug] [MainThread]: On master: COMMIT
[0m02:06:57.292967 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:57.293178 [debug] [MainThread]: On master: COMMIT
[0m02:06:57.367881 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:57.368370 [debug] [MainThread]: On master: Close
[0m02:06:57.369423 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:06:57.369834 [info ] [MainThread]: 
[0m02:06:57.372816 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:06:57.373401 [info ] [Thread-1 (]: 1 of 1 START sql table model public.stg_starlink_sattelite ..................... [RUN]
[0m02:06:57.374218 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:06:57.374673 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:06:57.378524 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:06:57.379452 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:06:57.374942 => 02:06:57.379248
[0m02:06:57.379829 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:06:57.416920 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:06:57.419437 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:06:57.419659 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:06:57.419846 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:06:57.420152 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:06:57.420355 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:06:57.775665 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:57.777221 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:06:57.778985 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public"."stg_starlink_sattelite__dbt_tmp"
    
    
    
  as (
    

with source as (
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s
),

max_ingested as (
    select
        object_id,
        max(export_date) as last_ingested_date
    from source
    group  by 1)

select
    src.*,
    case when m.last_ingested_date != src.export_date then true else false end as deleted_flag,
    row_number() over (partition by src.object_id order by src.export_date desc) as rnk
from source src

left join max_ingested m
on m.object_id = src.object_id
  );
[0m02:06:58.178585 [debug] [Thread-1 (]: Redshift adapter: Redshift error: Spectrum nested query error
[0m02:06:58.180107 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:06:58.259393 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:06:57.380067 => 02:06:58.258551
[0m02:06:58.261056 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:06:58.270443 [debug] [Thread-1 (]: Database Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)
  Spectrum nested query error
  compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:06:58.271288 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1ec721b-04fe-4600-bf69-a97601ba2bb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10988d810>]}
[0m02:06:58.272112 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public.stg_starlink_sattelite ............ [[31mERROR[0m in 0.90s]
[0m02:06:58.272927 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:06:58.275912 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:58.276523 [debug] [MainThread]: On master: BEGIN
[0m02:06:58.276934 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:06:58.277557 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:06:58.277996 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:06:58.646094 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:58.647499 [debug] [MainThread]: On master: COMMIT
[0m02:06:58.648709 [debug] [MainThread]: Using redshift connection "master"
[0m02:06:58.649829 [debug] [MainThread]: On master: COMMIT
[0m02:06:58.728385 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:06:58.729790 [debug] [MainThread]: On master: Close
[0m02:06:58.732121 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:06:58.733157 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:06:58.733784 [info ] [MainThread]: 
[0m02:06:58.734520 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 3.09 seconds (3.09s).
[0m02:06:58.735895 [debug] [MainThread]: Command end result
[0m02:06:58.751061 [info ] [MainThread]: 
[0m02:06:58.751631 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m02:06:58.751986 [info ] [MainThread]: 
[0m02:06:58.752492 [error] [MainThread]: [33mDatabase Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)[0m
[0m02:06:58.752900 [error] [MainThread]:   Spectrum nested query error
[0m02:06:58.753231 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:06:58.754001 [info ] [MainThread]: 
[0m02:06:58.754472 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:06:58.755212 [debug] [MainThread]: Command `dbt run` failed at 02:06:58.755087 after 3.27 seconds
[0m02:06:58.755670 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102f5fdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074d0650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107454890>]}
[0m02:06:58.756095 [debug] [MainThread]: Flushing usage events
[0m02:07:22.504706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acdb390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa16910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8f5550>]}


============================== 02:07:22.507557 | 1b23d677-14d7-41a7-9fb4-7caee1bd4522 ==============================
[0m02:07:22.507557 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:07:22.507902 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:07:22.587298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1b23d677-14d7-41a7-9fb4-7caee1bd4522', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aade950>]}
[0m02:07:22.591703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1b23d677-14d7-41a7-9fb4-7caee1bd4522', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b09ff50>]}
[0m02:07:22.592175 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:07:22.597854 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:07:22.613293 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:07:22.613722 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:07:22.644530 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:07:22.647328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1b23d677-14d7-41a7-9fb4-7caee1bd4522', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b010650>]}
[0m02:07:22.652545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1b23d677-14d7-41a7-9fb4-7caee1bd4522', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b331b10>]}
[0m02:07:22.652882 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:07:22.653068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1b23d677-14d7-41a7-9fb4-7caee1bd4522', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b915dd0>]}
[0m02:07:22.653838 [info ] [MainThread]: 
[0m02:07:22.654306 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:07:22.654975 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:07:22.663486 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:07:22.663764 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:07:22.663912 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:07:22.664520 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:07:22.664675 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:07:23.111699 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:23.115962 [debug] [ThreadPool]: On list_dev: Close
[0m02:07:23.119071 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public)
[0m02:07:23.130090 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:07:23.130664 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:07:23.130997 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:07:23.131545 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:07:23.131922 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:07:23.490781 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:23.491328 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:07:23.491629 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:07:23.580902 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:23.582526 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:07:23.661777 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:07:23.672803 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:23.673219 [debug] [MainThread]: On master: BEGIN
[0m02:07:23.673465 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:07:23.673841 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:07:23.674109 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:07:24.042783 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:24.044515 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:24.045532 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:07:24.170942 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:24.175106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1b23d677-14d7-41a7-9fb4-7caee1bd4522', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b010650>]}
[0m02:07:24.176759 [debug] [MainThread]: On master: ROLLBACK
[0m02:07:24.275322 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:24.276779 [debug] [MainThread]: On master: BEGIN
[0m02:07:24.318206 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:24.319785 [debug] [MainThread]: On master: COMMIT
[0m02:07:24.321379 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:24.322475 [debug] [MainThread]: On master: COMMIT
[0m02:07:24.402453 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:24.403916 [debug] [MainThread]: On master: Close
[0m02:07:24.406943 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:07:24.408007 [info ] [MainThread]: 
[0m02:07:24.414290 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:07:24.415376 [info ] [Thread-1 (]: 1 of 1 START sql table model public.stg_starlink_sattelite ..................... [RUN]
[0m02:07:24.416464 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:07:24.416976 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:07:24.422112 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:24.423581 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:07:24.417309 => 02:07:24.423073
[0m02:07:24.424272 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:07:24.469784 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:24.472561 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:24.472809 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:07:24.473025 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:07:24.473412 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:07:24.473653 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:07:24.829278 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:24.831121 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:24.832580 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public"."stg_starlink_sattelite__dbt_tmp"
    
    
    
  as (
    

with source as (
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s
),

max_ingested as (
    select
        object_id,
        max(export_date) as last_ingested_date
    from source
    group  by 1)

select
    src.*,
    -- case when m.last_ingested_date != src.export_date then true else false end as deleted_flag,
    row_number() over (partition by src.object_id order by src.export_date desc) as rnk
from source src

left join max_ingested m
on m.object_id = src.object_id
  );
[0m02:07:25.151118 [debug] [Thread-1 (]: Redshift adapter: Redshift error: Spectrum nested query error
[0m02:07:25.152902 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:07:25.230885 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:07:24.424643 => 02:07:25.230052
[0m02:07:25.232271 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:07:25.242673 [debug] [Thread-1 (]: Database Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)
  Spectrum nested query error
  compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:07:25.243505 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b23d677-14d7-41a7-9fb4-7caee1bd4522', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8def50>]}
[0m02:07:25.244312 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public.stg_starlink_sattelite ............ [[31mERROR[0m in 0.83s]
[0m02:07:25.245126 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:07:25.248007 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:25.248471 [debug] [MainThread]: On master: BEGIN
[0m02:07:25.248864 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:07:25.249484 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:07:25.249887 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:07:25.624705 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:25.626138 [debug] [MainThread]: On master: COMMIT
[0m02:07:25.627542 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:25.628253 [debug] [MainThread]: On master: COMMIT
[0m02:07:25.704609 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:25.705087 [debug] [MainThread]: On master: Close
[0m02:07:25.705957 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:07:25.706237 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:07:25.706528 [info ] [MainThread]: 
[0m02:07:25.706845 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 3.05 seconds (3.05s).
[0m02:07:25.707430 [debug] [MainThread]: Command end result
[0m02:07:25.717650 [info ] [MainThread]: 
[0m02:07:25.718114 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m02:07:25.718425 [info ] [MainThread]: 
[0m02:07:25.718661 [error] [MainThread]: [33mDatabase Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)[0m
[0m02:07:25.718882 [error] [MainThread]:   Spectrum nested query error
[0m02:07:25.719081 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:07:25.719282 [info ] [MainThread]: 
[0m02:07:25.719527 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:07:25.720012 [debug] [MainThread]: Command `dbt run` failed at 02:07:25.719926 after 3.22 seconds
[0m02:07:25.720326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8a6a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8ca1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b09fcd0>]}
[0m02:07:25.720618 [debug] [MainThread]: Flushing usage events
[0m02:07:31.975098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e4b490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105133390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e48810>]}


============================== 02:07:31.977725 | 43d3e034-aabb-4c3f-a14b-0160670059e0 ==============================
[0m02:07:31.977725 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:07:31.978051 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:07:32.058605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '43d3e034-aabb-4c3f-a14b-0160670059e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e554d0>]}
[0m02:07:32.062980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '43d3e034-aabb-4c3f-a14b-0160670059e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bc3050>]}
[0m02:07:32.063314 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:07:32.069521 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:07:32.084419 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:07:32.084825 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:07:32.113441 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:07:32.116293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '43d3e034-aabb-4c3f-a14b-0160670059e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cd4a90>]}
[0m02:07:32.121698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '43d3e034-aabb-4c3f-a14b-0160670059e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105770fd0>]}
[0m02:07:32.121971 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:07:32.122138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '43d3e034-aabb-4c3f-a14b-0160670059e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d4d850>]}
[0m02:07:32.122924 [info ] [MainThread]: 
[0m02:07:32.123432 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:07:32.124047 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:07:32.132268 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:07:32.132462 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:07:32.132603 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:07:32.133167 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:07:32.133318 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:07:32.571497 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:32.574721 [debug] [ThreadPool]: On list_dev: Close
[0m02:07:32.577798 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public)
[0m02:07:32.588581 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:07:32.588995 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:07:32.589310 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:07:32.589799 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:07:32.590138 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:07:32.953820 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:32.954215 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:07:32.954441 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:07:33.044619 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:33.046366 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:07:33.127541 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:07:33.137446 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:33.137894 [debug] [MainThread]: On master: BEGIN
[0m02:07:33.138150 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:07:33.138566 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:07:33.138834 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:07:33.495120 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:33.495611 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:33.495974 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:07:33.617707 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:33.618996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '43d3e034-aabb-4c3f-a14b-0160670059e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10544ea50>]}
[0m02:07:33.619440 [debug] [MainThread]: On master: ROLLBACK
[0m02:07:33.711965 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:33.712348 [debug] [MainThread]: On master: BEGIN
[0m02:07:33.751122 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:33.751610 [debug] [MainThread]: On master: COMMIT
[0m02:07:33.751994 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:33.752269 [debug] [MainThread]: On master: COMMIT
[0m02:07:33.826530 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:33.826986 [debug] [MainThread]: On master: Close
[0m02:07:33.828190 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:07:33.828668 [info ] [MainThread]: 
[0m02:07:33.832123 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:07:33.833128 [info ] [Thread-1 (]: 1 of 1 START sql table model public.stg_starlink_sattelite ..................... [RUN]
[0m02:07:33.834299 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:07:33.834941 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:07:33.839626 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:33.840717 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:07:33.835323 => 02:07:33.840452
[0m02:07:33.841184 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:07:33.885037 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:33.887584 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:33.887854 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:07:33.888070 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:07:33.888391 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:07:33.888610 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:07:34.250264 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:34.251913 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:34.253716 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public"."stg_starlink_sattelite__dbt_tmp"
    
    
    
  as (
    

with source as (
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s
),

max_ingested as (
    select
        object_id,
        max(export_date) as last_ingested_date
    from source
    group  by 1)

select
    src.*,
    -- case when m.last_ingested_date != src.export_date then true else false end as deleted_flag,
    row_number() over (partition by src.object_id order by src.export_date desc) as rnk
from source src

-- left join max_ingested m
-- on m.object_id = src.object_id
  );
[0m02:07:34.612861 [debug] [Thread-1 (]: Redshift adapter: Redshift error: Spectrum nested query error
[0m02:07:34.614602 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:07:34.694287 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:07:33.841472 => 02:07:34.693450
[0m02:07:34.695754 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:07:34.704176 [debug] [Thread-1 (]: Database Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)
  Spectrum nested query error
  compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:07:34.704985 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43d3e034-aabb-4c3f-a14b-0160670059e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e48f50>]}
[0m02:07:34.705803 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public.stg_starlink_sattelite ............ [[31mERROR[0m in 0.87s]
[0m02:07:34.706704 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:07:34.709868 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:34.710397 [debug] [MainThread]: On master: BEGIN
[0m02:07:34.710803 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:07:34.711417 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:07:34.711826 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:07:35.075790 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:35.077329 [debug] [MainThread]: On master: COMMIT
[0m02:07:35.078550 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:35.079430 [debug] [MainThread]: On master: COMMIT
[0m02:07:35.156393 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:35.157772 [debug] [MainThread]: On master: Close
[0m02:07:35.160567 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:07:35.161531 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:07:35.162216 [info ] [MainThread]: 
[0m02:07:35.162918 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 3.04 seconds (3.04s).
[0m02:07:35.164165 [debug] [MainThread]: Command end result
[0m02:07:35.180459 [info ] [MainThread]: 
[0m02:07:35.181035 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m02:07:35.181380 [info ] [MainThread]: 
[0m02:07:35.181711 [error] [MainThread]: [33mDatabase Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)[0m
[0m02:07:35.182183 [error] [MainThread]:   Spectrum nested query error
[0m02:07:35.182646 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:07:35.183059 [info ] [MainThread]: 
[0m02:07:35.183454 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:07:35.184254 [debug] [MainThread]: Command `dbt run` failed at 02:07:35.184120 after 3.22 seconds
[0m02:07:35.184741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e38d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b9f410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1009bd0d0>]}
[0m02:07:35.185190 [debug] [MainThread]: Flushing usage events
[0m02:07:46.161596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a025650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3db990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e565d0>]}


============================== 02:07:46.164015 | c8e4809c-a22f-4deb-98df-016677da7bb6 ==============================
[0m02:07:46.164015 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:07:46.164333 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'send_anonymous_usage_stats': 'True'}
[0m02:07:46.244927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c8e4809c-a22f-4deb-98df-016677da7bb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0242d0>]}
[0m02:07:46.249215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c8e4809c-a22f-4deb-98df-016677da7bb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7a5090>]}
[0m02:07:46.249561 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:07:46.255510 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:07:46.270354 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:07:46.270779 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:07:46.299718 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:07:46.302494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c8e4809c-a22f-4deb-98df-016677da7bb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095d17d0>]}
[0m02:07:46.307654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c8e4809c-a22f-4deb-98df-016677da7bb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab155d0>]}
[0m02:07:46.308063 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:07:46.308230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c8e4809c-a22f-4deb-98df-016677da7bb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0f1b90>]}
[0m02:07:46.308937 [info ] [MainThread]: 
[0m02:07:46.309379 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:07:46.309962 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:07:46.317882 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:07:46.318083 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:07:46.318228 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:07:46.318823 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:07:46.318978 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:07:46.804570 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:46.806103 [debug] [ThreadPool]: On list_dev: Close
[0m02:07:46.807710 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public)
[0m02:07:46.813637 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:07:46.813919 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:07:46.814128 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:07:46.814471 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:07:46.814694 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:07:47.169528 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:47.170065 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:07:47.170394 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:07:47.260744 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:47.262514 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:07:47.343339 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:07:47.352844 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:47.353259 [debug] [MainThread]: On master: BEGIN
[0m02:07:47.353484 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:07:47.353844 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:07:47.354078 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:07:47.717759 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:47.718340 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:47.718764 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:07:47.843258 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:47.846768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c8e4809c-a22f-4deb-98df-016677da7bb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7bf450>]}
[0m02:07:47.848222 [debug] [MainThread]: On master: ROLLBACK
[0m02:07:47.945659 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:47.946977 [debug] [MainThread]: On master: BEGIN
[0m02:07:47.986286 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:47.987749 [debug] [MainThread]: On master: COMMIT
[0m02:07:47.988898 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:47.989721 [debug] [MainThread]: On master: COMMIT
[0m02:07:48.068393 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:48.069542 [debug] [MainThread]: On master: Close
[0m02:07:48.071806 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:07:48.072924 [info ] [MainThread]: 
[0m02:07:48.077196 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:07:48.078111 [info ] [Thread-1 (]: 1 of 1 START sql table model public.stg_starlink_sattelite ..................... [RUN]
[0m02:07:48.079240 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:07:48.079800 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:07:48.084980 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:48.086280 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:07:48.080151 => 02:07:48.085987
[0m02:07:48.086835 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:07:48.131494 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:48.133939 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:48.134193 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:07:48.134407 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:07:48.134724 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:07:48.134946 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:07:48.492600 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:48.493739 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:48.494849 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public"."stg_starlink_sattelite__dbt_tmp"
    
    
    
  as (
    

with source as (
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date
from "dev"."raw"."starlink_satellites" s
),

max_ingested as (
    select
        object_id,
        max(export_date) as last_ingested_date
    from source
    group  by 1)

select
    src.*,
    -- case when m.last_ingested_date != src.export_date then true else false end as deleted_flag,
    row_number() over (partition by src.object_id order by src.export_date desc) as rnk
from source src

-- left join max_ingested m
-- on m.object_id = src.object_id
  );
[0m02:07:54.929469 [debug] [Thread-1 (]: SQL status: SUCCESS in 6.0 seconds
[0m02:07:54.942528 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:54.943274 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public"."stg_starlink_sattelite" rename to "stg_starlink_sattelite__dbt_backup"
[0m02:07:55.133366 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:55.136855 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:55.137271 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m02:07:55.249929 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:55.267116 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:07:55.267538 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:55.267780 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:07:57.099682 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m02:07:57.101708 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:57.102840 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:07:57.179959 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:57.197772 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:57.198440 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "dev"."public"."stg_starlink_sattelite__dbt_backup" cascade
[0m02:07:57.275014 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:57.278633 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:07:57.279868 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:57.280984 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:07:58.123245 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:07:58.123893 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:07:58.124205 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:07:58.162649 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:58.163606 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:07:48.087125 => 02:07:58.163445
[0m02:07:58.163907 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:07:58.237938 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:07:58.239101 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8e4809c-a22f-4deb-98df-016677da7bb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b02ea10>]}
[0m02:07:58.239681 [info ] [Thread-1 (]: 1 of 1 OK created sql table model public.stg_starlink_sattelite ................ [[32mSUCCESS[0m in 10.16s]
[0m02:07:58.240113 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:07:58.241966 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:58.242228 [debug] [MainThread]: On master: BEGIN
[0m02:07:58.242420 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:07:58.242774 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:07:58.242990 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:07:58.592746 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:58.594058 [debug] [MainThread]: On master: COMMIT
[0m02:07:58.595316 [debug] [MainThread]: Using redshift connection "master"
[0m02:07:58.596195 [debug] [MainThread]: On master: COMMIT
[0m02:07:58.673629 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:07:58.675550 [debug] [MainThread]: On master: Close
[0m02:07:58.677820 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:07:58.678648 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:07:58.679714 [info ] [MainThread]: 
[0m02:07:58.680602 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 12.37 seconds (12.37s).
[0m02:07:58.681945 [debug] [MainThread]: Command end result
[0m02:07:58.701825 [info ] [MainThread]: 
[0m02:07:58.702433 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:07:58.703085 [info ] [MainThread]: 
[0m02:07:58.703630 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m02:07:58.704506 [debug] [MainThread]: Command `dbt run` succeeded at 02:07:58.704348 after 12.55 seconds
[0m02:07:58.704986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3db590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104feddd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095d1050>]}
[0m02:07:58.705442 [debug] [MainThread]: Flushing usage events
[0m02:08:06.495439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109638bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109cd7990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098f8050>]}


============================== 02:08:06.497721 | 61b8dabd-de47-4b5c-ae38-8c4800d81f86 ==============================
[0m02:08:06.497721 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:08:06.498026 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:08:06.573928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '61b8dabd-de47-4b5c-ae38-8c4800d81f86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096e0d90>]}
[0m02:08:06.578160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '61b8dabd-de47-4b5c-ae38-8c4800d81f86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a29950>]}
[0m02:08:06.578483 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:08:06.584563 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:08:06.599641 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:08:06.599971 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:08:06.628700 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:08:06.631481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '61b8dabd-de47-4b5c-ae38-8c4800d81f86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ed0fd0>]}
[0m02:08:06.636614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '61b8dabd-de47-4b5c-ae38-8c4800d81f86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10abbf950>]}
[0m02:08:06.636987 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:08:06.637178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '61b8dabd-de47-4b5c-ae38-8c4800d81f86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b19dd50>]}
[0m02:08:06.638152 [info ] [MainThread]: 
[0m02:08:06.638657 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:08:06.639226 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:08:06.647374 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:08:06.647591 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:08:06.647733 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:08:06.648401 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:08:06.648554 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:08:07.096942 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:08:07.101613 [debug] [ThreadPool]: On list_dev: Close
[0m02:08:07.105369 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public)
[0m02:08:07.116784 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:08:07.117257 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:08:07.117575 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:08:07.118112 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:08:07.118483 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:08:07.493984 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:08:07.495320 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:08:07.496490 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:08:07.588189 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:08:07.592288 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:08:07.675180 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:08:07.694455 [debug] [MainThread]: Using redshift connection "master"
[0m02:08:07.695028 [debug] [MainThread]: On master: BEGIN
[0m02:08:07.695416 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:08:07.695966 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:08:07.696327 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:08:08.068021 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:08:08.069418 [debug] [MainThread]: Using redshift connection "master"
[0m02:08:08.070732 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:08:08.195624 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:08:08.199899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '61b8dabd-de47-4b5c-ae38-8c4800d81f86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096336d0>]}
[0m02:08:08.201536 [debug] [MainThread]: On master: ROLLBACK
[0m02:08:08.296366 [debug] [MainThread]: Using redshift connection "master"
[0m02:08:08.297775 [debug] [MainThread]: On master: BEGIN
[0m02:08:08.337281 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:08:08.338799 [debug] [MainThread]: On master: COMMIT
[0m02:08:08.340097 [debug] [MainThread]: Using redshift connection "master"
[0m02:08:08.341226 [debug] [MainThread]: On master: COMMIT
[0m02:08:08.419147 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:08:08.420637 [debug] [MainThread]: On master: Close
[0m02:08:08.423427 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:08:08.424589 [info ] [MainThread]: 
[0m02:08:08.430453 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:08:08.431265 [info ] [Thread-1 (]: 1 of 1 START sql table model public.stg_starlink_sattelite ..................... [RUN]
[0m02:08:08.432536 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:08:08.433228 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:08:08.437286 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:08:08.437963 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:08:08.433624 => 02:08:08.437815
[0m02:08:08.438214 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:08:08.480497 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:08:08.483275 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:08:08.483539 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:08:08.483759 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:08:08.484109 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:08:08.484352 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:08:08.843510 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:08:08.844775 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:08:08.846320 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public"."stg_starlink_sattelite__dbt_tmp"
    
    
    
  as (
    

with source as (
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date
from "dev"."raw"."starlink_satellites" s
),

max_ingested as (
    select
        object_id,
        max(export_date) as last_ingested_date
    from source
    group  by 1)

select
    src.*,
    case when m.last_ingested_date != src.export_date then true else false end as deleted_flag,
    row_number() over (partition by src.object_id order by src.export_date desc) as rnk
from source src

left join max_ingested m
on m.object_id = src.object_id
  );
[0m02:08:09.131471 [debug] [Thread-1 (]: Redshift adapter: Redshift error: Spectrum nested query error
[0m02:08:09.132897 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:08:09.211987 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:08:08.438364 => 02:08:09.211131
[0m02:08:09.213479 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:08:09.224727 [debug] [Thread-1 (]: Database Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)
  Spectrum nested query error
  compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:08:09.225549 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '61b8dabd-de47-4b5c-ae38-8c4800d81f86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10abd9010>]}
[0m02:08:09.226374 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public.stg_starlink_sattelite ............ [[31mERROR[0m in 0.79s]
[0m02:08:09.227176 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:08:09.230167 [debug] [MainThread]: Using redshift connection "master"
[0m02:08:09.230696 [debug] [MainThread]: On master: BEGIN
[0m02:08:09.231092 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:08:09.231694 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:08:09.232119 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:08:09.593433 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:08:09.594766 [debug] [MainThread]: On master: COMMIT
[0m02:08:09.595972 [debug] [MainThread]: Using redshift connection "master"
[0m02:08:09.597132 [debug] [MainThread]: On master: COMMIT
[0m02:08:09.673781 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:08:09.675158 [debug] [MainThread]: On master: Close
[0m02:08:09.677469 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:08:09.678365 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:08:09.679029 [info ] [MainThread]: 
[0m02:08:09.680164 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 3.04 seconds (3.04s).
[0m02:08:09.681564 [debug] [MainThread]: Command end result
[0m02:08:09.697482 [info ] [MainThread]: 
[0m02:08:09.698015 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m02:08:09.698357 [info ] [MainThread]: 
[0m02:08:09.698687 [error] [MainThread]: [33mDatabase Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)[0m
[0m02:08:09.699042 [error] [MainThread]:   Spectrum nested query error
[0m02:08:09.699504 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:08:09.699865 [info ] [MainThread]: 
[0m02:08:09.700258 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:08:09.700931 [debug] [MainThread]: Command `dbt run` failed at 02:08:09.700818 after 3.22 seconds
[0m02:08:09.701385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109cd77d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a280d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109cdead0>]}
[0m02:08:09.701811 [debug] [MainThread]: Flushing usage events
[0m02:09:17.715643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107776d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064a4290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074e1950>]}


============================== 02:09:17.718045 | f80cf0e0-806c-4403-b3af-ea9357d71b6c ==============================
[0m02:09:17.718045 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:09:17.718367 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:09:17.797173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f80cf0e0-806c-4403-b3af-ea9357d71b6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107818550>]}
[0m02:09:17.801357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f80cf0e0-806c-4403-b3af-ea9357d71b6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107818290>]}
[0m02:09:17.801693 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:09:17.807905 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:09:17.822655 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:09:17.823122 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:09:17.852014 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:09:17.855033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f80cf0e0-806c-4403-b3af-ea9357d71b6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c63510>]}
[0m02:09:17.860423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f80cf0e0-806c-4403-b3af-ea9357d71b6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080a5ad0>]}
[0m02:09:17.860735 [info ] [MainThread]: Found 1 model, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:09:17.860906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f80cf0e0-806c-4403-b3af-ea9357d71b6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086815d0>]}
[0m02:09:17.861646 [info ] [MainThread]: 
[0m02:09:17.862046 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:09:17.862567 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:09:17.870753 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:09:17.871068 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:09:17.871238 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:09:17.872138 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:09:17.872355 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:09:18.368944 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:18.373160 [debug] [ThreadPool]: On list_dev: Close
[0m02:09:18.376805 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public)
[0m02:09:18.387927 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:09:18.388381 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:09:18.388689 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:09:18.389192 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:09:18.389538 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:09:18.770184 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:18.772299 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:09:18.773393 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:09:18.867552 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:18.872115 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:09:18.956561 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:09:18.975797 [debug] [MainThread]: Using redshift connection "master"
[0m02:09:18.976378 [debug] [MainThread]: On master: BEGIN
[0m02:09:18.976770 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:09:18.977359 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:09:18.977707 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:09:19.349767 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:19.350478 [debug] [MainThread]: Using redshift connection "master"
[0m02:09:19.350994 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:09:19.474266 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:19.476924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f80cf0e0-806c-4403-b3af-ea9357d71b6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d24410>]}
[0m02:09:19.477786 [debug] [MainThread]: On master: ROLLBACK
[0m02:09:19.574280 [debug] [MainThread]: Using redshift connection "master"
[0m02:09:19.575535 [debug] [MainThread]: On master: BEGIN
[0m02:09:19.615336 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:19.616543 [debug] [MainThread]: On master: COMMIT
[0m02:09:19.617898 [debug] [MainThread]: Using redshift connection "master"
[0m02:09:19.619058 [debug] [MainThread]: On master: COMMIT
[0m02:09:19.696797 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:19.698018 [debug] [MainThread]: On master: Close
[0m02:09:19.700803 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:09:19.701863 [info ] [MainThread]: 
[0m02:09:19.707332 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:09:19.708290 [info ] [Thread-1 (]: 1 of 1 START sql table model public.stg_starlink_sattelite ..................... [RUN]
[0m02:09:19.709361 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:09:19.709871 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:09:19.714821 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:09:19.716022 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:09:19.710205 => 02:09:19.715732
[0m02:09:19.716530 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:09:19.762283 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:09:19.764746 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:09:19.764991 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:09:19.765204 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:09:19.765537 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:09:19.765776 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:09:20.123516 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:20.124977 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:09:20.126224 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public"."stg_starlink_sattelite__dbt_tmp"
    
    
    
  as (
    

with source as (
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date
from "dev"."raw"."starlink_satellites" s
),

max_ingested as (
    select
        object_id,
        max(export_date) as last_ingested_date
    from source
    group  by 1)

select
    src.*,
    last_ingested_date,
    row_number() over (partition by src.object_id order by src.export_date desc) as rnk
from source src

left join max_ingested m
on m.object_id = src.object_id
  );
[0m02:09:20.412546 [debug] [Thread-1 (]: Redshift adapter: Redshift error: Spectrum nested query error
[0m02:09:20.414167 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:09:20.492641 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:09:19.716851 => 02:09:20.491708
[0m02:09:20.494066 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:09:20.503798 [debug] [Thread-1 (]: Database Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)
  Spectrum nested query error
  compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:09:20.504666 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f80cf0e0-806c-4403-b3af-ea9357d71b6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085b9b10>]}
[0m02:09:20.505527 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public.stg_starlink_sattelite ............ [[31mERROR[0m in 0.80s]
[0m02:09:20.506425 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:09:20.509380 [debug] [MainThread]: Using redshift connection "master"
[0m02:09:20.509852 [debug] [MainThread]: On master: BEGIN
[0m02:09:20.510226 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:09:20.510887 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:09:20.511299 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:09:20.886703 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:20.888429 [debug] [MainThread]: On master: COMMIT
[0m02:09:20.890129 [debug] [MainThread]: Using redshift connection "master"
[0m02:09:20.891335 [debug] [MainThread]: On master: COMMIT
[0m02:09:20.969707 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:20.971511 [debug] [MainThread]: On master: Close
[0m02:09:20.973742 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:09:20.974554 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:09:20.975181 [info ] [MainThread]: 
[0m02:09:20.976005 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 3.11 seconds (3.11s).
[0m02:09:20.977316 [debug] [MainThread]: Command end result
[0m02:09:20.992837 [info ] [MainThread]: 
[0m02:09:20.993354 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m02:09:20.993692 [info ] [MainThread]: 
[0m02:09:20.994193 [error] [MainThread]: [33mDatabase Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)[0m
[0m02:09:20.994566 [error] [MainThread]:   Spectrum nested query error
[0m02:09:20.994908 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m02:09:20.995233 [info ] [MainThread]: 
[0m02:09:20.995593 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m02:09:20.996238 [debug] [MainThread]: Command `dbt run` failed at 02:09:20.996103 after 3.29 seconds
[0m02:09:20.996677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077426d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107781610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10756d410>]}
[0m02:09:20.997094 [debug] [MainThread]: Flushing usage events
[0m02:10:50.181618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a78750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081db390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b309d0>]}


============================== 02:10:50.184523 | 65522498-8192-41d7-b362-983c4b553f3e ==============================
[0m02:10:50.184523 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:10:50.184899 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:10:50.265095 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '65522498-8192-41d7-b362-983c4b553f3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081ec290>]}
[0m02:10:50.269444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '65522498-8192-41d7-b362-983c4b553f3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fdeed0>]}
[0m02:10:50.269812 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:10:50.275313 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:10:50.290207 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m02:10:50.290543 [debug] [MainThread]: Partial parsing: added file: dbt_remote://models/Starlink/dim_starlink_sattelite.sql
[0m02:10:50.290761 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:10:50.322195 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:10:50.324976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '65522498-8192-41d7-b362-983c4b553f3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10986e810>]}
[0m02:10:50.329833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '65522498-8192-41d7-b362-983c4b553f3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097c28d0>]}
[0m02:10:50.330076 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:10:50.330242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '65522498-8192-41d7-b362-983c4b553f3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086cbe10>]}
[0m02:10:50.331008 [info ] [MainThread]: 
[0m02:10:50.331469 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:10:50.332140 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:10:50.340604 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:10:50.340878 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:10:50.341031 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:10:50.341649 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:10:50.341803 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:10:50.837701 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:50.839161 [debug] [ThreadPool]: On list_dev: Close
[0m02:10:50.840731 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public)
[0m02:10:50.847276 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:10:50.847540 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m02:10:50.847746 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:10:50.848079 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:10:50.848300 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:10:51.218736 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:51.220148 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m02:10:51.221639 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:10:51.316378 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:51.321320 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m02:10:51.406089 [debug] [ThreadPool]: On list_dev_public: Close
[0m02:10:51.423971 [debug] [MainThread]: Using redshift connection "master"
[0m02:10:51.424473 [debug] [MainThread]: On master: BEGIN
[0m02:10:51.424787 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:10:51.425287 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:10:51.425622 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:10:51.814615 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:51.815475 [debug] [MainThread]: Using redshift connection "master"
[0m02:10:51.816247 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:10:51.947834 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:51.951200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '65522498-8192-41d7-b362-983c4b553f3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10986e910>]}
[0m02:10:51.952446 [debug] [MainThread]: On master: ROLLBACK
[0m02:10:52.054528 [debug] [MainThread]: Using redshift connection "master"
[0m02:10:52.055456 [debug] [MainThread]: On master: BEGIN
[0m02:10:52.096192 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:52.097673 [debug] [MainThread]: On master: COMMIT
[0m02:10:52.099563 [debug] [MainThread]: Using redshift connection "master"
[0m02:10:52.100600 [debug] [MainThread]: On master: COMMIT
[0m02:10:52.182895 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:52.184311 [debug] [MainThread]: On master: Close
[0m02:10:52.187174 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:10:52.188374 [info ] [MainThread]: 
[0m02:10:52.194162 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:10:52.195036 [info ] [Thread-1 (]: 1 of 1 START sql table model public.stg_starlink_sattelite ..................... [RUN]
[0m02:10:52.196225 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:10:52.196897 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:10:52.202433 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:10:52.203684 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:10:52.197309 => 02:10:52.203379
[0m02:10:52.204165 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:10:52.248755 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:10:52.250779 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:10:52.251033 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:10:52.251255 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:10:52.251621 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:10:52.251864 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:10:52.620377 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:52.621689 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:10:52.622619 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public"."stg_starlink_sattelite__dbt_tmp"
    
    
    
  as (
    

    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s
  );
[0m02:10:54.534384 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m02:10:54.548745 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:10:54.549475 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public"."stg_starlink_sattelite" rename to "stg_starlink_sattelite__dbt_backup"
[0m02:10:54.749372 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:54.758282 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:10:54.758974 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m02:10:54.878748 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:54.911573 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:10:54.912147 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:10:54.912484 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:10:56.833737 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m02:10:56.836263 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:10:56.837682 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:10:56.918271 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:56.935918 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:10:56.936586 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "dev"."public"."stg_starlink_sattelite__dbt_backup" cascade
[0m02:10:57.017429 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:57.020390 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:10:57.021797 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:10:57.022562 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:10:58.020967 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:10:58.022391 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:10:58.023186 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:10:58.064387 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:58.068283 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:10:52.204441 => 02:10:58.067739
[0m02:10:58.069577 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:10:58.149243 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:10:58.152667 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65522498-8192-41d7-b362-983c4b553f3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f64a90>]}
[0m02:10:58.154551 [info ] [Thread-1 (]: 1 of 1 OK created sql table model public.stg_starlink_sattelite ................ [[32mSUCCESS[0m in 5.96s]
[0m02:10:58.155911 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:10:58.159467 [debug] [MainThread]: Using redshift connection "master"
[0m02:10:58.160043 [debug] [MainThread]: On master: BEGIN
[0m02:10:58.160458 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:10:58.161133 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:10:58.161607 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:10:58.535156 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:58.536231 [debug] [MainThread]: On master: COMMIT
[0m02:10:58.537123 [debug] [MainThread]: Using redshift connection "master"
[0m02:10:58.538140 [debug] [MainThread]: On master: COMMIT
[0m02:10:58.616523 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:58.617509 [debug] [MainThread]: On master: Close
[0m02:10:58.619747 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:10:58.620673 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:10:58.621345 [info ] [MainThread]: 
[0m02:10:58.622010 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 8.29 seconds (8.29s).
[0m02:10:58.623344 [debug] [MainThread]: Command end result
[0m02:10:58.642593 [info ] [MainThread]: 
[0m02:10:58.643229 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:10:58.643694 [info ] [MainThread]: 
[0m02:10:58.644087 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m02:10:58.644789 [debug] [MainThread]: Command `dbt run` succeeded at 02:10:58.644651 after 8.47 seconds
[0m02:10:58.645235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108175590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081db750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102919e50>]}
[0m02:10:58.645630 [debug] [MainThread]: Flushing usage events
[0m02:14:53.404641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d13990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120eccd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120ed390>]}


============================== 02:14:53.407573 | 003e6e71-cdba-458c-b267-f85e6f625788 ==============================
[0m02:14:53.407573 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:14:53.407885 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:14:53.498019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '003e6e71-cdba-458c-b267-f85e6f625788', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a54450>]}
[0m02:14:53.502141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '003e6e71-cdba-458c-b267-f85e6f625788', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120e3dd0>]}
[0m02:14:53.502671 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:14:53.509289 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:14:53.528607 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m02:14:53.528972 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:14:53.529163 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/dim_starlink_sattelite.sql
[0m02:14:53.540846 [error] [MainThread]: Encountered an error:
Compilation Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)
  unexpected ']', expected ')'
    line 5
      ]) }}
[0m02:14:53.541358 [debug] [MainThread]: Command `dbt run` failed at 02:14:53.541279 after 0.15 seconds
[0m02:14:53.541606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a24450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a24590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a25490>]}
[0m02:14:53.541853 [debug] [MainThread]: Flushing usage events
[0m02:15:36.001951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077a8cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076e5f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079aff90>]}


============================== 02:15:36.004325 | 28799778-6a93-4009-a892-4f888fd38243 ==============================
[0m02:15:36.004325 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:15:36.004649 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:15:36.080807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '28799778-6a93-4009-a892-4f888fd38243', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c602d0>]}
[0m02:15:36.084948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '28799778-6a93-4009-a892-4f888fd38243', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107406910>]}
[0m02:15:36.085279 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:15:36.091265 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:15:36.105585 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m02:15:36.105962 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:15:36.106155 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/dim_starlink_sattelite.sql
[0m02:15:36.115132 [error] [MainThread]: Encountered an error:
Compilation Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)
  unexpected ']', expected ')'
    line 5
      ]) }}
[0m02:15:36.115508 [debug] [MainThread]: Command `dbt run` failed at 02:15:36.115412 after 0.12 seconds
[0m02:15:36.115745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079a2f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079a0550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079a19d0>]}
[0m02:15:36.115931 [debug] [MainThread]: Flushing usage events
[0m02:16:01.628250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105028ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10522ffd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10522ff90>]}


============================== 02:16:01.631044 | f4612840-e19e-43fd-a74e-18e3c116d347 ==============================
[0m02:16:01.631044 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:16:01.631368 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/Users/annaantypenko/.dbt', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run -s stg_starlink_sattelite', 'send_anonymous_usage_stats': 'True'}
[0m02:16:01.728112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f4612840-e19e-43fd-a74e-18e3c116d347', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f09150>]}
[0m02:16:01.732365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f4612840-e19e-43fd-a74e-18e3c116d347', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054c7ed0>]}
[0m02:16:01.732950 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:16:01.740296 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:16:01.759785 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m02:16:01.760173 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:16:01.760363 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/dim_starlink_sattelite.sql
[0m02:16:01.793771 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:16:01.796463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f4612840-e19e-43fd-a74e-18e3c116d347', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f64490>]}
[0m02:16:01.802586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f4612840-e19e-43fd-a74e-18e3c116d347', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105858c50>]}
[0m02:16:01.802905 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:16:01.803086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f4612840-e19e-43fd-a74e-18e3c116d347', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102179d50>]}
[0m02:16:01.804007 [info ] [MainThread]: 
[0m02:16:01.804723 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:16:01.805403 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:16:01.813480 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:16:01.813689 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:16:01.813833 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:16:01.814395 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:16:01.814548 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:16:02.361285 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:16:02.366021 [debug] [ThreadPool]: On list_dev: Close
[0m02:16:02.369370 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now create_dev_public_staging)
[0m02:16:02.370842 [debug] [ThreadPool]: Creating schema "database: "dev"
schema: "public_staging"
"
[0m02:16:02.380656 [debug] [ThreadPool]: Using redshift connection "create_dev_public_staging"
[0m02:16:02.381221 [debug] [ThreadPool]: On create_dev_public_staging: BEGIN
[0m02:16:02.381551 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:16:02.382172 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:16:02.382513 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:16:02.768431 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:02.769340 [debug] [ThreadPool]: Using redshift connection "create_dev_public_staging"
[0m02:16:02.769987 [debug] [ThreadPool]: On create_dev_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "create_dev_public_staging"} */
create schema if not exists "public_staging"
[0m02:16:02.927455 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:02.930542 [debug] [ThreadPool]: On create_dev_public_staging: COMMIT
[0m02:16:02.931781 [debug] [ThreadPool]: Using redshift connection "create_dev_public_staging"
[0m02:16:02.932589 [debug] [ThreadPool]: On create_dev_public_staging: COMMIT
[0m02:16:04.052131 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:16:04.053779 [debug] [ThreadPool]: On create_dev_public_staging: Close
[0m02:16:04.058662 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_dev_public_staging, now list_dev_public_staging)
[0m02:16:04.060131 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public_public'
[0m02:16:04.076055 [debug] [ThreadPool]: Using redshift connection "list_dev_public_staging"
[0m02:16:04.080423 [debug] [ThreadPool]: Using redshift connection "list_dev_public_public"
[0m02:16:04.080794 [debug] [ThreadPool]: On list_dev_public_staging: BEGIN
[0m02:16:04.081111 [debug] [ThreadPool]: On list_dev_public_public: BEGIN
[0m02:16:04.081408 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:16:04.081697 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:16:04.082184 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:16:04.082629 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:16:04.082960 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:16:04.083284 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:16:04.467293 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:04.468064 [debug] [ThreadPool]: Using redshift connection "list_dev_public_staging"
[0m02:16:04.468790 [debug] [ThreadPool]: On list_dev_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_staging'
[0m02:16:04.469275 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:04.469982 [debug] [ThreadPool]: Using redshift connection "list_dev_public_public"
[0m02:16:04.470489 [debug] [ThreadPool]: On list_dev_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_public'
[0m02:16:04.565231 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:04.566994 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:04.569970 [debug] [ThreadPool]: On list_dev_public_staging: ROLLBACK
[0m02:16:04.572704 [debug] [ThreadPool]: On list_dev_public_public: ROLLBACK
[0m02:16:04.650480 [debug] [ThreadPool]: On list_dev_public_public: Close
[0m02:16:04.652444 [debug] [ThreadPool]: On list_dev_public_staging: Close
[0m02:16:04.660320 [debug] [MainThread]: Using redshift connection "master"
[0m02:16:04.660675 [debug] [MainThread]: On master: BEGIN
[0m02:16:04.661066 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:16:04.661441 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:16:04.661690 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:16:05.034627 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:05.035803 [debug] [MainThread]: Using redshift connection "master"
[0m02:16:05.037041 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:16:05.165467 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:05.169424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f4612840-e19e-43fd-a74e-18e3c116d347', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f09290>]}
[0m02:16:05.170755 [debug] [MainThread]: On master: ROLLBACK
[0m02:16:05.270471 [debug] [MainThread]: Using redshift connection "master"
[0m02:16:05.271100 [debug] [MainThread]: On master: BEGIN
[0m02:16:05.310754 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:05.312071 [debug] [MainThread]: On master: COMMIT
[0m02:16:05.313472 [debug] [MainThread]: Using redshift connection "master"
[0m02:16:05.314602 [debug] [MainThread]: On master: COMMIT
[0m02:16:05.394939 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:05.396415 [debug] [MainThread]: On master: Close
[0m02:16:05.399257 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:16:05.400524 [info ] [MainThread]: 
[0m02:16:05.405772 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:16:05.406678 [info ] [Thread-1 (]: 1 of 1 START sql table model public_staging.stg_starlink_sattelite ............. [RUN]
[0m02:16:05.407716 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public_staging, now model.dbt_remote.stg_starlink_sattelite)
[0m02:16:05.408217 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:16:05.413600 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:05.414756 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:16:05.408546 => 02:16:05.414478
[0m02:16:05.415299 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:16:05.460622 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:05.462677 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:05.462933 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:16:05.463157 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:16:05.463500 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:16:05.463739 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:16:05.829482 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:05.831297 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:05.832846 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public_staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s
  );
[0m02:16:16.527826 [debug] [Thread-1 (]: SQL status: SUCCESS in 11.0 seconds
[0m02:16:16.542059 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:16.542773 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public_staging"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m02:16:16.738878 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:16.768807 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:16:16.769390 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:16.769764 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:16:17.715558 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:16:17.717983 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:17.719279 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:16:17.800196 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:17.821107 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:17.821645 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "dev"."public_staging"."stg_starlink_sattelite__dbt_backup" cascade
[0m02:16:17.899831 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:17.902196 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:16:17.903240 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:17.903856 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:16:17.948868 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:17.951190 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:17.952770 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:16:17.991949 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:17.994831 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:16:05.415774 => 02:16:17.994383
[0m02:16:17.995652 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:16:18.073717 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:16:18.076511 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4612840-e19e-43fd-a74e-18e3c116d347', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10586f990>]}
[0m02:16:18.078128 [info ] [Thread-1 (]: 1 of 1 OK created sql table model public_staging.stg_starlink_sattelite ........ [[32mSUCCESS[0m in 12.67s]
[0m02:16:18.079810 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:16:18.084301 [debug] [MainThread]: Using redshift connection "master"
[0m02:16:18.084813 [debug] [MainThread]: On master: BEGIN
[0m02:16:18.085210 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:16:18.085830 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:16:18.086239 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:16:18.468087 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:18.469526 [debug] [MainThread]: On master: COMMIT
[0m02:16:18.471005 [debug] [MainThread]: Using redshift connection "master"
[0m02:16:18.472058 [debug] [MainThread]: On master: COMMIT
[0m02:16:18.551084 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:18.551949 [debug] [MainThread]: On master: Close
[0m02:16:18.554027 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:16:18.554898 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:16:18.555460 [debug] [MainThread]: Connection 'list_dev_public_public' was properly closed.
[0m02:16:18.556147 [info ] [MainThread]: 
[0m02:16:18.557270 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 16.75 seconds (16.75s).
[0m02:16:18.559020 [debug] [MainThread]: Command end result
[0m02:16:18.573942 [info ] [MainThread]: 
[0m02:16:18.574589 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:16:18.574955 [info ] [MainThread]: 
[0m02:16:18.575630 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m02:16:18.576412 [debug] [MainThread]: Command `dbt run` succeeded at 02:16:18.576281 after 16.96 seconds
[0m02:16:18.576868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10470e3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c8c890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c8d6d0>]}
[0m02:16:18.577305 [debug] [MainThread]: Flushing usage events
[0m02:16:38.170443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105075190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10709e510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050751d0>]}


============================== 02:16:38.172804 | eca010d1-97ea-488b-a11b-5c9bebb8a4e2 ==============================
[0m02:16:38.172804 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:16:38.173116 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run -s stg_starlink_sattelite+', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:16:38.249240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eca010d1-97ea-488b-a11b-5c9bebb8a4e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107398a10>]}
[0m02:16:38.253376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eca010d1-97ea-488b-a11b-5c9bebb8a4e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107587f50>]}
[0m02:16:38.253694 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:16:38.259475 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:16:38.273959 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:16:38.274224 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:16:38.274558 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:16:38.277794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eca010d1-97ea-488b-a11b-5c9bebb8a4e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10759e710>]}
[0m02:16:38.282618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eca010d1-97ea-488b-a11b-5c9bebb8a4e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107671710>]}
[0m02:16:38.282878 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 397 macros, 0 groups, 0 semantic models
[0m02:16:38.283052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eca010d1-97ea-488b-a11b-5c9bebb8a4e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107167010>]}
[0m02:16:38.283898 [info ] [MainThread]: 
[0m02:16:38.284322 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:16:38.284928 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:16:38.285367 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:16:38.294165 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:16:38.295416 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:16:38.295640 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:16:38.295783 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:16:38.295922 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:16:38.296049 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:16:38.296540 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:16:38.296728 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:16:38.296872 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:16:38.297002 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:16:38.759713 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:38.760678 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:38.764249 [debug] [ThreadPool]: On list_dev: Close
[0m02:16:38.767120 [debug] [ThreadPool]: On list_dev: Close
[0m02:16:38.770298 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now create_dev_public_public)
[0m02:16:38.771394 [debug] [ThreadPool]: Creating schema "database: "dev"
schema: "public_public"
"
[0m02:16:38.780781 [debug] [ThreadPool]: Using redshift connection "create_dev_public_public"
[0m02:16:38.781177 [debug] [ThreadPool]: On create_dev_public_public: BEGIN
[0m02:16:38.781495 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:16:38.782014 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:16:38.782358 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:16:39.164156 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:39.165782 [debug] [ThreadPool]: Using redshift connection "create_dev_public_public"
[0m02:16:39.166989 [debug] [ThreadPool]: On create_dev_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "create_dev_public_public"} */
create schema if not exists "public_public"
[0m02:16:39.321641 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:39.324749 [debug] [ThreadPool]: On create_dev_public_public: COMMIT
[0m02:16:39.325897 [debug] [ThreadPool]: Using redshift connection "create_dev_public_public"
[0m02:16:39.326485 [debug] [ThreadPool]: On create_dev_public_public: COMMIT
[0m02:16:40.282679 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:16:40.283750 [debug] [ThreadPool]: On create_dev_public_public: Close
[0m02:16:40.287731 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public_public)
[0m02:16:40.289203 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_dev_public_public, now list_dev_public_staging)
[0m02:16:40.300281 [debug] [ThreadPool]: Using redshift connection "list_dev_public_public"
[0m02:16:40.311043 [debug] [ThreadPool]: Using redshift connection "list_dev_public_staging"
[0m02:16:40.311427 [debug] [ThreadPool]: On list_dev_public_public: BEGIN
[0m02:16:40.311719 [debug] [ThreadPool]: On list_dev_public_staging: BEGIN
[0m02:16:40.311988 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:16:40.312249 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:16:40.312704 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:16:40.313087 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:16:40.313374 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:16:40.313644 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:16:40.689403 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:40.689851 [debug] [ThreadPool]: Using redshift connection "list_dev_public_public"
[0m02:16:40.690124 [debug] [ThreadPool]: On list_dev_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_public'
[0m02:16:40.691214 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:40.691429 [debug] [ThreadPool]: Using redshift connection "list_dev_public_staging"
[0m02:16:40.691659 [debug] [ThreadPool]: On list_dev_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_staging'
[0m02:16:40.781061 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:40.782586 [debug] [ThreadPool]: On list_dev_public_public: ROLLBACK
[0m02:16:40.783001 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:40.784178 [debug] [ThreadPool]: On list_dev_public_staging: ROLLBACK
[0m02:16:40.862104 [debug] [ThreadPool]: On list_dev_public_public: Close
[0m02:16:40.863014 [debug] [ThreadPool]: On list_dev_public_staging: Close
[0m02:16:40.878128 [debug] [MainThread]: Using redshift connection "master"
[0m02:16:40.878634 [debug] [MainThread]: On master: BEGIN
[0m02:16:40.879012 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:16:40.879597 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:16:40.880007 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:16:41.300624 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:41.302181 [debug] [MainThread]: Using redshift connection "master"
[0m02:16:41.302783 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:16:41.428894 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:41.431440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eca010d1-97ea-488b-a11b-5c9bebb8a4e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e6a050>]}
[0m02:16:41.432463 [debug] [MainThread]: On master: ROLLBACK
[0m02:16:41.530509 [debug] [MainThread]: Using redshift connection "master"
[0m02:16:41.531088 [debug] [MainThread]: On master: BEGIN
[0m02:16:41.570208 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:41.571201 [debug] [MainThread]: On master: COMMIT
[0m02:16:41.572114 [debug] [MainThread]: Using redshift connection "master"
[0m02:16:41.572725 [debug] [MainThread]: On master: COMMIT
[0m02:16:41.651023 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:41.652094 [debug] [MainThread]: On master: Close
[0m02:16:41.653933 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:16:41.655011 [info ] [MainThread]: 
[0m02:16:41.661610 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:16:41.662650 [info ] [Thread-1 (]: 1 of 2 START sql table model public_staging.stg_starlink_sattelite ............. [RUN]
[0m02:16:41.663747 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:16:41.664268 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:16:41.669744 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:41.670896 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:16:41.664602 => 02:16:41.670609
[0m02:16:41.671420 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:16:41.717477 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:41.719388 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:41.719641 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:16:41.719864 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:16:41.720236 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:16:41.720479 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:16:42.082587 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:42.083469 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:42.084102 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public_staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s
  );
[0m02:16:43.766451 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m02:16:43.781278 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:43.782106 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public_staging"."stg_starlink_sattelite" rename to "stg_starlink_sattelite__dbt_backup"
[0m02:16:43.974942 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:43.984488 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:43.985890 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public_staging"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m02:16:44.102083 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:44.143501 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:16:44.144246 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:44.144668 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:16:44.988833 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:16:44.990534 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:44.991456 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:16:45.070021 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:45.090672 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:45.091810 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "dev"."public_staging"."stg_starlink_sattelite__dbt_backup" cascade
[0m02:16:45.172319 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:45.174641 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:16:45.175651 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:45.176313 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:16:46.073416 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:16:46.074481 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:16:46.074958 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:16:46.113435 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:46.115906 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:16:41.671748 => 02:16:46.115451
[0m02:16:46.116985 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:16:46.195166 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:16:46.197172 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eca010d1-97ea-488b-a11b-5c9bebb8a4e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079c87d0>]}
[0m02:16:46.198791 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_staging.stg_starlink_sattelite ........ [[32mSUCCESS[0m in 4.53s]
[0m02:16:46.199979 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:16:46.202907 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m02:16:46.204024 [info ] [Thread-3 (]: 2 of 2 START sql table model public_public.dim_starlink_sattelite .............. [RUN]
[0m02:16:46.206141 [debug] [Thread-3 (]: Acquiring new redshift connection 'model.dbt_remote.dim_starlink_sattelite'
[0m02:16:46.207086 [debug] [Thread-3 (]: Began compiling node model.dbt_remote.dim_starlink_sattelite
[0m02:16:46.222496 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (compile): 02:16:46.207495 => 02:16:46.222161
[0m02:16:46.228060 [debug] [Thread-3 (]: Compilation Error in model dim_starlink_sattelite (models/Starlink/dim_starlink_sattelite.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m02:16:46.228668 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eca010d1-97ea-488b-a11b-5c9bebb8a4e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108093210>]}
[0m02:16:46.229264 [error] [Thread-3 (]: 2 of 2 ERROR creating sql table model public_public.dim_starlink_sattelite ..... [[31mERROR[0m in 0.02s]
[0m02:16:46.229801 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m02:16:46.232014 [debug] [MainThread]: Using redshift connection "master"
[0m02:16:46.232366 [debug] [MainThread]: On master: BEGIN
[0m02:16:46.232644 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:16:46.233091 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:16:46.233408 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:16:46.606246 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:46.607138 [debug] [MainThread]: On master: COMMIT
[0m02:16:46.607824 [debug] [MainThread]: Using redshift connection "master"
[0m02:16:46.608240 [debug] [MainThread]: On master: COMMIT
[0m02:16:46.685137 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:16:46.685906 [debug] [MainThread]: On master: Close
[0m02:16:46.687600 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:16:46.689173 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:16:46.689905 [debug] [MainThread]: Connection 'list_dev_public_staging' was properly closed.
[0m02:16:46.690346 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_sattelite' was properly closed.
[0m02:16:46.690853 [info ] [MainThread]: 
[0m02:16:46.691730 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 8.41 seconds (8.41s).
[0m02:16:46.693276 [debug] [MainThread]: Command end result
[0m02:16:46.709490 [info ] [MainThread]: 
[0m02:16:46.709833 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m02:16:46.710038 [info ] [MainThread]: 
[0m02:16:46.710248 [error] [MainThread]: [33mCompilation Error in model dim_starlink_sattelite (models/Starlink/dim_starlink_sattelite.sql)[0m
[0m02:16:46.710460 [error] [MainThread]:   'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m02:16:46.710670 [info ] [MainThread]: 
[0m02:16:46.710935 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
[0m02:16:46.711481 [debug] [MainThread]: Command `dbt run` failed at 02:16:46.711397 after 8.55 seconds
[0m02:16:46.711791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dbb210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102b4cad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dcdf90>]}
[0m02:16:46.712074 [debug] [MainThread]: Flushing usage events
[0m02:18:55.061262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10417c990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054ea310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034514d0>]}


============================== 02:18:55.064368 | a335c841-d249-4f8e-886d-8db85b9e4223 ==============================
[0m02:18:55.064368 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:18:55.064780 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'version_check': 'True', 'profiles_dir': '/Users/annaantypenko/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:18:55.087892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a335c841-d249-4f8e-886d-8db85b9e4223', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10574cb50>]}
[0m02:18:55.088412 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:18:55.088803 [debug] [MainThread]: Command `dbt deps` succeeded at 02:18:55.088723 after 0.04 seconds
[0m02:18:55.089021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10544fc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10541a8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105542d10>]}
[0m02:18:55.089220 [debug] [MainThread]: Flushing usage events
[0m02:19:29.245141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b3a890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3309d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0e6450>]}


============================== 02:19:29.248728 | ab621c28-bce4-4070-9ef8-f3347b48b478 ==============================
[0m02:19:29.248728 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:19:29.249104 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt deps', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:19:29.265826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ab621c28-bce4-4070-9ef8-f3347b48b478', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a61bcd0>]}
[0m02:19:29.266279 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:19:29.266667 [debug] [MainThread]: Command `dbt deps` succeeded at 02:19:29.266583 after 0.03 seconds
[0m02:19:29.266887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3f3890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a347110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a347b50>]}
[0m02:19:29.267085 [debug] [MainThread]: Flushing usage events
[0m02:19:48.115407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ef7210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109015f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092e3b10>]}


============================== 02:19:48.117776 | dfb121bb-4e8e-4bcf-b190-7ca152148184 ==============================
[0m02:19:48.117776 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:19:48.118126 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:19:48.134523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dfb121bb-4e8e-4bcf-b190-7ca152148184', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092da490>]}
[0m02:19:48.135525 [debug] [MainThread]: Set downloads directory='/var/folders/mq/g3w56qvd2qjdkn68h0xg37nr0000gn/T/dbt-downloads-2j_qd7ln'
[0m02:19:48.135802 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m02:19:48.338229 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m02:19:48.340199 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m02:19:48.484549 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m02:19:48.498952 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m02:19:48.954557 [info ] [MainThread]: Installed from version 1.1.1
[0m02:19:48.954871 [info ] [MainThread]: Up to date!
[0m02:19:48.955169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'dfb121bb-4e8e-4bcf-b190-7ca152148184', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c24790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ef7550>]}
[0m02:19:48.956347 [debug] [MainThread]: Command `dbt deps` succeeded at 02:19:48.956251 after 0.85 seconds
[0m02:19:48.956612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bf3790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c3e6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ce12d0>]}
[0m02:19:48.957071 [debug] [MainThread]: Flushing usage events
[0m02:19:58.641414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bfd390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106edce50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071a7c10>]}


============================== 02:19:58.643805 | d70edd21-8a56-4bc9-8431-fdd6c50ab2cf ==============================
[0m02:19:58.643805 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:19:58.644122 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run -s stg_starlink_sattelite+', 'send_anonymous_usage_stats': 'True'}
[0m02:19:58.739972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd70edd21-8a56-4bc9-8431-fdd6c50ab2cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fa0b10>]}
[0m02:19:58.744229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd70edd21-8a56-4bc9-8431-fdd6c50ab2cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10744b850>]}
[0m02:19:58.744700 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:19:58.753431 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:19:58.758993 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m02:19:58.759230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd70edd21-8a56-4bc9-8431-fdd6c50ab2cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10744bfd0>]}
[0m02:19:59.304366 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:19:59.307319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd70edd21-8a56-4bc9-8431-fdd6c50ab2cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074721d0>]}
[0m02:19:59.315111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd70edd21-8a56-4bc9-8431-fdd6c50ab2cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107deac50>]}
[0m02:19:59.315434 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 511 macros, 0 groups, 0 semantic models
[0m02:19:59.315614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd70edd21-8a56-4bc9-8431-fdd6c50ab2cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040f1d90>]}
[0m02:19:59.316421 [info ] [MainThread]: 
[0m02:19:59.316886 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:19:59.317528 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:19:59.325397 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:19:59.325777 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:19:59.325917 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:19:59.327220 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:19:59.327369 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:19:59.327519 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:19:59.328074 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:19:59.328256 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:19:59.328442 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:19:59.328656 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:19:59.329558 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:19:59.870167 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:19:59.871215 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:19:59.875436 [debug] [ThreadPool]: On list_dev: Close
[0m02:19:59.878504 [debug] [ThreadPool]: On list_dev: Close
[0m02:19:59.881720 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now create_dev_public_staging)
[0m02:19:59.882715 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now create_dev_public_public)
[0m02:19:59.884893 [debug] [ThreadPool]: Creating schema "database: "dev"
schema: "public_staging"
"
[0m02:19:59.885807 [debug] [ThreadPool]: Creating schema "database: "dev"
schema: "public_public"
"
[0m02:19:59.894932 [debug] [ThreadPool]: Using redshift connection "create_dev_public_staging"
[0m02:19:59.898024 [debug] [ThreadPool]: Using redshift connection "create_dev_public_public"
[0m02:19:59.898403 [debug] [ThreadPool]: On create_dev_public_staging: BEGIN
[0m02:19:59.898727 [debug] [ThreadPool]: On create_dev_public_public: BEGIN
[0m02:19:59.899024 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:19:59.899325 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:19:59.899846 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:19:59.900314 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:19:59.900659 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:19:59.900951 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:20:00.280896 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:00.281950 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:00.282828 [debug] [ThreadPool]: Using redshift connection "create_dev_public_staging"
[0m02:20:00.283602 [debug] [ThreadPool]: Using redshift connection "create_dev_public_public"
[0m02:20:00.284373 [debug] [ThreadPool]: On create_dev_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "create_dev_public_staging"} */
create schema if not exists "public_staging"
[0m02:20:00.284995 [debug] [ThreadPool]: On create_dev_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "create_dev_public_public"} */
create schema if not exists "public_public"
[0m02:20:00.436960 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:00.437380 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:00.438423 [debug] [ThreadPool]: On create_dev_public_public: COMMIT
[0m02:20:00.439261 [debug] [ThreadPool]: On create_dev_public_staging: COMMIT
[0m02:20:00.439663 [debug] [ThreadPool]: Using redshift connection "create_dev_public_public"
[0m02:20:00.439999 [debug] [ThreadPool]: Using redshift connection "create_dev_public_staging"
[0m02:20:00.440282 [debug] [ThreadPool]: On create_dev_public_public: COMMIT
[0m02:20:00.440548 [debug] [ThreadPool]: On create_dev_public_staging: COMMIT
[0m02:20:02.212965 [debug] [ThreadPool]: SQL status: SUCCESS in 2.0 seconds
[0m02:20:02.214245 [debug] [ThreadPool]: SQL status: SUCCESS in 2.0 seconds
[0m02:20:02.215473 [debug] [ThreadPool]: On create_dev_public_public: Close
[0m02:20:02.216464 [debug] [ThreadPool]: On create_dev_public_staging: Close
[0m02:20:02.221909 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_dev_public_public, now list_dev_public_staging)
[0m02:20:02.223181 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_dev_public_staging, now list_dev_public_public)
[0m02:20:02.233988 [debug] [ThreadPool]: Using redshift connection "list_dev_public_staging"
[0m02:20:02.246816 [debug] [ThreadPool]: Using redshift connection "list_dev_public_public"
[0m02:20:02.247218 [debug] [ThreadPool]: On list_dev_public_staging: BEGIN
[0m02:20:02.247512 [debug] [ThreadPool]: On list_dev_public_public: BEGIN
[0m02:20:02.247784 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:20:02.248042 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:20:02.248538 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:20:02.248920 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:20:02.249213 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:20:02.249491 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:20:02.620093 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:02.621295 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:02.622116 [debug] [ThreadPool]: Using redshift connection "list_dev_public_staging"
[0m02:20:02.622800 [debug] [ThreadPool]: Using redshift connection "list_dev_public_public"
[0m02:20:02.623595 [debug] [ThreadPool]: On list_dev_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_staging'
[0m02:20:02.625003 [debug] [ThreadPool]: On list_dev_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_public'
[0m02:20:02.720590 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:02.721698 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:02.725400 [debug] [ThreadPool]: On list_dev_public_public: ROLLBACK
[0m02:20:02.728314 [debug] [ThreadPool]: On list_dev_public_staging: ROLLBACK
[0m02:20:02.811569 [debug] [ThreadPool]: On list_dev_public_staging: Close
[0m02:20:02.813519 [debug] [ThreadPool]: On list_dev_public_public: Close
[0m02:20:02.828759 [debug] [MainThread]: Using redshift connection "master"
[0m02:20:02.829295 [debug] [MainThread]: On master: BEGIN
[0m02:20:02.829675 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:20:02.830515 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:20:02.830949 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:20:03.201163 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:03.202237 [debug] [MainThread]: Using redshift connection "master"
[0m02:20:03.203196 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:20:03.328442 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:03.332842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd70edd21-8a56-4bc9-8431-fdd6c50ab2cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107efbd90>]}
[0m02:20:03.334201 [debug] [MainThread]: On master: ROLLBACK
[0m02:20:03.432547 [debug] [MainThread]: Using redshift connection "master"
[0m02:20:03.433316 [debug] [MainThread]: On master: BEGIN
[0m02:20:03.471641 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:03.472944 [debug] [MainThread]: On master: COMMIT
[0m02:20:03.474061 [debug] [MainThread]: Using redshift connection "master"
[0m02:20:03.474759 [debug] [MainThread]: On master: COMMIT
[0m02:20:03.552693 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:03.554045 [debug] [MainThread]: On master: Close
[0m02:20:03.556316 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:20:03.557517 [info ] [MainThread]: 
[0m02:20:03.563568 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:20:03.564517 [info ] [Thread-1 (]: 1 of 2 START sql table model public_staging.stg_starlink_sattelite ............. [RUN]
[0m02:20:03.565671 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public_staging, now model.dbt_remote.stg_starlink_sattelite)
[0m02:20:03.566342 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:20:03.572036 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:03.573372 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:20:03.566731 => 02:20:03.573073
[0m02:20:03.573897 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:20:03.619519 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:03.621570 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:03.621828 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:20:03.622052 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:20:03.622407 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:20:03.622653 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:20:03.976207 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:03.976604 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:03.976874 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public_staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s
  );
[0m02:20:05.651796 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m02:20:05.657242 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:05.657545 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public_staging"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m02:20:05.846677 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:05.860824 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:20:05.861199 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:05.861452 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:20:06.757742 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:20:06.758686 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:06.759101 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:20:06.834784 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:06.848616 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:06.849142 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "dev"."public_staging"."stg_starlink_sattelite__dbt_backup" cascade
[0m02:20:06.925579 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:06.928902 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:20:06.930412 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:06.931673 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:20:06.975984 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:06.976789 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:06.977289 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:20:07.016015 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:07.017401 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:20:03.574177 => 02:20:07.017172
[0m02:20:07.017850 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:20:07.093060 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:20:07.095670 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd70edd21-8a56-4bc9-8431-fdd6c50ab2cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ede650>]}
[0m02:20:07.097121 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_staging.stg_starlink_sattelite ........ [[32mSUCCESS[0m in 3.53s]
[0m02:20:07.098076 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:20:07.100353 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m02:20:07.101073 [info ] [Thread-3 (]: 2 of 2 START sql table model public_public.dim_starlink_sattelite .............. [RUN]
[0m02:20:07.102207 [debug] [Thread-3 (]: Acquiring new redshift connection 'model.dbt_remote.dim_starlink_sattelite'
[0m02:20:07.102685 [debug] [Thread-3 (]: Began compiling node model.dbt_remote.dim_starlink_sattelite
[0m02:20:07.135414 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:20:07.135866 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m02:20:07.136160 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:20:07.136657 [debug] [Thread-3 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:20:07.137061 [debug] [Thread-3 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:20:07.514468 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:07.516827 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:20:07.518426 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_starlink_sattelite'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_starlink_sattelite'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'public_staging'
        and tablename = 'stg_starlink_sattelite'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'public_staging'
    
    order by ordinal_position
[0m02:20:07.707970 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:07.714726 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_remote.dim_starlink_sattelite"
[0m02:20:07.715966 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (compile): 02:20:07.103007 => 02:20:07.715652
[0m02:20:07.716524 [debug] [Thread-3 (]: Began executing node model.dbt_remote.dim_starlink_sattelite
[0m02:20:07.723716 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_remote.dim_starlink_sattelite"
[0m02:20:07.726685 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:20:07.727253 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

  
    

  create  table
    "dev"."public_public"."dim_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    


with max_ingested as (
    select
        object_id,
        max(export_date) as last_ingested_date
    from "dev"."public_staging"."stg_starlink_sattelite"
    group  by 1)

select
    "object_id",
  "object_name",
  "launch_id",
  "version_id",
  "latitude",
  "longitude",
  "velocity_kms",
  "center_name",
  "time_system",
  "launch_date",
  "export_date",
    case when s.export_date != m.last_ingested_date then true else false end as deleted_flag
from
    "dev"."public_staging"."stg_starlink_sattelite" s
where rnk=1

left join max_ingested m
on m.object_id = s.object_id
  );
[0m02:20:07.794380 [debug] [Thread-3 (]: Redshift adapter: Redshift error: syntax error at or near "left"
[0m02:20:07.794955 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: ROLLBACK
[0m02:20:07.872565 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (execute): 02:20:07.716860 => 02:20:07.872291
[0m02:20:07.872980 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: Close
[0m02:20:07.878800 [debug] [Thread-3 (]: Database Error in model dim_starlink_sattelite (models/Starlink/dim_starlink_sattelite.sql)
  syntax error at or near "left"
  compiled Code at target/run/dbt_remote/models/Starlink/dim_starlink_sattelite.sql
[0m02:20:07.879271 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd70edd21-8a56-4bc9-8431-fdd6c50ab2cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077bda90>]}
[0m02:20:07.879725 [error] [Thread-3 (]: 2 of 2 ERROR creating sql table model public_public.dim_starlink_sattelite ..... [[31mERROR[0m in 0.78s]
[0m02:20:07.880172 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m02:20:07.882137 [debug] [MainThread]: Using redshift connection "master"
[0m02:20:07.882468 [debug] [MainThread]: On master: BEGIN
[0m02:20:07.882668 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:20:07.882999 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:20:07.883215 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:20:08.237425 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:08.238491 [debug] [MainThread]: On master: COMMIT
[0m02:20:08.239625 [debug] [MainThread]: Using redshift connection "master"
[0m02:20:08.240611 [debug] [MainThread]: On master: COMMIT
[0m02:20:08.318322 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:08.319422 [debug] [MainThread]: On master: Close
[0m02:20:08.321543 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:20:08.322263 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:20:08.322744 [debug] [MainThread]: Connection 'list_dev_public_public' was properly closed.
[0m02:20:08.323629 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_sattelite' was properly closed.
[0m02:20:08.324344 [info ] [MainThread]: 
[0m02:20:08.324839 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 9.01 seconds (9.01s).
[0m02:20:08.326308 [debug] [MainThread]: Command end result
[0m02:20:08.342449 [info ] [MainThread]: 
[0m02:20:08.343022 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m02:20:08.343519 [info ] [MainThread]: 
[0m02:20:08.343887 [error] [MainThread]: [33mDatabase Error in model dim_starlink_sattelite (models/Starlink/dim_starlink_sattelite.sql)[0m
[0m02:20:08.344236 [error] [MainThread]:   syntax error at or near "left"
[0m02:20:08.344551 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/dim_starlink_sattelite.sql
[0m02:20:08.344871 [info ] [MainThread]: 
[0m02:20:08.345329 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
[0m02:20:08.346194 [debug] [MainThread]: Command `dbt run` failed at 02:20:08.346011 after 9.71 seconds
[0m02:20:08.346818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ead090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ead0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102984ad0>]}
[0m02:20:08.347302 [debug] [MainThread]: Flushing usage events
[0m02:20:35.968554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073eef90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107164f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107eead90>]}


============================== 02:20:35.971154 | 717b4f4a-5449-4c5d-a54a-f9471e2fa5c6 ==============================
[0m02:20:35.971154 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:20:35.971521 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/Users/annaantypenko/.dbt', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run -s stg_starlink_sattelite+', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:20:36.063366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '717b4f4a-5449-4c5d-a54a-f9471e2fa5c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f12490>]}
[0m02:20:36.067747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '717b4f4a-5449-4c5d-a54a-f9471e2fa5c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ef3b50>]}
[0m02:20:36.068263 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:20:36.075691 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:20:36.099404 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:20:36.099828 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/dim_starlink_sattelite.sql
[0m02:20:36.127434 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:20:36.130564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '717b4f4a-5449-4c5d-a54a-f9471e2fa5c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073eda90>]}
[0m02:20:36.137021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '717b4f4a-5449-4c5d-a54a-f9471e2fa5c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112c5b90>]}
[0m02:20:36.137353 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 511 macros, 0 groups, 0 semantic models
[0m02:20:36.137532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '717b4f4a-5449-4c5d-a54a-f9471e2fa5c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11098ae90>]}
[0m02:20:36.138432 [info ] [MainThread]: 
[0m02:20:36.138880 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:20:36.139461 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:20:36.148108 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:20:36.148702 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:20:36.149049 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:20:36.150784 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:20:36.150989 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:20:36.151135 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:20:36.151653 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:20:36.151792 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:20:36.151929 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:20:36.152107 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:20:36.153264 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:20:36.612907 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:36.613822 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:36.616816 [debug] [ThreadPool]: On list_dev: Close
[0m02:20:36.619265 [debug] [ThreadPool]: On list_dev: Close
[0m02:20:36.622638 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public_staging)
[0m02:20:36.623747 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public_public)
[0m02:20:36.633801 [debug] [ThreadPool]: Using redshift connection "list_dev_public_staging"
[0m02:20:36.638347 [debug] [ThreadPool]: Using redshift connection "list_dev_public_public"
[0m02:20:36.638721 [debug] [ThreadPool]: On list_dev_public_staging: BEGIN
[0m02:20:36.639058 [debug] [ThreadPool]: On list_dev_public_public: BEGIN
[0m02:20:36.639360 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:20:36.639655 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:20:36.640150 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:20:36.640528 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:20:36.640808 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:20:36.641079 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:20:37.017386 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:37.017660 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:37.017923 [debug] [ThreadPool]: Using redshift connection "list_dev_public_staging"
[0m02:20:37.018114 [debug] [ThreadPool]: Using redshift connection "list_dev_public_public"
[0m02:20:37.018317 [debug] [ThreadPool]: On list_dev_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_staging'
[0m02:20:37.018526 [debug] [ThreadPool]: On list_dev_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_public'
[0m02:20:37.112516 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:37.112945 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:37.114548 [debug] [ThreadPool]: On list_dev_public_staging: ROLLBACK
[0m02:20:37.115896 [debug] [ThreadPool]: On list_dev_public_public: ROLLBACK
[0m02:20:37.196066 [debug] [ThreadPool]: On list_dev_public_public: Close
[0m02:20:37.198898 [debug] [ThreadPool]: On list_dev_public_staging: Close
[0m02:20:37.212754 [debug] [MainThread]: Using redshift connection "master"
[0m02:20:37.213266 [debug] [MainThread]: On master: BEGIN
[0m02:20:37.213651 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:20:37.214241 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:20:37.214663 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:20:37.599246 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:37.600316 [debug] [MainThread]: Using redshift connection "master"
[0m02:20:37.601156 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:20:37.727653 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:37.732172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '717b4f4a-5449-4c5d-a54a-f9471e2fa5c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e1e050>]}
[0m02:20:37.733531 [debug] [MainThread]: On master: ROLLBACK
[0m02:20:37.832821 [debug] [MainThread]: Using redshift connection "master"
[0m02:20:37.833911 [debug] [MainThread]: On master: BEGIN
[0m02:20:37.875005 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:37.876403 [debug] [MainThread]: On master: COMMIT
[0m02:20:37.877838 [debug] [MainThread]: Using redshift connection "master"
[0m02:20:37.878795 [debug] [MainThread]: On master: COMMIT
[0m02:20:37.958649 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:37.959571 [debug] [MainThread]: On master: Close
[0m02:20:37.961094 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:20:37.962371 [info ] [MainThread]: 
[0m02:20:37.966100 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:20:37.967188 [info ] [Thread-1 (]: 1 of 2 START sql table model public_staging.stg_starlink_sattelite ............. [RUN]
[0m02:20:37.969318 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public_staging, now model.dbt_remote.stg_starlink_sattelite)
[0m02:20:37.970033 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:20:37.975305 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:37.976541 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:20:37.970379 => 02:20:37.976234
[0m02:20:37.977066 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:20:38.027546 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:38.029582 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:38.029808 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:20:38.030001 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:20:38.030318 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:20:38.030533 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:20:38.386587 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:38.387781 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:38.388667 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public_staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s
  );
[0m02:20:40.181592 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m02:20:40.194656 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:40.195426 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public_staging"."stg_starlink_sattelite" rename to "stg_starlink_sattelite__dbt_backup"
[0m02:20:40.389783 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:40.400679 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:40.401342 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public_staging"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m02:20:40.517648 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:40.551261 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:20:40.551813 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:40.552154 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:20:41.615030 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:20:41.616775 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:41.617697 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:20:41.695571 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:41.713004 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:41.713692 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "dev"."public_staging"."stg_starlink_sattelite__dbt_backup" cascade
[0m02:20:41.792906 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:41.796098 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:20:41.797276 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:41.798089 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:20:42.762579 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:20:42.764304 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:20:42.765823 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:20:42.807008 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:42.810494 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:20:37.977390 => 02:20:42.809998
[0m02:20:42.811636 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:20:42.890302 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:20:42.893623 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '717b4f4a-5449-4c5d-a54a-f9471e2fa5c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107424490>]}
[0m02:20:42.895469 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_staging.stg_starlink_sattelite ........ [[32mSUCCESS[0m in 4.93s]
[0m02:20:42.897202 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:20:42.899802 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m02:20:42.900670 [info ] [Thread-3 (]: 2 of 2 START sql table model public_public.dim_starlink_sattelite .............. [RUN]
[0m02:20:42.901806 [debug] [Thread-3 (]: Acquiring new redshift connection 'model.dbt_remote.dim_starlink_sattelite'
[0m02:20:42.902280 [debug] [Thread-3 (]: Began compiling node model.dbt_remote.dim_starlink_sattelite
[0m02:20:42.933087 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:20:42.933591 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m02:20:42.933895 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:20:42.934429 [debug] [Thread-3 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:20:42.934852 [debug] [Thread-3 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:20:43.304078 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:43.305575 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:20:43.307039 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_starlink_sattelite'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_starlink_sattelite'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'public_staging'
        and tablename = 'stg_starlink_sattelite'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'public_staging'
    
    order by ordinal_position
[0m02:20:43.495389 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:43.505711 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_remote.dim_starlink_sattelite"
[0m02:20:43.506927 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (compile): 02:20:42.902606 => 02:20:43.506653
[0m02:20:43.507426 [debug] [Thread-3 (]: Began executing node model.dbt_remote.dim_starlink_sattelite
[0m02:20:43.517020 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_remote.dim_starlink_sattelite"
[0m02:20:43.519927 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:20:43.520382 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

  
    

  create  table
    "dev"."public_public"."dim_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    


with max_ingested as (
    select
        object_id,
        max(export_date) as last_ingested_date
    from "dev"."public_staging"."stg_starlink_sattelite"
    group  by 1)

select
    "object_id",
  "object_name",
  "launch_id",
  "version_id",
  "latitude",
  "longitude",
  "velocity_kms",
  "center_name",
  "time_system",
  "launch_date",
  "export_date",
    case when s.export_date != m.last_ingested_date then true else false end as deleted_flag
from
    "dev"."public_staging"."stg_starlink_sattelite" s

left join max_ingested m
on m.object_id = s.object_id

where s.rnk = 1
  );
[0m02:20:43.589457 [debug] [Thread-3 (]: Redshift adapter: Redshift error: column reference "object_id" is ambiguous
[0m02:20:43.590880 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: ROLLBACK
[0m02:20:43.668885 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (execute): 02:20:43.507750 => 02:20:43.668177
[0m02:20:43.669986 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: Close
[0m02:20:43.679412 [debug] [Thread-3 (]: Database Error in model dim_starlink_sattelite (models/Starlink/dim_starlink_sattelite.sql)
  column reference "object_id" is ambiguous
  compiled Code at target/run/dbt_remote/models/Starlink/dim_starlink_sattelite.sql
[0m02:20:43.680088 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '717b4f4a-5449-4c5d-a54a-f9471e2fa5c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10747fed0>]}
[0m02:20:43.680857 [error] [Thread-3 (]: 2 of 2 ERROR creating sql table model public_public.dim_starlink_sattelite ..... [[31mERROR[0m in 0.78s]
[0m02:20:43.681707 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m02:20:43.684817 [debug] [MainThread]: Using redshift connection "master"
[0m02:20:43.685375 [debug] [MainThread]: On master: BEGIN
[0m02:20:43.685770 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:20:43.686416 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:20:43.686846 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:20:44.063392 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:44.065002 [debug] [MainThread]: On master: COMMIT
[0m02:20:44.066446 [debug] [MainThread]: Using redshift connection "master"
[0m02:20:44.067109 [debug] [MainThread]: On master: COMMIT
[0m02:20:44.145530 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:20:44.147041 [debug] [MainThread]: On master: Close
[0m02:20:44.149414 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:20:44.150275 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:20:44.150721 [debug] [MainThread]: Connection 'list_dev_public_public' was properly closed.
[0m02:20:44.151148 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_sattelite' was properly closed.
[0m02:20:44.151653 [info ] [MainThread]: 
[0m02:20:44.152235 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 8.01 seconds (8.01s).
[0m02:20:44.153680 [debug] [MainThread]: Command end result
[0m02:20:44.169097 [info ] [MainThread]: 
[0m02:20:44.169628 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m02:20:44.170102 [info ] [MainThread]: 
[0m02:20:44.170535 [error] [MainThread]: [33mDatabase Error in model dim_starlink_sattelite (models/Starlink/dim_starlink_sattelite.sql)[0m
[0m02:20:44.170900 [error] [MainThread]:   column reference "object_id" is ambiguous
[0m02:20:44.171218 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/dim_starlink_sattelite.sql
[0m02:20:44.171556 [info ] [MainThread]: 
[0m02:20:44.171928 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
[0m02:20:44.172571 [debug] [MainThread]: Command `dbt run` failed at 02:20:44.172458 after 8.21 seconds
[0m02:20:44.172988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071d1a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10747fed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e1b510>]}
[0m02:20:44.173386 [debug] [MainThread]: Flushing usage events
[0m02:21:30.597569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e335d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105189950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054dacd0>]}


============================== 02:21:30.599919 | 33420427-d260-4522-8303-8f0eef8db141 ==============================
[0m02:21:30.599919 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:21:30.600240 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/Users/annaantypenko/.dbt', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run -s stg_starlink_sattelite+', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:21:30.685238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '33420427-d260-4522-8303-8f0eef8db141', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105111d50>]}
[0m02:21:30.689391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '33420427-d260-4522-8303-8f0eef8db141', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e563d0>]}
[0m02:21:30.689756 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:21:30.698497 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:21:30.720674 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:21:30.721011 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/dim_starlink_sattelite.sql
[0m02:21:30.747115 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:21:30.750125 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '33420427-d260-4522-8303-8f0eef8db141', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e55910>]}
[0m02:21:30.756305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '33420427-d260-4522-8303-8f0eef8db141', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ffc150>]}
[0m02:21:30.756620 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 511 macros, 0 groups, 0 semantic models
[0m02:21:30.756796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '33420427-d260-4522-8303-8f0eef8db141', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ff5150>]}
[0m02:21:30.757625 [info ] [MainThread]: 
[0m02:21:30.758027 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:21:30.758593 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:21:30.759008 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:21:30.767784 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:21:30.769143 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:21:30.769305 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:21:30.769451 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:21:30.769588 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:21:30.769712 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:21:30.770216 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:21:30.770405 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:21:30.770543 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:21:30.770672 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:21:31.328408 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:21:31.329843 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:21:31.333503 [debug] [ThreadPool]: On list_dev: Close
[0m02:21:31.336121 [debug] [ThreadPool]: On list_dev: Close
[0m02:21:31.339547 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public_public)
[0m02:21:31.340550 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public_staging)
[0m02:21:31.350959 [debug] [ThreadPool]: Using redshift connection "list_dev_public_public"
[0m02:21:31.355505 [debug] [ThreadPool]: Using redshift connection "list_dev_public_staging"
[0m02:21:31.355877 [debug] [ThreadPool]: On list_dev_public_public: BEGIN
[0m02:21:31.356202 [debug] [ThreadPool]: On list_dev_public_staging: BEGIN
[0m02:21:31.356505 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:21:31.356799 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:21:31.357291 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:21:31.357727 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:21:31.358052 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:21:31.358377 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:21:31.740544 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:31.741777 [debug] [ThreadPool]: Using redshift connection "list_dev_public_public"
[0m02:21:31.742770 [debug] [ThreadPool]: On list_dev_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_public'
[0m02:21:31.744784 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:31.745456 [debug] [ThreadPool]: Using redshift connection "list_dev_public_staging"
[0m02:21:31.746038 [debug] [ThreadPool]: On list_dev_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_staging'
[0m02:21:31.840045 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:31.841213 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:31.844513 [debug] [ThreadPool]: On list_dev_public_public: ROLLBACK
[0m02:21:31.847342 [debug] [ThreadPool]: On list_dev_public_staging: ROLLBACK
[0m02:21:31.929038 [debug] [ThreadPool]: On list_dev_public_public: Close
[0m02:21:31.931915 [debug] [ThreadPool]: On list_dev_public_staging: Close
[0m02:21:31.946505 [debug] [MainThread]: Using redshift connection "master"
[0m02:21:31.947033 [debug] [MainThread]: On master: BEGIN
[0m02:21:31.947407 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:21:31.947991 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:21:31.948416 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:21:32.325695 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:32.326880 [debug] [MainThread]: Using redshift connection "master"
[0m02:21:32.327948 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:21:32.456810 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:32.461039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '33420427-d260-4522-8303-8f0eef8db141', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ad5150>]}
[0m02:21:32.462443 [debug] [MainThread]: On master: ROLLBACK
[0m02:21:32.558365 [debug] [MainThread]: Using redshift connection "master"
[0m02:21:32.559833 [debug] [MainThread]: On master: BEGIN
[0m02:21:32.599233 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:32.600289 [debug] [MainThread]: On master: COMMIT
[0m02:21:32.601144 [debug] [MainThread]: Using redshift connection "master"
[0m02:21:32.601742 [debug] [MainThread]: On master: COMMIT
[0m02:21:32.678109 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:32.679514 [debug] [MainThread]: On master: Close
[0m02:21:32.682273 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:21:32.683277 [info ] [MainThread]: 
[0m02:21:32.687681 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:21:32.688493 [info ] [Thread-1 (]: 1 of 2 START sql table model public_staging.stg_starlink_sattelite ............. [RUN]
[0m02:21:32.689552 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:21:32.690564 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:21:32.694674 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:21:32.695510 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:21:32.690919 => 02:21:32.695344
[0m02:21:32.695770 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:21:32.738847 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:21:32.741003 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:21:32.741286 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:21:32.741512 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:21:32.741853 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:21:32.742091 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:21:33.107264 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:33.108154 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:21:33.108870 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public_staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s
  );
[0m02:21:34.740498 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m02:21:34.754740 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:21:34.755470 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public_staging"."stg_starlink_sattelite" rename to "stg_starlink_sattelite__dbt_backup"
[0m02:21:34.949345 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:34.958508 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:21:34.959262 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public_staging"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m02:21:35.074266 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:35.106738 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:21:35.107235 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:21:35.107567 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:21:36.092557 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:21:36.094499 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:21:36.095748 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:21:36.176973 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:36.193839 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:21:36.194543 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "dev"."public_staging"."stg_starlink_sattelite__dbt_backup" cascade
[0m02:21:36.274831 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:36.278572 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:21:36.280110 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:21:36.281178 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:21:37.203159 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:21:37.204513 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:21:37.205320 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:21:37.244538 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:37.247424 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:21:32.695903 => 02:21:37.246973
[0m02:21:37.248579 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:21:37.327480 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:21:37.331068 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33420427-d260-4522-8303-8f0eef8db141', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fed550>]}
[0m02:21:37.333072 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_staging.stg_starlink_sattelite ........ [[32mSUCCESS[0m in 4.64s]
[0m02:21:37.334360 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:21:37.336784 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m02:21:37.337502 [info ] [Thread-3 (]: 2 of 2 START sql table model public_public.dim_starlink_sattelite .............. [RUN]
[0m02:21:37.338621 [debug] [Thread-3 (]: Acquiring new redshift connection 'model.dbt_remote.dim_starlink_sattelite'
[0m02:21:37.339107 [debug] [Thread-3 (]: Began compiling node model.dbt_remote.dim_starlink_sattelite
[0m02:21:37.369890 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:21:37.370376 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m02:21:37.370678 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:21:37.371209 [debug] [Thread-3 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:21:37.371620 [debug] [Thread-3 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:21:37.749319 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:37.750556 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:21:37.751724 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_starlink_sattelite'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_starlink_sattelite'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'public_staging'
        and tablename = 'stg_starlink_sattelite'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'public_staging'
    
    order by ordinal_position
[0m02:21:37.939226 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:37.949644 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_remote.dim_starlink_sattelite"
[0m02:21:37.951564 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (compile): 02:21:37.339431 => 02:21:37.951285
[0m02:21:37.952073 [debug] [Thread-3 (]: Began executing node model.dbt_remote.dim_starlink_sattelite
[0m02:21:37.961150 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_remote.dim_starlink_sattelite"
[0m02:21:37.964100 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:21:37.964551 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

  
    

  create  table
    "dev"."public_public"."dim_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    


with max_ingested as (
    select
        s.object_id,
        max(s.export_date) as last_ingested_date
    from "dev"."public_staging"."stg_starlink_sattelite" s
    group  by 1)

select
    "object_id",
  "object_name",
  "launch_id",
  "version_id",
  "latitude",
  "longitude",
  "velocity_kms",
  "center_name",
  "time_system",
  "launch_date",
  "export_date",
    case when s.export_date != m.last_ingested_date then true else false end as deleted_flag
from
    "dev"."public_staging"."stg_starlink_sattelite" s

left join max_ingested m
on m.object_id = s.object_id

where s.rnk = 1
  );
[0m02:21:38.032412 [debug] [Thread-3 (]: Redshift adapter: Redshift error: column reference "object_id" is ambiguous
[0m02:21:38.033574 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: ROLLBACK
[0m02:21:38.111540 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (execute): 02:21:37.952401 => 02:21:38.110706
[0m02:21:38.112967 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: Close
[0m02:21:38.123846 [debug] [Thread-3 (]: Database Error in model dim_starlink_sattelite (models/Starlink/dim_starlink_sattelite.sql)
  column reference "object_id" is ambiguous
  compiled Code at target/run/dbt_remote/models/Starlink/dim_starlink_sattelite.sql
[0m02:21:38.124523 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33420427-d260-4522-8303-8f0eef8db141', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b6b810>]}
[0m02:21:38.125309 [error] [Thread-3 (]: 2 of 2 ERROR creating sql table model public_public.dim_starlink_sattelite ..... [[31mERROR[0m in 0.79s]
[0m02:21:38.126102 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m02:21:38.129019 [debug] [MainThread]: Using redshift connection "master"
[0m02:21:38.129569 [debug] [MainThread]: On master: BEGIN
[0m02:21:38.129967 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:21:38.130595 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:21:38.131026 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:21:38.509529 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:38.510315 [debug] [MainThread]: On master: COMMIT
[0m02:21:38.510866 [debug] [MainThread]: Using redshift connection "master"
[0m02:21:38.511375 [debug] [MainThread]: On master: COMMIT
[0m02:21:38.587161 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:21:38.588531 [debug] [MainThread]: On master: Close
[0m02:21:38.591230 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:21:38.592302 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:21:38.593173 [debug] [MainThread]: Connection 'list_dev_public_staging' was properly closed.
[0m02:21:38.594008 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_sattelite' was properly closed.
[0m02:21:38.594614 [info ] [MainThread]: 
[0m02:21:38.595121 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 7.84 seconds (7.84s).
[0m02:21:38.596593 [debug] [MainThread]: Command end result
[0m02:21:38.612365 [info ] [MainThread]: 
[0m02:21:38.612934 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m02:21:38.613282 [info ] [MainThread]: 
[0m02:21:38.613940 [error] [MainThread]: [33mDatabase Error in model dim_starlink_sattelite (models/Starlink/dim_starlink_sattelite.sql)[0m
[0m02:21:38.614388 [error] [MainThread]:   column reference "object_id" is ambiguous
[0m02:21:38.614739 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/dim_starlink_sattelite.sql
[0m02:21:38.615071 [info ] [MainThread]: 
[0m02:21:38.615432 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
[0m02:21:38.616105 [debug] [MainThread]: Command `dbt run` failed at 02:21:38.615984 after 8.03 seconds
[0m02:21:38.616561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104efcf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054ec9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057bb690>]}
[0m02:21:38.616975 [debug] [MainThread]: Flushing usage events
[0m02:23:40.486437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097a5550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109787d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094cd810>]}


============================== 02:23:40.489293 | 219d8c47-7e93-475e-a163-9b000ea616e9 ==============================
[0m02:23:40.489293 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:23:40.489609 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s stg_starlink_sattelite+', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:23:40.587142 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '219d8c47-7e93-475e-a163-9b000ea616e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109568510>]}
[0m02:23:40.591413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '219d8c47-7e93-475e-a163-9b000ea616e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d171d0>]}
[0m02:23:40.591911 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:23:40.600775 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:23:40.627252 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:23:40.627592 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/dim_starlink_sattelite.sql
[0m02:23:40.654992 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:23:40.657840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '219d8c47-7e93-475e-a163-9b000ea616e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a64cc10>]}
[0m02:23:40.664162 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '219d8c47-7e93-475e-a163-9b000ea616e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d574d0>]}
[0m02:23:40.664519 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 511 macros, 0 groups, 0 semantic models
[0m02:23:40.664725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '219d8c47-7e93-475e-a163-9b000ea616e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a61250>]}
[0m02:23:40.665778 [info ] [MainThread]: 
[0m02:23:40.666387 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:23:40.667049 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:23:40.667451 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m02:23:40.676003 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:23:40.677333 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m02:23:40.677505 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:23:40.677678 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m02:23:40.677856 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:23:40.677995 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:23:40.678554 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:23:40.678777 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:23:40.678943 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:23:40.679090 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:23:41.205374 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:23:41.206717 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:23:41.210560 [debug] [ThreadPool]: On list_dev: Close
[0m02:23:41.213933 [debug] [ThreadPool]: On list_dev: Close
[0m02:23:41.217636 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public_public)
[0m02:23:41.218677 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public_staging)
[0m02:23:41.228750 [debug] [ThreadPool]: Using redshift connection "list_dev_public_public"
[0m02:23:41.233358 [debug] [ThreadPool]: Using redshift connection "list_dev_public_staging"
[0m02:23:41.233736 [debug] [ThreadPool]: On list_dev_public_public: BEGIN
[0m02:23:41.234062 [debug] [ThreadPool]: On list_dev_public_staging: BEGIN
[0m02:23:41.234362 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:23:41.234658 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:23:41.235155 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:23:41.235597 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:23:41.235933 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:23:41.236251 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:23:41.620299 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:41.621770 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:41.622773 [debug] [ThreadPool]: Using redshift connection "list_dev_public_staging"
[0m02:23:41.623566 [debug] [ThreadPool]: Using redshift connection "list_dev_public_public"
[0m02:23:41.624565 [debug] [ThreadPool]: On list_dev_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_staging'
[0m02:23:41.625921 [debug] [ThreadPool]: On list_dev_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_public'
[0m02:23:41.722941 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:41.723882 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:41.726181 [debug] [ThreadPool]: On list_dev_public_staging: ROLLBACK
[0m02:23:41.728708 [debug] [ThreadPool]: On list_dev_public_public: ROLLBACK
[0m02:23:41.811214 [debug] [ThreadPool]: On list_dev_public_public: Close
[0m02:23:41.812648 [debug] [ThreadPool]: On list_dev_public_staging: Close
[0m02:23:41.828443 [debug] [MainThread]: Using redshift connection "master"
[0m02:23:41.829045 [debug] [MainThread]: On master: BEGIN
[0m02:23:41.829440 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:23:41.830036 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:23:41.830466 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:23:42.212741 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:42.214097 [debug] [MainThread]: Using redshift connection "master"
[0m02:23:42.215511 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:23:42.341481 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:42.345532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '219d8c47-7e93-475e-a163-9b000ea616e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a14fcd0>]}
[0m02:23:42.347077 [debug] [MainThread]: On master: ROLLBACK
[0m02:23:42.443111 [debug] [MainThread]: Using redshift connection "master"
[0m02:23:42.444022 [debug] [MainThread]: On master: BEGIN
[0m02:23:42.483691 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:42.484118 [debug] [MainThread]: On master: COMMIT
[0m02:23:42.484470 [debug] [MainThread]: Using redshift connection "master"
[0m02:23:42.484716 [debug] [MainThread]: On master: COMMIT
[0m02:23:42.561499 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:42.561877 [debug] [MainThread]: On master: Close
[0m02:23:42.562556 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:23:42.562793 [info ] [MainThread]: 
[0m02:23:42.565125 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:23:42.565536 [info ] [Thread-1 (]: 1 of 2 START sql table model public_staging.stg_starlink_sattelite ............. [RUN]
[0m02:23:42.566051 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:23:42.566580 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:23:42.569009 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:42.569722 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:23:42.566762 => 02:23:42.569606
[0m02:23:42.569927 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:23:42.600876 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:42.602362 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:42.602561 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:23:42.602733 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:23:42.603035 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:23:42.603209 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:23:42.963762 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:42.965410 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:42.966455 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public_staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s
  );
[0m02:23:44.497321 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m02:23:44.512049 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:44.512765 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public_staging"."stg_starlink_sattelite" rename to "stg_starlink_sattelite__dbt_backup"
[0m02:23:44.708165 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:44.717140 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:44.717690 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public_staging"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m02:23:44.834916 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:44.867010 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:23:44.867515 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:44.867854 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:23:45.854132 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:23:45.856192 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:45.857165 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:23:45.939428 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:45.956705 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:45.957364 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "dev"."public_staging"."stg_starlink_sattelite__dbt_backup" cascade
[0m02:23:46.037477 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:46.039781 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:23:46.040893 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:46.041489 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:23:46.960095 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:23:46.961878 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:46.963356 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:23:47.003118 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:47.006903 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:23:42.570049 => 02:23:47.006268
[0m02:23:47.007990 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:23:47.087751 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:23:47.090534 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '219d8c47-7e93-475e-a163-9b000ea616e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7e84d0>]}
[0m02:23:47.092271 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_staging.stg_starlink_sattelite ........ [[32mSUCCESS[0m in 4.52s]
[0m02:23:47.093876 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:23:47.096535 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m02:23:47.097589 [info ] [Thread-3 (]: 2 of 2 START sql table model public_public.dim_starlink_sattelite .............. [RUN]
[0m02:23:47.098803 [debug] [Thread-3 (]: Acquiring new redshift connection 'model.dbt_remote.dim_starlink_sattelite'
[0m02:23:47.099314 [debug] [Thread-3 (]: Began compiling node model.dbt_remote.dim_starlink_sattelite
[0m02:23:47.130206 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:47.130708 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m02:23:47.131034 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:23:47.131560 [debug] [Thread-3 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:23:47.131974 [debug] [Thread-3 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:23:47.518506 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:47.519105 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:47.519721 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_starlink_sattelite'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_starlink_sattelite'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'public_staging'
        and tablename = 'stg_starlink_sattelite'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'public_staging'
    
    order by ordinal_position
[0m02:23:47.711295 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:47.717769 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:47.718727 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (compile): 02:23:47.099647 => 02:23:47.718501
[0m02:23:47.719145 [debug] [Thread-3 (]: Began executing node model.dbt_remote.dim_starlink_sattelite
[0m02:23:47.727110 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:47.729938 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:47.730334 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

  
    

  create  table
    "dev"."public_public"."dim_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    


with max_ingested as (
    select
        s.object_id,
        max(s.export_date) as last_ingested_date
    from "dev"."public_staging"."stg_starlink_sattelite" s
    group  by 1)

select
    s."object_id",
  s."object_name",
  s."launch_id",
  s."version_id",
  s."latitude",
  s."longitude",
  s."velocity_kms",
  s."center_name",
  s."time_system",
  s."launch_date",
  s."export_date",
    case when s.export_date != m.last_ingested_date then true else false end as deleted_flag
from
    "dev"."public_staging"."stg_starlink_sattelite" s

left join max_ingested m
on m.object_id = s.object_id

where s.rnk = 1
  );
[0m02:23:57.691686 [debug] [Thread-3 (]: SQL status: SUCCESS in 10.0 seconds
[0m02:23:57.700868 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:57.701637 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "dev"."public_public"."dim_starlink_sattelite__dbt_tmp" rename to "dim_starlink_sattelite"
[0m02:23:57.934664 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:57.939631 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m02:23:57.940577 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:57.941184 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m02:23:58.879695 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:23:58.882102 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:58.883313 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m02:23:58.963695 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:58.971878 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:58.972560 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
drop table if exists "dev"."public_public"."dim_starlink_sattelite__dbt_backup" cascade
[0m02:23:59.053275 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:59.056566 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m02:23:59.057870 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:59.058984 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m02:23:59.104604 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:59.106351 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:59.107432 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m02:23:59.148005 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:59.151364 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (execute): 02:23:47.719411 => 02:23:59.150767
[0m02:23:59.152650 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: ROLLBACK
[0m02:23:59.232614 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: Close
[0m02:23:59.235663 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '219d8c47-7e93-475e-a163-9b000ea616e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8abb10>]}
[0m02:23:59.237426 [info ] [Thread-3 (]: 2 of 2 OK created sql table model public_public.dim_starlink_sattelite ......... [[32mSUCCESS[0m in 12.14s]
[0m02:23:59.238854 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m02:23:59.243312 [debug] [MainThread]: Using redshift connection "master"
[0m02:23:59.243976 [debug] [MainThread]: On master: BEGIN
[0m02:23:59.244384 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:23:59.245025 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:23:59.245466 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:23:59.619798 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:59.621082 [debug] [MainThread]: On master: COMMIT
[0m02:23:59.622221 [debug] [MainThread]: Using redshift connection "master"
[0m02:23:59.623109 [debug] [MainThread]: On master: COMMIT
[0m02:23:59.701995 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:59.703634 [debug] [MainThread]: On master: Close
[0m02:23:59.706104 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:23:59.706954 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:23:59.707795 [debug] [MainThread]: Connection 'list_dev_public_staging' was properly closed.
[0m02:23:59.708719 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_sattelite' was properly closed.
[0m02:23:59.709361 [info ] [MainThread]: 
[0m02:23:59.709844 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 19.04 seconds (19.04s).
[0m02:23:59.711360 [debug] [MainThread]: Command end result
[0m02:23:59.726726 [info ] [MainThread]: 
[0m02:23:59.727269 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:23:59.727613 [info ] [MainThread]: 
[0m02:23:59.728282 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m02:23:59.729141 [debug] [MainThread]: Command `dbt run` succeeded at 02:23:59.729002 after 19.25 seconds
[0m02:23:59.729597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094f8750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10958d190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094cfe10>]}
[0m02:23:59.730028 [debug] [MainThread]: Flushing usage events
[0m00:14:03.080672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107171550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ec9850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071889d0>]}


============================== 00:14:03.083528 | 16793aca-2111-4323-ae41-be36b70a3751 ==============================
[0m00:14:03.083528 [info ] [MainThread]: Running with dbt=1.6.0
[0m00:14:03.083856 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run -s dim_starlink_sattelite', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:14:03.180303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '16793aca-2111-4323-ae41-be36b70a3751', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074842d0>]}
[0m00:14:03.184517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '16793aca-2111-4323-ae41-be36b70a3751', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107460350>]}
[0m00:14:03.185000 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m00:14:03.194628 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m00:14:03.221804 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:14:03.222074 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:14:03.222410 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m00:14:03.226455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '16793aca-2111-4323-ae41-be36b70a3751', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077030d0>]}
[0m00:14:03.233358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '16793aca-2111-4323-ae41-be36b70a3751', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10776d890>]}
[0m00:14:03.233641 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 511 macros, 0 groups, 0 semantic models
[0m00:14:03.233807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '16793aca-2111-4323-ae41-be36b70a3751', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107167150>]}
[0m00:14:03.234600 [info ] [MainThread]: 
[0m00:14:03.235053 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m00:14:03.235627 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m00:14:03.244839 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m00:14:03.245110 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m00:14:03.245258 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:14:03.245776 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:14:03.245928 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:14:04.719051 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m00:14:04.722906 [debug] [ThreadPool]: On list_dev: Close
[0m00:14:04.726545 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public_public)
[0m00:14:04.728274 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public_staging'
[0m00:14:04.739426 [debug] [ThreadPool]: Using redshift connection "list_dev_public_public"
[0m00:14:04.743861 [debug] [ThreadPool]: Using redshift connection "list_dev_public_staging"
[0m00:14:04.744238 [debug] [ThreadPool]: On list_dev_public_public: BEGIN
[0m00:14:04.744566 [debug] [ThreadPool]: On list_dev_public_staging: BEGIN
[0m00:14:04.744864 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:14:04.745164 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:14:04.745665 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:14:04.746196 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:14:04.746634 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:14:04.746987 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:14:30.647688 [debug] [ThreadPool]: SQL status: SUCCESS in 26.0 seconds
[0m00:14:30.650086 [debug] [ThreadPool]: Using redshift connection "list_dev_public_public"
[0m00:14:30.651318 [debug] [ThreadPool]: On list_dev_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_public'
[0m00:14:30.653591 [debug] [ThreadPool]: SQL status: SUCCESS in 26.0 seconds
[0m00:14:30.654390 [debug] [ThreadPool]: Using redshift connection "list_dev_public_staging"
[0m00:14:30.655090 [debug] [ThreadPool]: On list_dev_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_staging'
[0m00:14:30.754560 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m00:14:30.758561 [debug] [ThreadPool]: On list_dev_public_staging: ROLLBACK
[0m00:14:30.759578 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m00:14:30.762253 [debug] [ThreadPool]: On list_dev_public_public: ROLLBACK
[0m00:14:30.840627 [debug] [ThreadPool]: On list_dev_public_staging: Close
[0m00:14:30.844025 [debug] [ThreadPool]: On list_dev_public_public: Close
[0m00:14:30.858790 [debug] [MainThread]: Using redshift connection "master"
[0m00:14:30.859412 [debug] [MainThread]: On master: BEGIN
[0m00:14:30.859809 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:14:30.860413 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:14:30.860849 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:14:32.140050 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m00:14:32.140482 [debug] [MainThread]: Using redshift connection "master"
[0m00:14:32.140766 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m00:14:32.266279 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:14:32.267309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '16793aca-2111-4323-ae41-be36b70a3751', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a83410>]}
[0m00:14:32.267647 [debug] [MainThread]: On master: ROLLBACK
[0m00:14:32.365306 [debug] [MainThread]: Using redshift connection "master"
[0m00:14:32.365786 [debug] [MainThread]: On master: BEGIN
[0m00:14:32.404411 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:14:32.404827 [debug] [MainThread]: On master: COMMIT
[0m00:14:32.405305 [debug] [MainThread]: Using redshift connection "master"
[0m00:14:32.405698 [debug] [MainThread]: On master: COMMIT
[0m00:14:32.484772 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:14:32.486362 [debug] [MainThread]: On master: Close
[0m00:14:32.489305 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m00:14:32.490358 [info ] [MainThread]: 
[0m00:14:32.495601 [debug] [Thread-1 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m00:14:32.496419 [info ] [Thread-1 (]: 1 of 1 START sql table model public_public.dim_starlink_sattelite .............. [RUN]
[0m00:14:32.497495 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public_public, now model.dbt_remote.dim_starlink_sattelite)
[0m00:14:32.498055 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.dim_starlink_sattelite
[0m00:14:32.540866 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:14:32.541304 [debug] [Thread-1 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m00:14:32.541577 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:14:32.545648 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:14:32.546064 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:14:32.911331 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:14:32.911857 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:14:32.912306 [debug] [Thread-1 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_starlink_sattelite'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_starlink_sattelite'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'public_staging'
        and tablename = 'stg_starlink_sattelite'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'public_staging'
    
    order by ordinal_position
[0m00:14:33.100661 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:14:33.104044 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.dim_starlink_sattelite"
[0m00:14:33.105633 [debug] [Thread-1 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (compile): 00:14:32.498415 => 00:14:33.105460
[0m00:14:33.105925 [debug] [Thread-1 (]: Began executing node model.dbt_remote.dim_starlink_sattelite
[0m00:14:33.134759 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.dim_starlink_sattelite"
[0m00:14:33.136654 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:14:33.136869 [debug] [Thread-1 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

  
    

  create  table
    "dev"."public_public"."dim_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    


with max_ingested as (
    select
        s.object_id,
        max(s.export_date) as last_ingested_date
    from "dev"."public_staging"."stg_starlink_sattelite" s
    group  by 1)

select
    s."object_id",
  s."object_name",
  s."launch_id",
  s."version_id",
  s."latitude",
  s."longitude",
  s."velocity_kms",
  s."center_name",
  s."time_system",
  s."launch_date",
  s."export_date",
    case when s.export_date != m.last_ingested_date then true else false end as deleted_flag
from
    "dev"."public_staging"."stg_starlink_sattelite" s

left join max_ingested m
on m.object_id = s.object_id

where s.rnk = 1
  );
[0m00:14:33.488196 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:14:33.493655 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:14:33.493946 [debug] [Thread-1 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "dev"."public_public"."dim_starlink_sattelite" rename to "dim_starlink_sattelite__dbt_backup"
[0m00:14:33.720374 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:14:33.723739 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:14:33.724063 [debug] [Thread-1 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "dev"."public_public"."dim_starlink_sattelite__dbt_tmp" rename to "dim_starlink_sattelite"
[0m00:14:33.838568 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:14:33.859796 [debug] [Thread-1 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m00:14:33.860263 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:14:33.860537 [debug] [Thread-1 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m00:14:35.013454 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m00:14:35.014115 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:14:35.014399 [debug] [Thread-1 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m00:14:35.090629 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:14:35.100309 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:14:35.100744 [debug] [Thread-1 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
drop table if exists "dev"."public_public"."dim_starlink_sattelite__dbt_backup" cascade
[0m00:14:35.179076 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:14:35.180080 [debug] [Thread-1 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m00:14:35.180475 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:14:35.180769 [debug] [Thread-1 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m00:14:36.074648 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m00:14:36.075798 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:14:36.076482 [debug] [Thread-1 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m00:14:36.114454 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:14:36.116679 [debug] [Thread-1 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (execute): 00:14:33.106098 => 00:14:36.116391
[0m00:14:36.117348 [debug] [Thread-1 (]: On model.dbt_remote.dim_starlink_sattelite: ROLLBACK
[0m00:14:36.194980 [debug] [Thread-1 (]: On model.dbt_remote.dim_starlink_sattelite: Close
[0m00:14:36.197757 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16793aca-2111-4323-ae41-be36b70a3751', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066d7190>]}
[0m00:14:36.199207 [info ] [Thread-1 (]: 1 of 1 OK created sql table model public_public.dim_starlink_sattelite ......... [[32mSUCCESS[0m in 3.70s]
[0m00:14:36.200375 [debug] [Thread-1 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m00:14:36.205337 [debug] [MainThread]: Using redshift connection "master"
[0m00:14:36.206014 [debug] [MainThread]: On master: BEGIN
[0m00:14:36.206450 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:14:36.207096 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:14:36.207528 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:14:36.585976 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:14:36.586895 [debug] [MainThread]: On master: COMMIT
[0m00:14:36.587664 [debug] [MainThread]: Using redshift connection "master"
[0m00:14:36.588415 [debug] [MainThread]: On master: COMMIT
[0m00:14:36.667629 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:14:36.669092 [debug] [MainThread]: On master: Close
[0m00:14:36.671772 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:14:36.672625 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_sattelite' was properly closed.
[0m00:14:36.673115 [debug] [MainThread]: Connection 'list_dev_public_staging' was properly closed.
[0m00:14:36.673719 [info ] [MainThread]: 
[0m00:14:36.674388 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 33.44 seconds (33.44s).
[0m00:14:36.675537 [debug] [MainThread]: Command end result
[0m00:14:36.693465 [info ] [MainThread]: 
[0m00:14:36.694078 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:14:36.694548 [info ] [MainThread]: 
[0m00:14:36.694943 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m00:14:36.695609 [debug] [MainThread]: Command `dbt run` succeeded at 00:14:36.695491 after 33.63 seconds
[0m00:14:36.696045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102b95e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ebb750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102ba8110>]}
[0m00:14:36.696461 [debug] [MainThread]: Flushing usage events
[0m00:54:33.784697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10807da10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109539f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10927b990>]}


============================== 00:54:33.787711 | 7555711f-e025-4950-94bd-e55044c5f619 ==============================
[0m00:54:33.787711 [info ] [MainThread]: Running with dbt=1.6.0
[0m00:54:33.788056 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s +dim_starlink_sattelite', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:54:33.889615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7555711f-e025-4950-94bd-e55044c5f619', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10927a550>]}
[0m00:54:33.894205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7555711f-e025-4950-94bd-e55044c5f619', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ab3e10>]}
[0m00:54:33.894823 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m00:54:33.902980 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m00:54:33.929880 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:54:33.930132 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:54:33.930461 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m00:54:33.934069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7555711f-e025-4950-94bd-e55044c5f619', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109602c10>]}
[0m00:54:33.941723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7555711f-e025-4950-94bd-e55044c5f619', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b1d590>]}
[0m00:54:33.942026 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 511 macros, 0 groups, 0 semantic models
[0m00:54:33.942197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7555711f-e025-4950-94bd-e55044c5f619', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a34150>]}
[0m00:54:33.943066 [info ] [MainThread]: 
[0m00:54:33.943488 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m00:54:33.944058 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m00:54:33.944436 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m00:54:33.952983 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m00:54:33.954692 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m00:54:33.954969 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m00:54:33.955113 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m00:54:33.955250 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:54:33.955374 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:54:33.955957 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:54:33.956161 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:54:33.956305 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:54:33.956437 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:54:35.414010 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m00:54:35.415704 [debug] [ThreadPool]: On list_dev: Close
[0m00:54:35.416007 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m00:54:35.417136 [debug] [ThreadPool]: On list_dev: Close
[0m00:54:35.419137 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public_staging)
[0m00:54:35.419707 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_public_public)
[0m00:54:35.425766 [debug] [ThreadPool]: Using redshift connection "list_dev_public_staging"
[0m00:54:35.428611 [debug] [ThreadPool]: Using redshift connection "list_dev_public_public"
[0m00:54:35.428853 [debug] [ThreadPool]: On list_dev_public_staging: BEGIN
[0m00:54:35.429052 [debug] [ThreadPool]: On list_dev_public_public: BEGIN
[0m00:54:35.429231 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:54:35.429405 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:54:35.429716 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:54:35.429980 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:54:35.430180 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:54:35.430373 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:54:35.791231 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:35.791757 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:35.792337 [debug] [ThreadPool]: Using redshift connection "list_dev_public_staging"
[0m00:54:35.792763 [debug] [ThreadPool]: Using redshift connection "list_dev_public_public"
[0m00:54:35.793221 [debug] [ThreadPool]: On list_dev_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_staging'
[0m00:54:35.793726 [debug] [ThreadPool]: On list_dev_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "list_dev_public_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_public'
[0m00:54:35.887822 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:35.888724 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:35.891512 [debug] [ThreadPool]: On list_dev_public_public: ROLLBACK
[0m00:54:35.893649 [debug] [ThreadPool]: On list_dev_public_staging: ROLLBACK
[0m00:54:35.973719 [debug] [ThreadPool]: On list_dev_public_public: Close
[0m00:54:35.975509 [debug] [ThreadPool]: On list_dev_public_staging: Close
[0m00:54:35.985647 [debug] [MainThread]: Using redshift connection "master"
[0m00:54:35.986107 [debug] [MainThread]: On master: BEGIN
[0m00:54:35.986382 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:54:35.986898 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:54:35.987185 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:54:36.344735 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:36.347233 [debug] [MainThread]: Using redshift connection "master"
[0m00:54:36.348588 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m00:54:36.473155 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:36.475656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7555711f-e025-4950-94bd-e55044c5f619', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10919c510>]}
[0m00:54:36.477143 [debug] [MainThread]: On master: ROLLBACK
[0m00:54:36.573215 [debug] [MainThread]: Using redshift connection "master"
[0m00:54:36.573730 [debug] [MainThread]: On master: BEGIN
[0m00:54:36.611517 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:36.612038 [debug] [MainThread]: On master: COMMIT
[0m00:54:36.612421 [debug] [MainThread]: Using redshift connection "master"
[0m00:54:36.612700 [debug] [MainThread]: On master: COMMIT
[0m00:54:36.687075 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:36.687522 [debug] [MainThread]: On master: Close
[0m00:54:36.688376 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m00:54:36.688697 [info ] [MainThread]: 
[0m00:54:36.691443 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m00:54:36.691873 [info ] [Thread-1 (]: 1 of 2 START sql table model public_staging.stg_starlink_sattelite ............. [RUN]
[0m00:54:36.692709 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dev_public_staging, now model.dbt_remote.stg_starlink_sattelite)
[0m00:54:36.693000 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m00:54:36.696100 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m00:54:36.697475 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 00:54:36.693184 => 00:54:36.697317
[0m00:54:36.697754 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m00:54:36.733688 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m00:54:36.735317 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m00:54:36.735544 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m00:54:36.735705 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:54:36.735968 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:54:36.736141 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:54:37.093793 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:37.094655 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m00:54:37.095340 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "dev"."public_staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s
  );
[0m00:54:39.054338 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m00:54:39.068868 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m00:54:39.069601 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public_staging"."stg_starlink_sattelite" rename to "stg_starlink_sattelite__dbt_backup"
[0m00:54:39.260434 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:39.263393 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m00:54:39.263706 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "dev"."public_staging"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m00:54:39.378009 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:39.401412 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m00:54:39.401840 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m00:54:39.402133 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m00:54:40.499410 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m00:54:40.500705 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m00:54:40.501356 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m00:54:40.581159 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:40.594855 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m00:54:40.595330 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "dev"."public_staging"."stg_starlink_sattelite__dbt_backup" cascade
[0m00:54:40.674302 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:40.677460 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m00:54:40.678629 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m00:54:40.679330 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m00:54:41.593229 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m00:54:41.594714 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m00:54:41.595673 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m00:54:41.635994 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:41.639528 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 00:54:36.697929 => 00:54:41.638930
[0m00:54:41.640674 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m00:54:41.718557 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m00:54:41.722064 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7555711f-e025-4950-94bd-e55044c5f619', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e86850>]}
[0m00:54:41.723985 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_staging.stg_starlink_sattelite ........ [[32mSUCCESS[0m in 5.03s]
[0m00:54:41.725287 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m00:54:41.727980 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m00:54:41.729226 [info ] [Thread-3 (]: 2 of 2 START sql table model public_public.dim_starlink_sattelite .............. [RUN]
[0m00:54:41.730520 [debug] [Thread-3 (]: Acquiring new redshift connection 'model.dbt_remote.dim_starlink_sattelite'
[0m00:54:41.731155 [debug] [Thread-3 (]: Began compiling node model.dbt_remote.dim_starlink_sattelite
[0m00:54:41.773803 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:54:41.774207 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m00:54:41.774476 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m00:54:41.774929 [debug] [Thread-3 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:54:41.775313 [debug] [Thread-3 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:54:43.074793 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m00:54:43.076399 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:54:43.077714 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_starlink_sattelite'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_starlink_sattelite'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'public_staging'
        and tablename = 'stg_starlink_sattelite'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'public_staging'
    
    order by ordinal_position
[0m00:54:43.266453 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:43.276972 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_remote.dim_starlink_sattelite"
[0m00:54:43.279722 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (compile): 00:54:41.731563 => 00:54:43.279434
[0m00:54:43.280235 [debug] [Thread-3 (]: Began executing node model.dbt_remote.dim_starlink_sattelite
[0m00:54:43.289750 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_remote.dim_starlink_sattelite"
[0m00:54:43.293430 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:54:43.293950 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

  
    

  create  table
    "dev"."public_public"."dim_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    


with max_ingested as (
    select
        s.object_id,
        max(s.export_date) as last_ingested_date
    from "dev"."public_staging"."stg_starlink_sattelite" s
    group  by 1)

select
    s."object_id",
  s."object_name",
  s."launch_id",
  s."version_id",
  s."latitude",
  s."longitude",
  s."velocity_kms",
  s."center_name",
  s."time_system",
  s."launch_date",
  s."export_date",
    case when s.export_date != m.last_ingested_date then true else false end as deleted_flag
from
    "dev"."public_staging"."stg_starlink_sattelite" s

left join max_ingested m
on m.object_id = s.object_id

where s.rnk = 1
  );
[0m00:54:43.735010 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:43.738986 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:54:43.739490 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "dev"."public_public"."dim_starlink_sattelite" rename to "dim_starlink_sattelite__dbt_backup"
[0m00:54:43.969270 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:43.973325 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:54:43.973746 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "dev"."public_public"."dim_starlink_sattelite__dbt_tmp" rename to "dim_starlink_sattelite"
[0m00:54:44.087051 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:44.089378 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m00:54:44.089812 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:54:44.090105 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m00:54:45.169042 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m00:54:45.171506 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:54:45.172849 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m00:54:45.251577 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:45.256616 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:54:45.257143 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "dev", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
drop table if exists "dev"."public_public"."dim_starlink_sattelite__dbt_backup" cascade
[0m00:54:45.336403 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:45.337650 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m00:54:45.338162 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:54:45.338565 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m00:54:46.274743 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m00:54:46.276416 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m00:54:46.277426 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m00:54:46.316545 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:46.318832 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (execute): 00:54:43.280569 => 00:54:46.318440
[0m00:54:46.319428 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: ROLLBACK
[0m00:54:46.397581 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: Close
[0m00:54:46.400051 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7555711f-e025-4950-94bd-e55044c5f619', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a61d010>]}
[0m00:54:46.401452 [info ] [Thread-3 (]: 2 of 2 OK created sql table model public_public.dim_starlink_sattelite ......... [[32mSUCCESS[0m in 4.67s]
[0m00:54:46.402850 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m00:54:46.406234 [debug] [MainThread]: Using redshift connection "master"
[0m00:54:46.406760 [debug] [MainThread]: On master: BEGIN
[0m00:54:46.407158 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:54:46.407812 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:54:46.408226 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:54:46.780973 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:46.782357 [debug] [MainThread]: On master: COMMIT
[0m00:54:46.783460 [debug] [MainThread]: Using redshift connection "master"
[0m00:54:46.784176 [debug] [MainThread]: On master: COMMIT
[0m00:54:46.863687 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:54:46.864979 [debug] [MainThread]: On master: Close
[0m00:54:46.866987 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:54:46.868104 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m00:54:46.868793 [debug] [MainThread]: Connection 'list_dev_public_public' was properly closed.
[0m00:54:46.869215 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_sattelite' was properly closed.
[0m00:54:46.869744 [info ] [MainThread]: 
[0m00:54:46.870448 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 12.93 seconds (12.93s).
[0m00:54:46.871786 [debug] [MainThread]: Command end result
[0m00:54:46.888083 [info ] [MainThread]: 
[0m00:54:46.888692 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:54:46.889056 [info ] [MainThread]: 
[0m00:54:46.889457 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m00:54:46.890163 [debug] [MainThread]: Command `dbt run` succeeded at 00:54:46.890017 after 13.12 seconds
[0m00:54:46.890630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c67090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092577d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092f80d0>]}
[0m00:54:46.891064 [debug] [MainThread]: Flushing usage events
[0m01:43:30.145842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055b6c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055b7390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d1ed0>]}


============================== 01:43:30.148694 | 2afc8afc-fc85-4b13-bfdc-220ac368ebce ==============================
[0m01:43:30.148694 [info ] [MainThread]: Running with dbt=1.6.0
[0m01:43:30.149017 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run -s +dim_starlink_sattelite', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m01:43:30.246143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2afc8afc-fc85-4b13-bfdc-220ac368ebce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105604a50>]}
[0m01:43:30.250356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2afc8afc-fc85-4b13-bfdc-220ac368ebce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b8fe90>]}
[0m01:43:30.250845 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m01:43:30.260667 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m01:43:30.267248 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m01:43:30.267592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2afc8afc-fc85-4b13-bfdc-220ac368ebce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106422f90>]}
[0m01:43:30.812373 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m01:43:30.815427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2afc8afc-fc85-4b13-bfdc-220ac368ebce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055ffcd0>]}
[0m01:43:30.822671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2afc8afc-fc85-4b13-bfdc-220ac368ebce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106498f50>]}
[0m01:43:30.822956 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 511 macros, 0 groups, 0 semantic models
[0m01:43:30.823126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2afc8afc-fc85-4b13-bfdc-220ac368ebce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102835d90>]}
[0m01:43:30.823863 [info ] [MainThread]: 
[0m01:43:30.824241 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:43:30.824762 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m01:43:30.825121 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m01:43:30.832965 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m01:43:30.834237 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m01:43:30.834448 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m01:43:30.834639 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m01:43:30.834797 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:43:30.834946 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:43:30.835529 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:43:30.835772 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:43:30.835937 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:43:30.836087 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:43:31.425461 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m01:43:31.430104 [debug] [ThreadPool]: On list_analytics: Close
[0m01:43:31.434089 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m01:43:31.437423 [debug] [ThreadPool]: On list_analytics: Close
[0m01:43:31.439857 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_public_staging)
[0m01:43:31.440756 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_public_public)
[0m01:43:31.441757 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "public_staging"
"
[0m01:43:31.442639 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "public_public"
"
[0m01:43:31.452375 [debug] [ThreadPool]: Using redshift connection "create_analytics_public_staging"
[0m01:43:31.455593 [debug] [ThreadPool]: Using redshift connection "create_analytics_public_public"
[0m01:43:31.455968 [debug] [ThreadPool]: On create_analytics_public_staging: BEGIN
[0m01:43:31.456290 [debug] [ThreadPool]: On create_analytics_public_public: BEGIN
[0m01:43:31.456588 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:43:31.456885 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:43:31.457368 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:43:31.457811 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:43:31.458141 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:43:31.458458 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:43:31.842473 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:31.844709 [debug] [ThreadPool]: Using redshift connection "create_analytics_public_staging"
[0m01:43:31.845684 [debug] [ThreadPool]: On create_analytics_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "create_analytics_public_staging"} */
create schema if not exists "public_staging"
[0m01:43:31.848030 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:31.848976 [debug] [ThreadPool]: Using redshift connection "create_analytics_public_public"
[0m01:43:31.849684 [debug] [ThreadPool]: On create_analytics_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "create_analytics_public_public"} */
create schema if not exists "public_public"
[0m01:43:31.998516 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:31.999487 [debug] [ThreadPool]: On create_analytics_public_staging: COMMIT
[0m01:43:31.999842 [debug] [ThreadPool]: Using redshift connection "create_analytics_public_staging"
[0m01:43:32.000089 [debug] [ThreadPool]: On create_analytics_public_staging: COMMIT
[0m01:43:32.005857 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:32.006572 [debug] [ThreadPool]: On create_analytics_public_public: COMMIT
[0m01:43:32.006876 [debug] [ThreadPool]: Using redshift connection "create_analytics_public_public"
[0m01:43:32.007112 [debug] [ThreadPool]: On create_analytics_public_public: COMMIT
[0m01:43:33.846568 [debug] [ThreadPool]: SQL status: SUCCESS in 2.0 seconds
[0m01:43:33.848356 [debug] [ThreadPool]: SQL status: SUCCESS in 2.0 seconds
[0m01:43:33.849620 [debug] [ThreadPool]: On create_analytics_public_staging: Close
[0m01:43:33.850510 [debug] [ThreadPool]: On create_analytics_public_public: Close
[0m01:43:33.857016 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_analytics_public_staging, now list_analytics_public_staging)
[0m01:43:33.858193 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_analytics_public_public, now list_analytics_public_public)
[0m01:43:33.869088 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_staging"
[0m01:43:33.873777 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_public"
[0m01:43:33.874145 [debug] [ThreadPool]: On list_analytics_public_staging: BEGIN
[0m01:43:33.874464 [debug] [ThreadPool]: On list_analytics_public_public: BEGIN
[0m01:43:33.874774 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:43:33.875075 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:43:33.875638 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:43:33.876078 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:43:33.876412 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:43:33.876717 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:43:35.158662 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m01:43:35.159365 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_staging"
[0m01:43:35.159858 [debug] [ThreadPool]: On list_analytics_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics_public_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_staging'
[0m01:43:35.202780 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m01:43:35.203606 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_public"
[0m01:43:35.204426 [debug] [ThreadPool]: On list_analytics_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics_public_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_public'
[0m01:43:35.254902 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:35.257448 [debug] [ThreadPool]: On list_analytics_public_staging: ROLLBACK
[0m01:43:35.301031 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:35.303414 [debug] [ThreadPool]: On list_analytics_public_public: ROLLBACK
[0m01:43:35.341870 [debug] [ThreadPool]: On list_analytics_public_staging: Close
[0m01:43:35.388371 [debug] [ThreadPool]: On list_analytics_public_public: Close
[0m01:43:35.410145 [debug] [MainThread]: Using redshift connection "master"
[0m01:43:35.411019 [debug] [MainThread]: On master: BEGIN
[0m01:43:35.411520 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:43:35.412338 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:43:35.413122 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:43:35.813444 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:35.814250 [debug] [MainThread]: Using redshift connection "master"
[0m01:43:35.814899 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m01:43:35.907738 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:35.909930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2afc8afc-fc85-4b13-bfdc-220ac368ebce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065dd150>]}
[0m01:43:35.911186 [debug] [MainThread]: On master: ROLLBACK
[0m01:43:35.995972 [debug] [MainThread]: Using redshift connection "master"
[0m01:43:35.997097 [debug] [MainThread]: On master: BEGIN
[0m01:43:36.038800 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:36.039819 [debug] [MainThread]: On master: COMMIT
[0m01:43:36.040691 [debug] [MainThread]: Using redshift connection "master"
[0m01:43:36.041195 [debug] [MainThread]: On master: COMMIT
[0m01:43:36.123353 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:36.123831 [debug] [MainThread]: On master: Close
[0m01:43:36.124695 [info ] [MainThread]: Concurrency: 4 threads (target='production')
[0m01:43:36.125021 [info ] [MainThread]: 
[0m01:43:36.127698 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m01:43:36.128309 [info ] [Thread-1 (]: 1 of 2 START sql table model public_staging.stg_starlink_sattelite ............. [RUN]
[0m01:43:36.129321 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_public_staging, now model.dbt_remote.stg_starlink_sattelite)
[0m01:43:36.129667 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m01:43:36.133397 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m01:43:36.134656 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 01:43:36.129890 => 01:43:36.134416
[0m01:43:36.135075 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m01:43:36.168798 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m01:43:36.170567 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:43:36.170814 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:43:36.171000 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:43:36.171309 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:43:36.171505 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:43:36.531499 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:36.532644 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:43:36.533369 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "analytics"."public_staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s
  );
[0m01:43:36.587880 [debug] [Thread-1 (]: Redshift adapter: Redshift error: Relation starlink_satellites does not exist in the database.
[0m01:43:36.589343 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m01:43:36.669333 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 01:43:36.135326 => 01:43:36.668280
[0m01:43:36.670909 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m01:43:36.680540 [debug] [Thread-1 (]: Database Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)
  Relation starlink_satellites does not exist in the database.
  compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m01:43:36.681341 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2afc8afc-fc85-4b13-bfdc-220ac368ebce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10649a050>]}
[0m01:43:36.682147 [error] [Thread-1 (]: 1 of 2 ERROR creating sql table model public_staging.stg_starlink_sattelite .... [[31mERROR[0m in 0.55s]
[0m01:43:36.682986 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m01:43:36.685265 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m01:43:36.685980 [info ] [Thread-3 (]: 2 of 2 SKIP relation public_public.dim_starlink_sattelite ...................... [[33mSKIP[0m]
[0m01:43:36.686620 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m01:43:36.689270 [debug] [MainThread]: Using redshift connection "master"
[0m01:43:36.689662 [debug] [MainThread]: On master: BEGIN
[0m01:43:36.689982 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:43:36.690498 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:43:36.690851 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:43:38.008877 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m01:43:38.009466 [debug] [MainThread]: On master: COMMIT
[0m01:43:38.009918 [debug] [MainThread]: Using redshift connection "master"
[0m01:43:38.010249 [debug] [MainThread]: On master: COMMIT
[0m01:43:38.088008 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:38.088926 [debug] [MainThread]: On master: Close
[0m01:43:38.090402 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:43:38.091204 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m01:43:38.091911 [debug] [MainThread]: Connection 'list_analytics_public_public' was properly closed.
[0m01:43:38.092523 [info ] [MainThread]: 
[0m01:43:38.093100 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 7.27 seconds (7.27s).
[0m01:43:38.094236 [debug] [MainThread]: Command end result
[0m01:43:38.118789 [info ] [MainThread]: 
[0m01:43:38.119298 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m01:43:38.119597 [info ] [MainThread]: 
[0m01:43:38.119879 [error] [MainThread]: [33mDatabase Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)[0m
[0m01:43:38.120154 [error] [MainThread]:   Relation starlink_satellites does not exist in the database.
[0m01:43:38.120413 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m01:43:38.120749 [info ] [MainThread]: 
[0m01:43:38.121170 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
[0m01:43:38.121845 [debug] [MainThread]: Command `dbt run` failed at 01:43:38.121732 after 7.99 seconds
[0m01:43:38.122260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10116b090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1011690d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10590a0d0>]}
[0m01:43:38.122624 [debug] [MainThread]: Flushing usage events
[0m01:43:55.383878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b70990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b72990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b62d90>]}


============================== 01:43:55.386389 | 42fb6880-7baa-428f-8067-cca00b7cac2f ==============================
[0m01:43:55.386389 [info ] [MainThread]: Running with dbt=1.6.0
[0m01:43:55.386699 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m01:43:55.461883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '42fb6880-7baa-428f-8067-cca00b7cac2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b541d0>]}
[0m01:43:55.466252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '42fb6880-7baa-428f-8067-cca00b7cac2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053c0f90>]}
[0m01:43:55.466786 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m01:43:55.475120 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m01:43:55.493658 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:43:55.493901 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:43:55.494222 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m01:43:55.497420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '42fb6880-7baa-428f-8067-cca00b7cac2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b13050>]}
[0m01:43:55.503881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '42fb6880-7baa-428f-8067-cca00b7cac2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105415810>]}
[0m01:43:55.504206 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 511 macros, 0 groups, 0 semantic models
[0m01:43:55.504382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '42fb6880-7baa-428f-8067-cca00b7cac2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105123bd0>]}
[0m01:43:55.505221 [info ] [MainThread]: 
[0m01:43:55.505667 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:43:55.506249 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m01:43:55.514586 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m01:43:55.514952 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m01:43:55.515087 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m01:43:55.516432 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m01:43:55.516582 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:43:55.516720 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m01:43:55.517288 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:43:55.517465 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:43:55.517618 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:43:55.517809 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:43:55.518917 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:43:55.960331 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:55.961318 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:55.964608 [debug] [ThreadPool]: On list_analytics: Close
[0m01:43:55.967106 [debug] [ThreadPool]: On list_analytics: Close
[0m01:43:55.970429 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_public_public)
[0m01:43:55.971575 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_public_staging)
[0m01:43:55.981174 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_public"
[0m01:43:55.985691 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_staging"
[0m01:43:55.986079 [debug] [ThreadPool]: On list_analytics_public_public: BEGIN
[0m01:43:55.986410 [debug] [ThreadPool]: On list_analytics_public_staging: BEGIN
[0m01:43:55.986717 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:43:55.987009 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:43:55.987499 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:43:55.987941 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:43:55.988260 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:43:55.988540 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:43:56.371795 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:56.372737 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:56.373584 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_public"
[0m01:43:56.374286 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_staging"
[0m01:43:56.374883 [debug] [ThreadPool]: On list_analytics_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics_public_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_public'
[0m01:43:56.375490 [debug] [ThreadPool]: On list_analytics_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics_public_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_staging'
[0m01:43:56.473662 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:56.474121 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:56.475646 [debug] [ThreadPool]: On list_analytics_public_public: ROLLBACK
[0m01:43:56.476932 [debug] [ThreadPool]: On list_analytics_public_staging: ROLLBACK
[0m01:43:56.561720 [debug] [ThreadPool]: On list_analytics_public_public: Close
[0m01:43:56.563323 [debug] [ThreadPool]: On list_analytics_public_staging: Close
[0m01:43:56.574939 [debug] [MainThread]: Using redshift connection "master"
[0m01:43:56.575350 [debug] [MainThread]: On master: BEGIN
[0m01:43:56.575663 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:43:56.576160 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:43:56.576501 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:43:56.948368 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:56.949404 [debug] [MainThread]: Using redshift connection "master"
[0m01:43:56.950057 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m01:43:57.039587 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:57.041959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '42fb6880-7baa-428f-8067-cca00b7cac2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10512d3d0>]}
[0m01:43:57.042818 [debug] [MainThread]: On master: ROLLBACK
[0m01:43:57.121343 [debug] [MainThread]: Using redshift connection "master"
[0m01:43:57.122270 [debug] [MainThread]: On master: BEGIN
[0m01:43:57.161643 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:57.162816 [debug] [MainThread]: On master: COMMIT
[0m01:43:57.163739 [debug] [MainThread]: Using redshift connection "master"
[0m01:43:57.164365 [debug] [MainThread]: On master: COMMIT
[0m01:43:57.239872 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:57.240848 [debug] [MainThread]: On master: Close
[0m01:43:57.242931 [info ] [MainThread]: Concurrency: 4 threads (target='production')
[0m01:43:57.243630 [info ] [MainThread]: 
[0m01:43:57.247240 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m01:43:57.247994 [info ] [Thread-1 (]: 1 of 2 START sql table model public_staging.stg_starlink_sattelite ............. [RUN]
[0m01:43:57.249582 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_public_public, now model.dbt_remote.stg_starlink_sattelite)
[0m01:43:57.250138 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m01:43:57.254156 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m01:43:57.254822 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 01:43:57.250485 => 01:43:57.254685
[0m01:43:57.255053 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m01:43:57.301747 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m01:43:57.303712 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:43:57.303967 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:43:57.304189 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:43:57.304533 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:43:57.304773 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:43:57.661860 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:57.662231 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:43:57.662481 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "analytics"."public_staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "dev"."raw"."starlink_satellites" s
  );
[0m01:43:57.715442 [debug] [Thread-1 (]: Redshift adapter: Redshift error: Relation starlink_satellites does not exist in the database.
[0m01:43:57.715955 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m01:43:57.790098 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 01:43:57.255182 => 01:43:57.789841
[0m01:43:57.790553 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m01:43:57.795852 [debug] [Thread-1 (]: Database Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)
  Relation starlink_satellites does not exist in the database.
  compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m01:43:57.796431 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42fb6880-7baa-428f-8067-cca00b7cac2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105eb3f90>]}
[0m01:43:57.797101 [error] [Thread-1 (]: 1 of 2 ERROR creating sql table model public_staging.stg_starlink_sattelite .... [[31mERROR[0m in 0.55s]
[0m01:43:57.797874 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m01:43:57.799763 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m01:43:57.800270 [info ] [Thread-3 (]: 2 of 2 SKIP relation public_public.dim_starlink_sattelite ...................... [[33mSKIP[0m]
[0m01:43:57.800695 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m01:43:57.802608 [debug] [MainThread]: Using redshift connection "master"
[0m01:43:57.802999 [debug] [MainThread]: On master: BEGIN
[0m01:43:57.803272 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:43:57.803782 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:43:57.804090 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:43:58.174255 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:58.175340 [debug] [MainThread]: On master: COMMIT
[0m01:43:58.176152 [debug] [MainThread]: Using redshift connection "master"
[0m01:43:58.176841 [debug] [MainThread]: On master: COMMIT
[0m01:43:58.256398 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:43:58.257560 [debug] [MainThread]: On master: Close
[0m01:43:58.259556 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:43:58.260312 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m01:43:58.261069 [debug] [MainThread]: Connection 'list_analytics_public_staging' was properly closed.
[0m01:43:58.261995 [info ] [MainThread]: 
[0m01:43:58.262934 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 2.76 seconds (2.76s).
[0m01:43:58.264222 [debug] [MainThread]: Command end result
[0m01:43:58.281740 [info ] [MainThread]: 
[0m01:43:58.282273 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m01:43:58.282617 [info ] [MainThread]: 
[0m01:43:58.282950 [error] [MainThread]: [33mDatabase Error in model stg_starlink_sattelite (models/Starlink/stg_starlink_sattelite.sql)[0m
[0m01:43:58.283276 [error] [MainThread]:   Relation starlink_satellites does not exist in the database.
[0m01:43:58.283577 [error] [MainThread]:   compiled Code at target/run/dbt_remote/models/Starlink/stg_starlink_sattelite.sql
[0m01:43:58.283874 [info ] [MainThread]: 
[0m01:43:58.284211 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
[0m01:43:58.284854 [debug] [MainThread]: Command `dbt run` failed at 01:43:58.284740 after 2.91 seconds
[0m01:43:58.285307 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100980f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100981010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1008e07d0>]}
[0m01:43:58.285739 [debug] [MainThread]: Flushing usage events
[0m01:44:24.034706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10978e9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10969b010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109488d10>]}


============================== 01:44:24.037587 | e6659d92-8dd4-47d1-9a66-71187673220d ==============================
[0m01:44:24.037587 [info ] [MainThread]: Running with dbt=1.6.0
[0m01:44:24.037900 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m01:44:24.131712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e6659d92-8dd4-47d1-9a66-71187673220d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096b68d0>]}
[0m01:44:24.136033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e6659d92-8dd4-47d1-9a66-71187673220d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109993750>]}
[0m01:44:24.136561 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m01:44:24.144211 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m01:44:24.169259 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m01:44:24.169752 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/schema.yml
[0m01:44:24.218055 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m01:44:24.221010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e6659d92-8dd4-47d1-9a66-71187673220d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5bea90>]}
[0m01:44:24.227396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e6659d92-8dd4-47d1-9a66-71187673220d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a625f10>]}
[0m01:44:24.227691 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 511 macros, 0 groups, 0 semantic models
[0m01:44:24.227864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e6659d92-8dd4-47d1-9a66-71187673220d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068e5610>]}
[0m01:44:24.228699 [info ] [MainThread]: 
[0m01:44:24.229101 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:44:24.229655 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m01:44:24.238245 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m01:44:24.238516 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m01:44:24.238662 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:44:24.239173 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:44:24.239330 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:44:24.240474 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m01:44:24.241784 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m01:44:24.241942 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m01:44:24.242072 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:44:24.242257 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:44:24.242396 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:44:24.697896 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:24.699518 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:24.703218 [debug] [ThreadPool]: On list_analytics: Close
[0m01:44:24.705845 [debug] [ThreadPool]: On list_analytics: Close
[0m01:44:24.709586 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_public_public)
[0m01:44:24.710688 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_public_staging)
[0m01:44:24.720733 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_public"
[0m01:44:24.725265 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_staging"
[0m01:44:24.725648 [debug] [ThreadPool]: On list_analytics_public_public: BEGIN
[0m01:44:24.725972 [debug] [ThreadPool]: On list_analytics_public_staging: BEGIN
[0m01:44:24.726274 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:44:24.726572 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:44:24.727091 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:44:24.727537 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:44:24.727872 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:44:24.728187 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:44:25.099950 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:25.101183 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_public"
[0m01:44:25.102462 [debug] [ThreadPool]: On list_analytics_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics_public_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_public'
[0m01:44:25.104400 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:25.105301 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_staging"
[0m01:44:25.105970 [debug] [ThreadPool]: On list_analytics_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics_public_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_staging'
[0m01:44:25.196770 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:25.200885 [debug] [ThreadPool]: On list_analytics_public_public: ROLLBACK
[0m01:44:25.201720 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:25.204900 [debug] [ThreadPool]: On list_analytics_public_staging: ROLLBACK
[0m01:44:25.287150 [debug] [ThreadPool]: On list_analytics_public_public: Close
[0m01:44:25.289657 [debug] [ThreadPool]: On list_analytics_public_staging: Close
[0m01:44:25.304292 [debug] [MainThread]: Using redshift connection "master"
[0m01:44:25.304798 [debug] [MainThread]: On master: BEGIN
[0m01:44:25.305177 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:44:25.305784 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:44:25.306235 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:44:25.696958 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:25.698711 [debug] [MainThread]: Using redshift connection "master"
[0m01:44:25.700022 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m01:44:25.793633 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:25.797731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e6659d92-8dd4-47d1-9a66-71187673220d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5be910>]}
[0m01:44:25.798955 [debug] [MainThread]: On master: ROLLBACK
[0m01:44:25.883884 [debug] [MainThread]: Using redshift connection "master"
[0m01:44:25.885437 [debug] [MainThread]: On master: BEGIN
[0m01:44:25.927319 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:25.928436 [debug] [MainThread]: On master: COMMIT
[0m01:44:25.929607 [debug] [MainThread]: Using redshift connection "master"
[0m01:44:25.930789 [debug] [MainThread]: On master: COMMIT
[0m01:44:26.011735 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:26.013110 [debug] [MainThread]: On master: Close
[0m01:44:26.015729 [info ] [MainThread]: Concurrency: 4 threads (target='production')
[0m01:44:26.016721 [info ] [MainThread]: 
[0m01:44:26.021946 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m01:44:26.022729 [info ] [Thread-1 (]: 1 of 2 START sql table model public_staging.stg_starlink_sattelite ............. [RUN]
[0m01:44:26.023806 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_public_public, now model.dbt_remote.stg_starlink_sattelite)
[0m01:44:26.024433 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m01:44:26.027711 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m01:44:26.028205 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 01:44:26.024806 => 01:44:26.028097
[0m01:44:26.028389 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m01:44:26.073879 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m01:44:26.075813 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:44:26.076071 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:44:26.076290 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:44:26.076634 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:44:26.076875 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:44:26.439045 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:26.440296 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:44:26.441151 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "analytics"."public_staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "analytics"."raw"."starlink_satellites" s
  );
[0m01:44:28.354248 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m01:44:28.368288 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:44:28.368948 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "analytics"."public_staging"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m01:44:28.564912 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:28.598018 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:44:28.598578 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:44:28.598927 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:44:29.622449 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:44:29.624249 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:44:29.625126 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:44:29.704727 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:29.721962 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:44:29.722696 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "analytics"."public_staging"."stg_starlink_sattelite__dbt_backup" cascade
[0m01:44:29.800896 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:29.805231 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:44:29.806592 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:44:29.807293 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:44:29.853194 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:29.855048 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:44:29.856061 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:44:29.896342 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:29.899666 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 01:44:26.028501 => 01:44:29.899170
[0m01:44:29.900679 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m01:44:29.980092 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m01:44:29.983755 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6659d92-8dd4-47d1-9a66-71187673220d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7f9890>]}
[0m01:44:29.985623 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_staging.stg_starlink_sattelite ........ [[32mSUCCESS[0m in 3.96s]
[0m01:44:29.987351 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m01:44:29.989945 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m01:44:29.991157 [info ] [Thread-3 (]: 2 of 2 START sql table model public_public.dim_starlink_sattelite .............. [RUN]
[0m01:44:29.992380 [debug] [Thread-3 (]: Acquiring new redshift connection 'model.dbt_remote.dim_starlink_sattelite'
[0m01:44:29.992889 [debug] [Thread-3 (]: Began compiling node model.dbt_remote.dim_starlink_sattelite
[0m01:44:30.023460 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:44:30.023923 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:44:30.024219 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m01:44:30.024721 [debug] [Thread-3 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:44:30.025128 [debug] [Thread-3 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:44:30.410746 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:30.412209 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:44:30.413579 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_starlink_sattelite'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_starlink_sattelite'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'public_staging'
        and tablename = 'stg_starlink_sattelite'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'public_staging'
    
    order by ordinal_position
[0m01:44:30.600078 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:30.609236 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_remote.dim_starlink_sattelite"
[0m01:44:30.611545 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (compile): 01:44:29.993216 => 01:44:30.611251
[0m01:44:30.612066 [debug] [Thread-3 (]: Began executing node model.dbt_remote.dim_starlink_sattelite
[0m01:44:30.619362 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_remote.dim_starlink_sattelite"
[0m01:44:30.622718 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:44:30.623171 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

  
    

  create  table
    "analytics"."public_public"."dim_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    


with max_ingested as (
    select
        s.object_id,
        max(s.export_date) as last_ingested_date
    from "analytics"."public_staging"."stg_starlink_sattelite" s
    group  by 1)

select
    s."object_id",
  s."object_name",
  s."launch_id",
  s."version_id",
  s."latitude",
  s."longitude",
  s."velocity_kms",
  s."center_name",
  s."time_system",
  s."launch_date",
  s."export_date",
    case when s.export_date != m.last_ingested_date then true else false end as deleted_flag
from
    "analytics"."public_staging"."stg_starlink_sattelite" s

left join max_ingested m
on m.object_id = s.object_id

where s.rnk = 1
  );
[0m01:44:31.039567 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:31.048715 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:44:31.049445 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "analytics"."public_public"."dim_starlink_sattelite__dbt_tmp" rename to "dim_starlink_sattelite"
[0m01:44:31.278881 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:31.284881 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:44:31.285798 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:44:31.286494 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:44:32.203044 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:44:32.205442 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:44:32.206576 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:44:32.286833 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:32.294581 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:44:32.295582 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
drop table if exists "analytics"."public_public"."dim_starlink_sattelite__dbt_backup" cascade
[0m01:44:32.375949 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:32.379141 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:44:32.380782 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:44:32.381695 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:44:32.426461 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:32.427515 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:44:32.428201 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:44:32.467670 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:32.469636 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (execute): 01:44:30.612403 => 01:44:32.469245
[0m01:44:32.470687 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: ROLLBACK
[0m01:44:32.549840 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: Close
[0m01:44:32.552927 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6659d92-8dd4-47d1-9a66-71187673220d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a74a250>]}
[0m01:44:32.554497 [info ] [Thread-3 (]: 2 of 2 OK created sql table model public_public.dim_starlink_sattelite ......... [[32mSUCCESS[0m in 2.56s]
[0m01:44:32.555675 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m01:44:32.559487 [debug] [MainThread]: Using redshift connection "master"
[0m01:44:32.560024 [debug] [MainThread]: On master: BEGIN
[0m01:44:32.560403 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:44:32.561081 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:44:32.561538 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:44:32.930560 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:32.932316 [debug] [MainThread]: On master: COMMIT
[0m01:44:32.933451 [debug] [MainThread]: Using redshift connection "master"
[0m01:44:32.934300 [debug] [MainThread]: On master: COMMIT
[0m01:44:33.012140 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:44:33.013756 [debug] [MainThread]: On master: Close
[0m01:44:33.016642 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:44:33.017643 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m01:44:33.018553 [debug] [MainThread]: Connection 'list_analytics_public_staging' was properly closed.
[0m01:44:33.019424 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_sattelite' was properly closed.
[0m01:44:33.020287 [info ] [MainThread]: 
[0m01:44:33.020815 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 8.79 seconds (8.79s).
[0m01:44:33.022308 [debug] [MainThread]: Command end result
[0m01:44:33.088727 [info ] [MainThread]: 
[0m01:44:33.089036 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:44:33.089310 [info ] [MainThread]: 
[0m01:44:33.089545 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m01:44:33.089924 [debug] [MainThread]: Command `dbt run` succeeded at 01:44:33.089856 after 9.07 seconds
[0m01:44:33.090163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a9a190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050d1cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105167d50>]}
[0m01:44:33.090390 [debug] [MainThread]: Flushing usage events
[0m01:52:20.124166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f83090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052d6490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105250d50>]}


============================== 01:52:20.126972 | 7b0acf90-fdbc-4daa-9f90-1ae085b3ef8d ==============================
[0m01:52:20.126972 [info ] [MainThread]: Running with dbt=1.6.0
[0m01:52:20.127296 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m01:52:20.224169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7b0acf90-fdbc-4daa-9f90-1ae085b3ef8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052481d0>]}
[0m01:52:20.228371 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7b0acf90-fdbc-4daa-9f90-1ae085b3ef8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057cf910>]}
[0m01:52:20.228866 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m01:52:20.238112 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m01:52:20.264178 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m01:52:20.264565 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m01:52:20.297570 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m01:52:20.300795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7b0acf90-fdbc-4daa-9f90-1ae085b3ef8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f8d250>]}
[0m01:52:20.307995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7b0acf90-fdbc-4daa-9f90-1ae085b3ef8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106130ed0>]}
[0m01:52:20.308312 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 511 macros, 0 groups, 0 semantic models
[0m01:52:20.308489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7b0acf90-fdbc-4daa-9f90-1ae085b3ef8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061786d0>]}
[0m01:52:20.309491 [info ] [MainThread]: 
[0m01:52:20.309999 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:52:20.310668 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m01:52:20.311095 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m01:52:20.320729 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m01:52:20.322377 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m01:52:20.322545 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m01:52:20.322690 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m01:52:20.322825 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:52:20.322950 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:52:20.323449 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:52:20.323640 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:52:20.323781 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:52:20.323915 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:52:20.918207 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m01:52:20.919428 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m01:52:20.922916 [debug] [ThreadPool]: On list_analytics: Close
[0m01:52:20.925705 [debug] [ThreadPool]: On list_analytics: Close
[0m01:52:20.929021 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_public_staging)
[0m01:52:20.930014 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_public_public)
[0m01:52:20.931063 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "public_staging"
"
[0m01:52:20.932027 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "public_public"
"
[0m01:52:20.940893 [debug] [ThreadPool]: Using redshift connection "create_analytics_public_staging"
[0m01:52:20.944966 [debug] [ThreadPool]: Using redshift connection "create_analytics_public_public"
[0m01:52:20.945358 [debug] [ThreadPool]: On create_analytics_public_staging: BEGIN
[0m01:52:20.945683 [debug] [ThreadPool]: On create_analytics_public_public: BEGIN
[0m01:52:20.946045 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:52:20.946346 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:52:20.946883 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:52:20.947333 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:52:20.947667 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:52:20.947985 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:52:21.340181 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:21.341711 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:21.342864 [debug] [ThreadPool]: Using redshift connection "create_analytics_public_staging"
[0m01:52:21.343770 [debug] [ThreadPool]: Using redshift connection "create_analytics_public_public"
[0m01:52:21.344454 [debug] [ThreadPool]: On create_analytics_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "create_analytics_public_staging"} */
create schema if not exists "public_staging"
[0m01:52:21.345572 [debug] [ThreadPool]: On create_analytics_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "create_analytics_public_public"} */
create schema if not exists "public_public"
[0m01:52:21.499616 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:21.503067 [debug] [ThreadPool]: On create_analytics_public_staging: COMMIT
[0m01:52:21.503917 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:21.504889 [debug] [ThreadPool]: Using redshift connection "create_analytics_public_staging"
[0m01:52:21.506781 [debug] [ThreadPool]: On create_analytics_public_public: COMMIT
[0m01:52:21.507663 [debug] [ThreadPool]: On create_analytics_public_staging: COMMIT
[0m01:52:21.508533 [debug] [ThreadPool]: Using redshift connection "create_analytics_public_public"
[0m01:52:21.509310 [debug] [ThreadPool]: On create_analytics_public_public: COMMIT
[0m01:52:23.367514 [debug] [ThreadPool]: SQL status: SUCCESS in 2.0 seconds
[0m01:52:23.368524 [debug] [ThreadPool]: SQL status: SUCCESS in 2.0 seconds
[0m01:52:23.369745 [debug] [ThreadPool]: On create_analytics_public_staging: Close
[0m01:52:23.370736 [debug] [ThreadPool]: On create_analytics_public_public: Close
[0m01:52:23.377053 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_analytics_public_staging, now list_analytics_public_staging)
[0m01:52:23.378295 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_analytics_public_public, now list_analytics_public_public)
[0m01:52:23.388804 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_staging"
[0m01:52:23.393281 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_public"
[0m01:52:23.393674 [debug] [ThreadPool]: On list_analytics_public_staging: BEGIN
[0m01:52:23.393992 [debug] [ThreadPool]: On list_analytics_public_public: BEGIN
[0m01:52:23.394286 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:52:23.394572 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:52:23.395055 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:52:23.395495 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:52:23.395834 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:52:23.396148 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:52:23.778512 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:23.780221 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:23.781021 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_public"
[0m01:52:23.782066 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_staging"
[0m01:52:23.783197 [debug] [ThreadPool]: On list_analytics_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics_public_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_public'
[0m01:52:23.784414 [debug] [ThreadPool]: On list_analytics_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics_public_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_staging'
[0m01:52:23.884086 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:23.884932 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:23.888317 [debug] [ThreadPool]: On list_analytics_public_public: ROLLBACK
[0m01:52:23.891086 [debug] [ThreadPool]: On list_analytics_public_staging: ROLLBACK
[0m01:52:23.979950 [debug] [ThreadPool]: On list_analytics_public_staging: Close
[0m01:52:23.981103 [debug] [ThreadPool]: On list_analytics_public_public: Close
[0m01:52:23.997215 [debug] [MainThread]: Using redshift connection "master"
[0m01:52:23.997832 [debug] [MainThread]: On master: BEGIN
[0m01:52:23.998235 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:52:23.998868 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:52:23.999288 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:52:24.376523 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:24.377877 [debug] [MainThread]: Using redshift connection "master"
[0m01:52:24.379742 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m01:52:24.468130 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:24.472042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7b0acf90-fdbc-4daa-9f90-1ae085b3ef8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b93390>]}
[0m01:52:24.473592 [debug] [MainThread]: On master: ROLLBACK
[0m01:52:24.552621 [debug] [MainThread]: Using redshift connection "master"
[0m01:52:24.553903 [debug] [MainThread]: On master: BEGIN
[0m01:52:24.592653 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:24.593959 [debug] [MainThread]: On master: COMMIT
[0m01:52:24.595340 [debug] [MainThread]: Using redshift connection "master"
[0m01:52:24.595987 [debug] [MainThread]: On master: COMMIT
[0m01:52:24.672901 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:24.673368 [debug] [MainThread]: On master: Close
[0m01:52:24.674233 [info ] [MainThread]: Concurrency: 4 threads (target='production')
[0m01:52:24.674532 [info ] [MainThread]: 
[0m01:52:24.677497 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m01:52:24.678045 [info ] [Thread-1 (]: 1 of 2 START sql table model public_staging.stg_starlink_sattelite ............. [RUN]
[0m01:52:24.679008 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_public_staging, now model.dbt_remote.stg_starlink_sattelite)
[0m01:52:24.679359 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m01:52:24.682936 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m01:52:24.683876 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 01:52:24.679583 => 01:52:24.683662
[0m01:52:24.684214 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m01:52:24.716977 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m01:52:24.718513 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:52:24.718714 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:52:24.718890 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:52:24.719181 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:52:24.719368 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:52:25.086463 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:25.087955 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:52:25.089164 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "analytics"."public_staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "analytics"."raw"."starlink_satellites" s
  );
[0m01:52:27.049205 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m01:52:27.071794 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:52:27.072372 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "analytics"."public_staging"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m01:52:27.269818 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:27.299835 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:52:27.300417 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:52:27.300795 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:52:28.440761 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:52:28.442972 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:52:28.444056 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:52:28.522326 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:28.533884 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:52:28.534407 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "analytics"."public_staging"."stg_starlink_sattelite__dbt_backup" cascade
[0m01:52:28.611593 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:28.612878 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:52:28.613394 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:52:28.613782 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:52:28.658039 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:28.658636 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:52:28.659094 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:52:28.705633 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:28.706910 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 01:52:24.684419 => 01:52:28.706696
[0m01:52:28.707345 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m01:52:28.785019 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m01:52:28.788062 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7b0acf90-fdbc-4daa-9f90-1ae085b3ef8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105839810>]}
[0m01:52:28.789709 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_staging.stg_starlink_sattelite ........ [[32mSUCCESS[0m in 4.11s]
[0m01:52:28.791364 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m01:52:28.793667 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m01:52:28.794438 [info ] [Thread-3 (]: 2 of 2 START sql table model public_public.dim_starlink_sattelite .............. [RUN]
[0m01:52:28.795562 [debug] [Thread-3 (]: Acquiring new redshift connection 'model.dbt_remote.dim_starlink_sattelite'
[0m01:52:28.796043 [debug] [Thread-3 (]: Began compiling node model.dbt_remote.dim_starlink_sattelite
[0m01:52:28.839049 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:52:28.839482 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:52:28.839752 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m01:52:28.840200 [debug] [Thread-3 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:52:28.840569 [debug] [Thread-3 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:52:29.207252 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:29.209061 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:52:29.210648 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_starlink_sattelite'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_starlink_sattelite'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'public_staging'
        and tablename = 'stg_starlink_sattelite'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'public_staging'
    
    order by ordinal_position
[0m01:52:29.400587 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:29.410411 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_remote.dim_starlink_sattelite"
[0m01:52:29.412748 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (compile): 01:52:28.796368 => 01:52:29.412458
[0m01:52:29.413271 [debug] [Thread-3 (]: Began executing node model.dbt_remote.dim_starlink_sattelite
[0m01:52:29.420481 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_remote.dim_starlink_sattelite"
[0m01:52:29.423937 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:52:29.424403 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

  
    

  create  table
    "analytics"."public_public"."dim_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    


with max_ingested as (
    select
        s.object_id,
        max(s.export_date) as last_ingested_date
    from "analytics"."public_staging"."stg_starlink_sattelite" s
    group  by 1)

select
    s."object_id",
  s."object_name",
  s."launch_id",
  s."version_id",
  s."latitude",
  s."longitude",
  s."velocity_kms",
  s."center_name",
  s."time_system",
  s."launch_date",
  s."export_date",
    case when s.export_date != m.last_ingested_date then true else false end as deleted_flag
from
    "analytics"."public_staging"."stg_starlink_sattelite" s

left join max_ingested m
on m.object_id = s.object_id

where s.rnk = 1
  );
[0m01:52:29.843976 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:29.850519 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:52:29.851206 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "analytics"."public_public"."dim_starlink_sattelite__dbt_tmp" rename to "dim_starlink_sattelite"
[0m01:52:30.077846 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:30.083645 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:52:30.084627 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:52:30.085232 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:52:31.179676 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:52:31.182012 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:52:31.183373 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:52:31.262675 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:31.274130 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:52:31.274899 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
drop table if exists "analytics"."public_public"."dim_starlink_sattelite__dbt_backup" cascade
[0m01:52:31.352700 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:31.355837 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:52:31.357410 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:52:31.358319 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:52:31.402094 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:31.403240 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:52:31.404329 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:52:31.443854 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:31.447165 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (execute): 01:52:29.413607 => 01:52:31.446542
[0m01:52:31.448244 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: ROLLBACK
[0m01:52:31.526388 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: Close
[0m01:52:31.528578 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7b0acf90-fdbc-4daa-9f90-1ae085b3ef8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10670a350>]}
[0m01:52:31.529800 [info ] [Thread-3 (]: 2 of 2 OK created sql table model public_public.dim_starlink_sattelite ......... [[32mSUCCESS[0m in 2.73s]
[0m01:52:31.531285 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m01:52:31.536080 [debug] [MainThread]: Using redshift connection "master"
[0m01:52:31.536706 [debug] [MainThread]: On master: BEGIN
[0m01:52:31.537114 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:52:31.537738 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:52:31.538168 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:52:31.907019 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:31.907588 [debug] [MainThread]: On master: COMMIT
[0m01:52:31.908052 [debug] [MainThread]: Using redshift connection "master"
[0m01:52:31.908379 [debug] [MainThread]: On master: COMMIT
[0m01:52:31.985420 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:52:31.986077 [debug] [MainThread]: On master: Close
[0m01:52:31.987278 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:52:31.987677 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m01:52:31.988035 [debug] [MainThread]: Connection 'list_analytics_public_public' was properly closed.
[0m01:52:31.988363 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_sattelite' was properly closed.
[0m01:52:31.988773 [info ] [MainThread]: 
[0m01:52:31.989233 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 11.68 seconds (11.68s).
[0m01:52:31.990259 [debug] [MainThread]: Command end result
[0m01:52:32.054455 [info ] [MainThread]: 
[0m01:52:32.054765 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:52:32.054951 [info ] [MainThread]: 
[0m01:52:32.055183 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m01:52:32.055587 [debug] [MainThread]: Command `dbt run` succeeded at 01:52:32.055518 after 11.94 seconds
[0m01:52:32.055813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102fcbed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100d07d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100d14d50>]}
[0m01:52:32.056035 [debug] [MainThread]: Flushing usage events
[0m01:53:28.979107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049f4350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049d4210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cc6410>]}


============================== 01:53:28.982219 | 7f34adad-e7c0-4b7c-9ccd-40ebda6a3a18 ==============================
[0m01:53:28.982219 [info ] [MainThread]: Running with dbt=1.6.0
[0m01:53:28.982533 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m01:53:29.076772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7f34adad-e7c0-4b7c-9ccd-40ebda6a3a18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cd8210>]}
[0m01:53:29.081734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7f34adad-e7c0-4b7c-9ccd-40ebda6a3a18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c6ae90>]}
[0m01:53:29.082573 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m01:53:29.090713 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m01:53:29.116967 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m01:53:29.117419 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m01:53:29.150237 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m01:53:29.153041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7f34adad-e7c0-4b7c-9ccd-40ebda6a3a18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d04a90>]}
[0m01:53:29.159473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7f34adad-e7c0-4b7c-9ccd-40ebda6a3a18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10527b8d0>]}
[0m01:53:29.159904 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 511 macros, 0 groups, 0 semantic models
[0m01:53:29.160103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7f34adad-e7c0-4b7c-9ccd-40ebda6a3a18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101ee5750>]}
[0m01:53:29.161125 [info ] [MainThread]: 
[0m01:53:29.161582 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:53:29.162186 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m01:53:29.162590 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m01:53:29.170493 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m01:53:29.171707 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m01:53:29.171867 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m01:53:29.172027 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m01:53:29.172180 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:53:29.172309 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:53:29.172845 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:53:29.173067 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:53:29.173227 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:53:29.173373 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:53:29.629554 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:29.631954 [debug] [ThreadPool]: On list_analytics: Close
[0m01:53:29.632557 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:29.635014 [debug] [ThreadPool]: On list_analytics: Close
[0m01:53:29.637368 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_public_public)
[0m01:53:29.638512 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_public_staging)
[0m01:53:29.647986 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_public"
[0m01:53:29.653733 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_staging"
[0m01:53:29.654132 [debug] [ThreadPool]: On list_analytics_public_public: BEGIN
[0m01:53:29.654423 [debug] [ThreadPool]: On list_analytics_public_staging: BEGIN
[0m01:53:29.654701 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:53:29.654978 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:53:29.655413 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:53:29.655789 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:53:29.656075 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:53:29.656351 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:53:30.036618 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:30.036993 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:30.038163 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_public"
[0m01:53:30.038455 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_staging"
[0m01:53:30.038739 [debug] [ThreadPool]: On list_analytics_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics_public_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_public'
[0m01:53:30.039042 [debug] [ThreadPool]: On list_analytics_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics_public_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_staging'
[0m01:53:30.140308 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:30.140781 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:30.142411 [debug] [ThreadPool]: On list_analytics_public_staging: ROLLBACK
[0m01:53:30.143784 [debug] [ThreadPool]: On list_analytics_public_public: ROLLBACK
[0m01:53:30.229488 [debug] [ThreadPool]: On list_analytics_public_public: Close
[0m01:53:30.230855 [debug] [ThreadPool]: On list_analytics_public_staging: Close
[0m01:53:30.238002 [debug] [MainThread]: Using redshift connection "master"
[0m01:53:30.238319 [debug] [MainThread]: On master: BEGIN
[0m01:53:30.238526 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:53:30.238990 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:53:30.239217 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:53:30.617131 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:30.617933 [debug] [MainThread]: Using redshift connection "master"
[0m01:53:30.618584 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m01:53:30.737841 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:30.740194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7f34adad-e7c0-4b7c-9ccd-40ebda6a3a18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cc7d50>]}
[0m01:53:30.740869 [debug] [MainThread]: On master: ROLLBACK
[0m01:53:30.832929 [debug] [MainThread]: Using redshift connection "master"
[0m01:53:30.833576 [debug] [MainThread]: On master: BEGIN
[0m01:53:30.873503 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:30.874175 [debug] [MainThread]: On master: COMMIT
[0m01:53:30.874731 [debug] [MainThread]: Using redshift connection "master"
[0m01:53:30.875142 [debug] [MainThread]: On master: COMMIT
[0m01:53:30.954271 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:30.954772 [debug] [MainThread]: On master: Close
[0m01:53:30.955832 [info ] [MainThread]: Concurrency: 4 threads (target='production')
[0m01:53:30.956220 [info ] [MainThread]: 
[0m01:53:30.959874 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m01:53:30.960590 [info ] [Thread-1 (]: 1 of 2 START sql table model public_staging.stg_starlink_sattelite ............. [RUN]
[0m01:53:30.961526 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_public_public, now model.dbt_remote.stg_starlink_sattelite)
[0m01:53:30.961971 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m01:53:30.966719 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m01:53:30.967899 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 01:53:30.962242 => 01:53:30.967643
[0m01:53:30.968324 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m01:53:31.007731 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m01:53:31.009736 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:53:31.009976 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:53:31.010176 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:53:31.010488 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:53:31.010706 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:53:31.361611 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:31.362104 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:53:31.362452 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "analytics"."public_staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "analytics"."raw"."starlink_satellites" s
  );
[0m01:53:33.151517 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m01:53:33.160233 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:53:33.160747 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "analytics"."public_staging"."stg_starlink_sattelite" rename to "stg_starlink_sattelite__dbt_backup"
[0m01:53:33.347908 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:33.353291 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:53:33.353828 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "analytics"."public_staging"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m01:53:33.466732 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:33.494596 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:53:33.495164 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:53:33.495529 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:53:34.608747 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:53:34.611255 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:53:34.612579 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:53:34.690194 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:34.708054 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:53:34.708740 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "analytics"."public_staging"."stg_starlink_sattelite__dbt_backup" cascade
[0m01:53:34.784368 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:34.787236 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:53:34.788457 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:53:34.789082 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:53:35.670008 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:53:35.671276 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:53:35.672266 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:53:35.710563 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:35.714195 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 01:53:30.968575 => 01:53:35.713727
[0m01:53:35.715211 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m01:53:35.793154 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m01:53:35.796896 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f34adad-e7c0-4b7c-9ccd-40ebda6a3a18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ef7bd0>]}
[0m01:53:35.798476 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_staging.stg_starlink_sattelite ........ [[32mSUCCESS[0m in 4.84s]
[0m01:53:35.800228 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m01:53:35.802967 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m01:53:35.804016 [info ] [Thread-3 (]: 2 of 2 START sql table model public_public.dim_starlink_sattelite .............. [RUN]
[0m01:53:35.805163 [debug] [Thread-3 (]: Acquiring new redshift connection 'model.dbt_remote.dim_starlink_sattelite'
[0m01:53:35.805709 [debug] [Thread-3 (]: Began compiling node model.dbt_remote.dim_starlink_sattelite
[0m01:53:35.851157 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:53:35.851560 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:53:35.851825 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m01:53:35.852271 [debug] [Thread-3 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:53:35.852633 [debug] [Thread-3 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:53:36.232171 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:36.232899 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:53:36.233638 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_starlink_sattelite'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_starlink_sattelite'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'public_staging'
        and tablename = 'stg_starlink_sattelite'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'public_staging'
    
    order by ordinal_position
[0m01:53:36.419865 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:36.426007 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_remote.dim_starlink_sattelite"
[0m01:53:36.426905 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (compile): 01:53:35.806063 => 01:53:36.426703
[0m01:53:36.427273 [debug] [Thread-3 (]: Began executing node model.dbt_remote.dim_starlink_sattelite
[0m01:53:36.432456 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_remote.dim_starlink_sattelite"
[0m01:53:36.435320 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:53:36.435708 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

  
    

  create  table
    "analytics"."public_public"."dim_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    


with max_ingested as (
    select
        s.object_id,
        max(s.export_date) as last_ingested_date
    from "analytics"."public_staging"."stg_starlink_sattelite" s
    group  by 1)

select
    s."object_id",
  s."object_name",
  s."launch_id",
  s."version_id",
  s."latitude",
  s."longitude",
  s."velocity_kms",
  s."center_name",
  s."time_system",
  s."launch_date",
  s."export_date",
    case when s.export_date != m.last_ingested_date then true else false end as deleted_flag
from
    "analytics"."public_staging"."stg_starlink_sattelite" s

left join max_ingested m
on m.object_id = s.object_id

where s.rnk = 1
  );
[0m01:53:36.928531 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:36.934558 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:53:36.935127 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "analytics"."public_public"."dim_starlink_sattelite" rename to "dim_starlink_sattelite__dbt_backup"
[0m01:53:37.164913 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:37.170259 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:53:37.170716 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "analytics"."public_public"."dim_starlink_sattelite__dbt_tmp" rename to "dim_starlink_sattelite"
[0m01:53:37.286213 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:37.291822 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:53:37.293133 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:53:37.293825 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:53:38.414748 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:53:38.415201 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:53:38.415372 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:53:38.493693 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:38.495853 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:53:38.496178 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
drop table if exists "analytics"."public_public"."dim_starlink_sattelite__dbt_backup" cascade
[0m01:53:38.574823 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:38.575788 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:53:38.576142 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:53:38.576402 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:53:39.617215 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:53:39.617865 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:53:39.618217 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:53:39.657582 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:39.659027 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (execute): 01:53:36.427503 => 01:53:39.658803
[0m01:53:39.659598 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: ROLLBACK
[0m01:53:39.740090 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: Close
[0m01:53:39.741111 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f34adad-e7c0-4b7c-9ccd-40ebda6a3a18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ee6750>]}
[0m01:53:39.741605 [info ] [Thread-3 (]: 2 of 2 OK created sql table model public_public.dim_starlink_sattelite ......... [[32mSUCCESS[0m in 3.94s]
[0m01:53:39.742015 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m01:53:39.744314 [debug] [MainThread]: Using redshift connection "master"
[0m01:53:39.744694 [debug] [MainThread]: On master: BEGIN
[0m01:53:39.744914 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:53:39.745309 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:53:39.745633 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:53:40.179615 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:40.180317 [debug] [MainThread]: On master: COMMIT
[0m01:53:40.180856 [debug] [MainThread]: Using redshift connection "master"
[0m01:53:40.181252 [debug] [MainThread]: On master: COMMIT
[0m01:53:40.257645 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:53:40.258101 [debug] [MainThread]: On master: Close
[0m01:53:40.259004 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:53:40.259282 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m01:53:40.259531 [debug] [MainThread]: Connection 'list_analytics_public_staging' was properly closed.
[0m01:53:40.259765 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_sattelite' was properly closed.
[0m01:53:40.260097 [info ] [MainThread]: 
[0m01:53:40.260426 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 11.10 seconds (11.10s).
[0m01:53:40.261151 [debug] [MainThread]: Command end result
[0m01:53:40.317696 [info ] [MainThread]: 
[0m01:53:40.317966 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:53:40.318185 [info ] [MainThread]: 
[0m01:53:40.318364 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m01:53:40.318737 [debug] [MainThread]: Command `dbt run` succeeded at 01:53:40.318658 after 11.35 seconds
[0m01:53:40.318979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d15b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100767d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100774d50>]}
[0m01:53:40.319201 [debug] [MainThread]: Flushing usage events
[0m01:56:56.854567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10494ff50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c1df50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ef5b10>]}


============================== 01:56:56.857443 | 939501e2-9b9e-45f3-b506-a34dfa5b2f19 ==============================
[0m01:56:56.857443 [info ] [MainThread]: Running with dbt=1.6.0
[0m01:56:56.857753 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/Users/annaantypenko/.dbt', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m01:56:56.954608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '939501e2-9b9e-45f3-b506-a34dfa5b2f19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10493a6d0>]}
[0m01:56:56.958865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '939501e2-9b9e-45f3-b506-a34dfa5b2f19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ef5bd0>]}
[0m01:56:56.959345 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m01:56:56.967995 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m01:56:56.994501 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m01:56:56.994832 [debug] [MainThread]: Partial parsing: added file: dbt_remote://macros/generate_schema.sql
[0m01:56:56.999229 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m01:56:57.002731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '939501e2-9b9e-45f3-b506-a34dfa5b2f19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c09210>]}
[0m01:56:57.009259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '939501e2-9b9e-45f3-b506-a34dfa5b2f19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10557a8d0>]}
[0m01:56:57.009611 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 512 macros, 0 groups, 0 semantic models
[0m01:56:57.009809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '939501e2-9b9e-45f3-b506-a34dfa5b2f19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a09a90>]}
[0m01:56:57.010687 [info ] [MainThread]: 
[0m01:56:57.011114 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:56:57.011731 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m01:56:57.019822 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m01:56:57.020193 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m01:56:57.020336 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m01:56:57.021516 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m01:56:57.021675 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:56:57.021831 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m01:56:57.022355 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:56:57.022496 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:56:57.022654 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:56:57.022850 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:56:57.023822 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:56:57.576150 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m01:56:57.577359 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m01:56:57.581055 [debug] [ThreadPool]: On list_analytics: Close
[0m01:56:57.584051 [debug] [ThreadPool]: On list_analytics: Close
[0m01:56:57.587355 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_public_staging)
[0m01:56:57.588339 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_public_public)
[0m01:56:57.598613 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_staging"
[0m01:56:57.603009 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_public"
[0m01:56:57.603404 [debug] [ThreadPool]: On list_analytics_public_staging: BEGIN
[0m01:56:57.603735 [debug] [ThreadPool]: On list_analytics_public_public: BEGIN
[0m01:56:57.604039 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:56:57.604337 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:56:57.604825 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:56:57.605267 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:56:57.605598 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:56:57.605912 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:56:57.981192 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:56:57.982548 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_staging"
[0m01:56:57.983651 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:56:57.984958 [debug] [ThreadPool]: On list_analytics_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics_public_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_staging'
[0m01:56:57.985907 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_public"
[0m01:56:57.987026 [debug] [ThreadPool]: On list_analytics_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "list_analytics_public_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_public'
[0m01:56:58.083242 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:56:58.084229 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:56:58.087607 [debug] [ThreadPool]: On list_analytics_public_staging: ROLLBACK
[0m01:56:58.090288 [debug] [ThreadPool]: On list_analytics_public_public: ROLLBACK
[0m01:56:58.173416 [debug] [ThreadPool]: On list_analytics_public_staging: Close
[0m01:56:58.176692 [debug] [ThreadPool]: On list_analytics_public_public: Close
[0m01:56:58.194425 [debug] [MainThread]: Using redshift connection "master"
[0m01:56:58.194881 [debug] [MainThread]: On master: BEGIN
[0m01:56:58.195182 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:56:58.195666 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:56:58.196007 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:56:58.558729 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:56:58.559578 [debug] [MainThread]: Using redshift connection "master"
[0m01:56:58.560253 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m01:56:58.676439 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:56:58.678036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '939501e2-9b9e-45f3-b506-a34dfa5b2f19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051b78d0>]}
[0m01:56:58.678587 [debug] [MainThread]: On master: ROLLBACK
[0m01:56:58.767341 [debug] [MainThread]: Using redshift connection "master"
[0m01:56:58.767803 [debug] [MainThread]: On master: BEGIN
[0m01:56:58.805814 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:56:58.806309 [debug] [MainThread]: On master: COMMIT
[0m01:56:58.806686 [debug] [MainThread]: Using redshift connection "master"
[0m01:56:58.806965 [debug] [MainThread]: On master: COMMIT
[0m01:56:58.882406 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:56:58.883359 [debug] [MainThread]: On master: Close
[0m01:56:58.885254 [info ] [MainThread]: Concurrency: 4 threads (target='production')
[0m01:56:58.886001 [info ] [MainThread]: 
[0m01:56:58.890328 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m01:56:58.891163 [info ] [Thread-1 (]: 1 of 2 START sql table model public_staging.stg_starlink_sattelite ............. [RUN]
[0m01:56:58.892692 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_public_staging, now model.dbt_remote.stg_starlink_sattelite)
[0m01:56:58.893316 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m01:56:58.898746 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m01:56:58.899914 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 01:56:58.893685 => 01:56:58.899668
[0m01:56:58.900354 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m01:56:58.944259 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m01:56:58.946241 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:56:58.946500 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:56:58.946721 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:56:58.947065 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:56:58.947274 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:56:59.299034 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:56:59.299479 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:56:59.299784 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "analytics"."public_staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "analytics"."raw"."starlink_satellites" s
  );
[0m01:57:01.031938 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m01:57:01.041027 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:01.041554 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "analytics"."public_staging"."stg_starlink_sattelite" rename to "stg_starlink_sattelite__dbt_backup"
[0m01:57:01.229915 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:01.235295 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:01.235878 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "analytics"."public_staging"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m01:57:01.348815 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:01.370391 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:57:01.370874 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:01.371143 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:57:02.427454 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:57:02.429085 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:02.429815 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:57:02.508631 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:02.524991 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:02.525672 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "analytics"."public_staging"."stg_starlink_sattelite__dbt_backup" cascade
[0m01:57:02.602640 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:02.604970 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:57:02.605747 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:02.606379 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:57:03.503625 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:57:03.505180 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:03.506082 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:57:03.546913 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:03.549040 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 01:56:58.900625 => 01:57:03.548709
[0m01:57:03.550322 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m01:57:03.628577 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m01:57:03.631744 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '939501e2-9b9e-45f3-b506-a34dfa5b2f19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c08690>]}
[0m01:57:03.633668 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_staging.stg_starlink_sattelite ........ [[32mSUCCESS[0m in 4.74s]
[0m01:57:03.635207 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m01:57:03.637513 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m01:57:03.638626 [info ] [Thread-3 (]: 2 of 2 START sql table model public_public.dim_starlink_sattelite .............. [RUN]
[0m01:57:03.639826 [debug] [Thread-3 (]: Acquiring new redshift connection 'model.dbt_remote.dim_starlink_sattelite'
[0m01:57:03.640318 [debug] [Thread-3 (]: Began compiling node model.dbt_remote.dim_starlink_sattelite
[0m01:57:03.683781 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:03.684225 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:57:03.684501 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m01:57:03.684958 [debug] [Thread-3 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:57:03.685330 [debug] [Thread-3 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:57:04.066477 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:04.067986 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:04.068955 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_starlink_sattelite'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_starlink_sattelite'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'public_staging'
        and tablename = 'stg_starlink_sattelite'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'public_staging'
    
    order by ordinal_position
[0m01:57:04.255973 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:04.264062 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:04.266342 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (compile): 01:57:03.640645 => 01:57:04.266037
[0m01:57:04.266867 [debug] [Thread-3 (]: Began executing node model.dbt_remote.dim_starlink_sattelite
[0m01:57:04.273403 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:04.277291 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:04.277759 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

  
    

  create  table
    "analytics"."public_public"."dim_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    


with max_ingested as (
    select
        s.object_id,
        max(s.export_date) as last_ingested_date
    from "analytics"."public_staging"."stg_starlink_sattelite" s
    group  by 1)

select
    s."object_id",
  s."object_name",
  s."launch_id",
  s."version_id",
  s."latitude",
  s."longitude",
  s."velocity_kms",
  s."center_name",
  s."time_system",
  s."launch_date",
  s."export_date",
    case when s.export_date != m.last_ingested_date then true else false end as deleted_flag
from
    "analytics"."public_staging"."stg_starlink_sattelite" s

left join max_ingested m
on m.object_id = s.object_id

where s.rnk = 1
  );
[0m01:57:04.732312 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:04.739675 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:04.740534 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "analytics"."public_public"."dim_starlink_sattelite" rename to "dim_starlink_sattelite__dbt_backup"
[0m01:57:04.967829 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:04.976393 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:04.977096 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "analytics"."public_public"."dim_starlink_sattelite__dbt_tmp" rename to "dim_starlink_sattelite"
[0m01:57:05.092867 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:05.099084 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:57:05.099943 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:05.100535 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:57:05.908907 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:57:05.910668 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:05.911470 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:57:05.989719 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:05.994486 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:05.995043 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "production", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
drop table if exists "analytics"."public_public"."dim_starlink_sattelite__dbt_backup" cascade
[0m01:57:06.072863 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:06.075066 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:57:06.075827 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:06.076395 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:57:06.909165 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:57:06.910318 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:06.910891 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:57:06.949347 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:06.951664 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (execute): 01:57:04.267200 => 01:57:06.951316
[0m01:57:06.952542 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: ROLLBACK
[0m01:57:07.028030 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: Close
[0m01:57:07.030653 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '939501e2-9b9e-45f3-b506-a34dfa5b2f19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105192d10>]}
[0m01:57:07.032112 [info ] [Thread-3 (]: 2 of 2 OK created sql table model public_public.dim_starlink_sattelite ......... [[32mSUCCESS[0m in 3.39s]
[0m01:57:07.033442 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m01:57:07.036700 [debug] [MainThread]: Using redshift connection "master"
[0m01:57:07.037277 [debug] [MainThread]: On master: BEGIN
[0m01:57:07.037663 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:57:07.038276 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:57:07.038712 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:57:07.413195 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:07.413674 [debug] [MainThread]: On master: COMMIT
[0m01:57:07.414022 [debug] [MainThread]: Using redshift connection "master"
[0m01:57:07.414272 [debug] [MainThread]: On master: COMMIT
[0m01:57:07.492487 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:07.492917 [debug] [MainThread]: On master: Close
[0m01:57:07.493671 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:57:07.493912 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m01:57:07.494128 [debug] [MainThread]: Connection 'list_analytics_public_public' was properly closed.
[0m01:57:07.494333 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_sattelite' was properly closed.
[0m01:57:07.494599 [info ] [MainThread]: 
[0m01:57:07.494891 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 10.48 seconds (10.48s).
[0m01:57:07.495524 [debug] [MainThread]: Command end result
[0m01:57:07.507605 [info ] [MainThread]: 
[0m01:57:07.507953 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:57:07.508173 [info ] [MainThread]: 
[0m01:57:07.508453 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m01:57:07.508951 [debug] [MainThread]: Command `dbt run` succeeded at 01:57:07.508873 after 10.66 seconds
[0m01:57:07.509230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104699690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bb70d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10076d010>]}
[0m01:57:07.509483 [debug] [MainThread]: Flushing usage events
[0m01:57:10.941155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10884a310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10890e310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088349d0>]}


============================== 01:57:10.943454 | f3971e5e-aa4c-4d20-91ba-fddd7d57eecf ==============================
[0m01:57:10.943454 [info ] [MainThread]: Running with dbt=1.6.0
[0m01:57:10.943770 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m01:57:11.016445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f3971e5e-aa4c-4d20-91ba-fddd7d57eecf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b36f10>]}
[0m01:57:11.020759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f3971e5e-aa4c-4d20-91ba-fddd7d57eecf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108dbbc10>]}
[0m01:57:11.021104 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m01:57:11.028638 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m01:57:11.034698 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m01:57:11.034980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f3971e5e-aa4c-4d20-91ba-fddd7d57eecf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108563910>]}
[0m01:57:11.560295 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m01:57:11.563478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f3971e5e-aa4c-4d20-91ba-fddd7d57eecf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10963da90>]}
[0m01:57:11.569533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f3971e5e-aa4c-4d20-91ba-fddd7d57eecf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10917b050>]}
[0m01:57:11.569804 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 512 macros, 0 groups, 0 semantic models
[0m01:57:11.569975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f3971e5e-aa4c-4d20-91ba-fddd7d57eecf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091e3450>]}
[0m01:57:11.570730 [info ] [MainThread]: 
[0m01:57:11.571123 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:57:11.571650 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m01:57:11.579976 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m01:57:11.580242 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m01:57:11.580386 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:57:11.580913 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:57:11.581069 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:57:11.582069 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m01:57:11.583455 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m01:57:11.583721 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m01:57:11.583941 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:57:11.584150 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:57:11.584321 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:57:12.032150 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:12.033741 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:12.037177 [debug] [ThreadPool]: On list_analytics: Close
[0m01:57:12.040127 [debug] [ThreadPool]: On list_analytics: Close
[0m01:57:12.043910 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_public_staging)
[0m01:57:12.045051 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_public_public)
[0m01:57:12.055053 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_staging"
[0m01:57:12.060735 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_public"
[0m01:57:12.061133 [debug] [ThreadPool]: On list_analytics_public_staging: BEGIN
[0m01:57:12.061454 [debug] [ThreadPool]: On list_analytics_public_public: BEGIN
[0m01:57:12.061755 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:57:12.062053 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:57:12.062551 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:57:12.063006 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:57:12.063345 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:57:12.063680 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:57:12.436442 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:12.437656 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:12.438856 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_public"
[0m01:57:12.440131 [debug] [ThreadPool]: Using redshift connection "list_analytics_public_staging"
[0m01:57:12.440925 [debug] [ThreadPool]: On list_analytics_public_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics_public_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_public'
[0m01:57:12.441574 [debug] [ThreadPool]: On list_analytics_public_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics_public_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public_staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public_staging'
[0m01:57:12.539688 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:12.540897 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:12.544294 [debug] [ThreadPool]: On list_analytics_public_staging: ROLLBACK
[0m01:57:12.547050 [debug] [ThreadPool]: On list_analytics_public_public: ROLLBACK
[0m01:57:12.631626 [debug] [ThreadPool]: On list_analytics_public_staging: Close
[0m01:57:12.632504 [debug] [ThreadPool]: On list_analytics_public_public: Close
[0m01:57:12.649517 [debug] [MainThread]: Using redshift connection "master"
[0m01:57:12.650046 [debug] [MainThread]: On master: BEGIN
[0m01:57:12.650683 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:57:12.651267 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:57:12.651687 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:57:13.027604 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:13.029092 [debug] [MainThread]: Using redshift connection "master"
[0m01:57:13.030323 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m01:57:13.149988 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:13.154117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f3971e5e-aa4c-4d20-91ba-fddd7d57eecf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ddfe50>]}
[0m01:57:13.155685 [debug] [MainThread]: On master: ROLLBACK
[0m01:57:13.245604 [debug] [MainThread]: Using redshift connection "master"
[0m01:57:13.246957 [debug] [MainThread]: On master: BEGIN
[0m01:57:13.285203 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:13.286635 [debug] [MainThread]: On master: COMMIT
[0m01:57:13.287920 [debug] [MainThread]: Using redshift connection "master"
[0m01:57:13.289182 [debug] [MainThread]: On master: COMMIT
[0m01:57:13.366012 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:13.367508 [debug] [MainThread]: On master: Close
[0m01:57:13.369556 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m01:57:13.370495 [info ] [MainThread]: 
[0m01:57:13.374328 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m01:57:13.375214 [info ] [Thread-1 (]: 1 of 2 START sql table model public_staging.stg_starlink_sattelite ............. [RUN]
[0m01:57:13.376241 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_public_staging, now model.dbt_remote.stg_starlink_sattelite)
[0m01:57:13.376749 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m01:57:13.381227 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:13.381838 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 01:57:13.377090 => 01:57:13.381721
[0m01:57:13.382063 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m01:57:13.420124 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:13.422424 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:13.422709 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:57:13.422960 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:57:13.423355 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:57:13.423618 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:57:13.780528 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:13.782010 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:13.783229 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "analytics"."public_staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "analytics"."raw"."starlink_satellites" s
  );
[0m01:57:15.627164 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m01:57:15.633615 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:15.634057 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "analytics"."public_staging"."stg_starlink_sattelite" rename to "stg_starlink_sattelite__dbt_backup"
[0m01:57:15.821810 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:15.829144 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:15.829886 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "analytics"."public_staging"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m01:57:15.943687 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:15.975738 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:57:15.976383 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:15.976739 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:57:16.894188 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:57:16.896339 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:16.897453 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:57:16.974748 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:16.991110 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:16.991811 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "analytics"."public_staging"."stg_starlink_sattelite__dbt_backup" cascade
[0m01:57:17.069930 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:17.073278 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:57:17.074467 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:17.075103 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:57:17.798633 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:57:17.800872 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:57:17.802014 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:57:17.841016 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:17.844613 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 01:57:13.382194 => 01:57:17.844094
[0m01:57:17.845677 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m01:57:17.925878 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m01:57:17.929750 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3971e5e-aa4c-4d20-91ba-fddd7d57eecf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10881aad0>]}
[0m01:57:17.931499 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_staging.stg_starlink_sattelite ........ [[32mSUCCESS[0m in 4.55s]
[0m01:57:17.933248 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m01:57:17.935927 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m01:57:17.936889 [info ] [Thread-3 (]: 2 of 2 START sql table model public_public.dim_starlink_sattelite .............. [RUN]
[0m01:57:17.938167 [debug] [Thread-3 (]: Acquiring new redshift connection 'model.dbt_remote.dim_starlink_sattelite'
[0m01:57:17.938707 [debug] [Thread-3 (]: Began compiling node model.dbt_remote.dim_starlink_sattelite
[0m01:57:17.971394 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:17.971864 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:57:17.972165 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m01:57:17.972683 [debug] [Thread-3 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:57:17.973092 [debug] [Thread-3 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:57:18.342544 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:18.344461 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:18.346340 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_starlink_sattelite'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_starlink_sattelite'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'public_staging'
        and tablename = 'stg_starlink_sattelite'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'public_staging'
    
    order by ordinal_position
[0m01:57:18.534124 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:18.544315 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:18.545590 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (compile): 01:57:17.939047 => 01:57:18.545301
[0m01:57:18.546132 [debug] [Thread-3 (]: Began executing node model.dbt_remote.dim_starlink_sattelite
[0m01:57:18.552635 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:18.556121 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:18.556567 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

  
    

  create  table
    "analytics"."public_public"."dim_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    


with max_ingested as (
    select
        s.object_id,
        max(s.export_date) as last_ingested_date
    from "analytics"."public_staging"."stg_starlink_sattelite" s
    group  by 1)

select
    s."object_id",
  s."object_name",
  s."launch_id",
  s."version_id",
  s."latitude",
  s."longitude",
  s."velocity_kms",
  s."center_name",
  s."time_system",
  s."launch_date",
  s."export_date",
    case when s.export_date != m.last_ingested_date then true else false end as deleted_flag
from
    "analytics"."public_staging"."stg_starlink_sattelite" s

left join max_ingested m
on m.object_id = s.object_id

where s.rnk = 1
  );
[0m01:57:19.068262 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:57:19.078473 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:19.079165 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "analytics"."public_public"."dim_starlink_sattelite" rename to "dim_starlink_sattelite__dbt_backup"
[0m01:57:19.306350 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:19.314763 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:19.315425 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "analytics"."public_public"."dim_starlink_sattelite__dbt_tmp" rename to "dim_starlink_sattelite"
[0m01:57:19.428860 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:19.435087 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:57:19.436087 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:19.436796 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:57:20.408895 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:57:20.411332 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:20.412669 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:57:20.491145 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:20.499833 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:20.500709 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
drop table if exists "analytics"."public_public"."dim_starlink_sattelite__dbt_backup" cascade
[0m01:57:20.578877 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:20.579872 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:57:20.580267 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:20.580552 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:57:21.794832 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:57:21.796545 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:57:21.797478 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:57:21.836731 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:21.839967 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (execute): 01:57:18.546477 => 01:57:21.839315
[0m01:57:21.841272 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: ROLLBACK
[0m01:57:21.918640 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: Close
[0m01:57:21.921772 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3971e5e-aa4c-4d20-91ba-fddd7d57eecf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f9bd90>]}
[0m01:57:21.923475 [info ] [Thread-3 (]: 2 of 2 OK created sql table model public_public.dim_starlink_sattelite ......... [[32mSUCCESS[0m in 3.98s]
[0m01:57:21.925113 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m01:57:21.929606 [debug] [MainThread]: Using redshift connection "master"
[0m01:57:21.930362 [debug] [MainThread]: On master: BEGIN
[0m01:57:21.930780 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:57:21.931455 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:57:21.931894 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:57:22.305510 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:22.306955 [debug] [MainThread]: On master: COMMIT
[0m01:57:22.308071 [debug] [MainThread]: Using redshift connection "master"
[0m01:57:22.309091 [debug] [MainThread]: On master: COMMIT
[0m01:57:22.385351 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:22.386724 [debug] [MainThread]: On master: Close
[0m01:57:22.389129 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:57:22.390244 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m01:57:22.390898 [debug] [MainThread]: Connection 'list_analytics_public_public' was properly closed.
[0m01:57:22.391350 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_sattelite' was properly closed.
[0m01:57:22.391945 [info ] [MainThread]: 
[0m01:57:22.392672 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 10.82 seconds (10.82s).
[0m01:57:22.394532 [debug] [MainThread]: Command end result
[0m01:57:22.416650 [info ] [MainThread]: 
[0m01:57:22.417126 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:57:22.417429 [info ] [MainThread]: 
[0m01:57:22.417735 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m01:57:22.418268 [debug] [MainThread]: Command `dbt run` succeeded at 01:57:22.418169 after 11.49 seconds
[0m01:57:22.418622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042e7d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104251cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042f4690>]}
[0m01:57:22.418988 [debug] [MainThread]: Flushing usage events
[0m01:57:58.019285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10916af50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109483590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109202190>]}


============================== 01:57:58.021889 | ec9916ee-08ae-49bd-ace8-721dd2ee96de ==============================
[0m01:57:58.021889 [info ] [MainThread]: Running with dbt=1.6.0
[0m01:57:58.022220 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m01:57:58.099357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ec9916ee-08ae-49bd-ace8-721dd2ee96de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109127e90>]}
[0m01:57:58.103608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ec9916ee-08ae-49bd-ace8-721dd2ee96de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109480090>]}
[0m01:57:58.103937 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m01:57:58.111707 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m01:57:58.131737 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m01:57:58.132090 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://macros/generate_schema.sql
[0m01:57:58.133560 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m01:57:58.654400 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m01:57:58.657333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ec9916ee-08ae-49bd-ace8-721dd2ee96de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a50a390>]}
[0m01:57:58.664056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ec9916ee-08ae-49bd-ace8-721dd2ee96de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4ed710>]}
[0m01:57:58.664347 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 512 macros, 0 groups, 0 semantic models
[0m01:57:58.664515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ec9916ee-08ae-49bd-ace8-721dd2ee96de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a541f50>]}
[0m01:57:58.665286 [info ] [MainThread]: 
[0m01:57:58.665697 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:57:58.666295 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m01:57:58.666649 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m01:57:58.674531 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m01:57:58.675916 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m01:57:58.676234 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m01:57:58.676402 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m01:57:58.676551 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:57:58.676706 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:57:58.677293 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:57:58.677506 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:57:58.677673 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:57:58.677819 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:57:59.143417 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:59.144270 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:59.146686 [debug] [ThreadPool]: On list_analytics: Close
[0m01:57:59.148512 [debug] [ThreadPool]: On list_analytics: Close
[0m01:57:59.151172 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_staging)
[0m01:57:59.152248 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "staging"
"
[0m01:57:59.161812 [debug] [ThreadPool]: Using redshift connection "create_analytics_staging"
[0m01:57:59.162279 [debug] [ThreadPool]: On create_analytics_staging: BEGIN
[0m01:57:59.162590 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:57:59.163174 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:57:59.163536 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:57:59.539564 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:59.539850 [debug] [ThreadPool]: Using redshift connection "create_analytics_staging"
[0m01:57:59.540008 [debug] [ThreadPool]: On create_analytics_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "create_analytics_staging"} */
create schema if not exists "staging"
[0m01:57:59.695347 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:57:59.696738 [debug] [ThreadPool]: On create_analytics_staging: COMMIT
[0m01:57:59.697301 [debug] [ThreadPool]: Using redshift connection "create_analytics_staging"
[0m01:57:59.697700 [debug] [ThreadPool]: On create_analytics_staging: COMMIT
[0m01:58:00.642397 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m01:58:00.642963 [debug] [ThreadPool]: On create_analytics_staging: Close
[0m01:58:00.645078 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_staging)
[0m01:58:00.645848 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_analytics_staging, now list_analytics_public)
[0m01:58:00.654487 [debug] [ThreadPool]: Using redshift connection "list_analytics_staging"
[0m01:58:00.657777 [debug] [ThreadPool]: Using redshift connection "list_analytics_public"
[0m01:58:00.658070 [debug] [ThreadPool]: On list_analytics_staging: BEGIN
[0m01:58:00.658320 [debug] [ThreadPool]: On list_analytics_public: BEGIN
[0m01:58:00.658545 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:58:00.658765 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:58:00.659147 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:58:00.659484 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:58:00.659735 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:58:00.659963 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:58:01.044504 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:01.045995 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:01.046930 [debug] [ThreadPool]: Using redshift connection "list_analytics_staging"
[0m01:58:01.048086 [debug] [ThreadPool]: Using redshift connection "list_analytics_public"
[0m01:58:01.048962 [debug] [ThreadPool]: On list_analytics_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m01:58:01.049664 [debug] [ThreadPool]: On list_analytics_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m01:58:01.152982 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:01.154029 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:01.157864 [debug] [ThreadPool]: On list_analytics_staging: ROLLBACK
[0m01:58:01.160529 [debug] [ThreadPool]: On list_analytics_public: ROLLBACK
[0m01:58:01.247960 [debug] [ThreadPool]: On list_analytics_public: Close
[0m01:58:01.249864 [debug] [ThreadPool]: On list_analytics_staging: Close
[0m01:58:01.265457 [debug] [MainThread]: Using redshift connection "master"
[0m01:58:01.266106 [debug] [MainThread]: On master: BEGIN
[0m01:58:01.266506 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:58:01.267141 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:58:01.267571 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:58:01.632369 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:01.632824 [debug] [MainThread]: Using redshift connection "master"
[0m01:58:01.633138 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m01:58:01.751251 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:01.754339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ec9916ee-08ae-49bd-ace8-721dd2ee96de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4d8310>]}
[0m01:58:01.755634 [debug] [MainThread]: On master: ROLLBACK
[0m01:58:01.846488 [debug] [MainThread]: Using redshift connection "master"
[0m01:58:01.847008 [debug] [MainThread]: On master: BEGIN
[0m01:58:01.886316 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:01.886946 [debug] [MainThread]: On master: COMMIT
[0m01:58:01.887474 [debug] [MainThread]: Using redshift connection "master"
[0m01:58:01.887879 [debug] [MainThread]: On master: COMMIT
[0m01:58:01.965106 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:01.965935 [debug] [MainThread]: On master: Close
[0m01:58:01.967632 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m01:58:01.968307 [info ] [MainThread]: 
[0m01:58:01.971199 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m01:58:01.971982 [info ] [Thread-1 (]: 1 of 2 START sql table model staging.stg_starlink_sattelite .................... [RUN]
[0m01:58:01.972975 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_staging, now model.dbt_remote.stg_starlink_sattelite)
[0m01:58:01.973470 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m01:58:01.978910 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m01:58:01.980277 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 01:58:01.973812 => 01:58:01.979980
[0m01:58:01.980756 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m01:58:02.024335 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m01:58:02.026371 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:58:02.026628 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:58:02.026845 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:58:02.027187 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:58:02.027424 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:58:02.389595 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:02.391105 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:58:02.392517 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "analytics"."staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "analytics"."raw"."starlink_satellites" s
  );
[0m01:58:03.961835 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m01:58:03.980971 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:58:03.981667 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "analytics"."staging"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m01:58:04.172249 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:04.203083 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:58:04.203576 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:58:04.203923 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:58:05.189443 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:58:05.190537 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:58:05.191068 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:58:05.268707 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:05.276129 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:58:05.276479 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "analytics"."staging"."stg_starlink_sattelite__dbt_backup" cascade
[0m01:58:05.352731 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:05.353851 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:58:05.354303 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:58:05.354637 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m01:58:05.398277 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:05.398780 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m01:58:05.399167 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m01:58:05.437847 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:05.439567 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 01:58:01.981043 => 01:58:05.439256
[0m01:58:05.440210 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m01:58:05.517779 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m01:58:05.520648 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ec9916ee-08ae-49bd-ace8-721dd2ee96de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b77c90>]}
[0m01:58:05.522363 [info ] [Thread-1 (]: 1 of 2 OK created sql table model staging.stg_starlink_sattelite ............... [[32mSUCCESS[0m in 3.55s]
[0m01:58:05.523966 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m01:58:05.526790 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m01:58:05.527831 [info ] [Thread-3 (]: 2 of 2 START sql table model public.dim_starlink_sattelite ..................... [RUN]
[0m01:58:05.529231 [debug] [Thread-3 (]: Acquiring new redshift connection 'model.dbt_remote.dim_starlink_sattelite'
[0m01:58:05.529808 [debug] [Thread-3 (]: Began compiling node model.dbt_remote.dim_starlink_sattelite
[0m01:58:05.560136 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:58:05.560592 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:58:05.560885 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m01:58:05.561397 [debug] [Thread-3 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:58:05.561823 [debug] [Thread-3 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:58:05.946937 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:05.948391 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:58:05.949590 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_starlink_sattelite'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_starlink_sattelite'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_starlink_sattelite'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m01:58:06.141075 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:06.151495 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_remote.dim_starlink_sattelite"
[0m01:58:06.152767 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (compile): 01:58:05.530157 => 01:58:06.152488
[0m01:58:06.153277 [debug] [Thread-3 (]: Began executing node model.dbt_remote.dim_starlink_sattelite
[0m01:58:06.159999 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_remote.dim_starlink_sattelite"
[0m01:58:06.163530 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:58:06.164000 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

  
    

  create  table
    "analytics"."public"."dim_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    


with max_ingested as (
    select
        s.object_id,
        max(s.export_date) as last_ingested_date
    from "analytics"."staging"."stg_starlink_sattelite" s
    group  by 1)

select
    s."object_id",
  s."object_name",
  s."launch_id",
  s."version_id",
  s."latitude",
  s."longitude",
  s."velocity_kms",
  s."center_name",
  s."time_system",
  s."launch_date",
  s."export_date",
    case when s.export_date != m.last_ingested_date then true else false end as deleted_flag
from
    "analytics"."staging"."stg_starlink_sattelite" s

left join max_ingested m
on m.object_id = s.object_id

where s.rnk = 1
  );
[0m01:58:06.568682 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:06.576344 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:58:06.576925 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "analytics"."public"."dim_starlink_sattelite__dbt_tmp" rename to "dim_starlink_sattelite"
[0m01:58:06.811567 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:06.817517 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:58:06.818640 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:58:06.819370 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:58:07.851364 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m01:58:07.852361 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:58:07.852840 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:58:07.932974 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:07.939546 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:58:07.940372 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
drop table if exists "analytics"."public"."dim_starlink_sattelite__dbt_backup" cascade
[0m01:58:08.020239 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:08.022338 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:58:08.023136 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:58:08.023662 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m01:58:08.069439 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:08.071065 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m01:58:08.072284 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m01:58:08.113349 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:08.116315 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (execute): 01:58:06.153609 => 01:58:08.115854
[0m01:58:08.117274 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: ROLLBACK
[0m01:58:08.197392 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: Close
[0m01:58:08.200372 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ec9916ee-08ae-49bd-ace8-721dd2ee96de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4eca90>]}
[0m01:58:08.201848 [info ] [Thread-3 (]: 2 of 2 OK created sql table model public.dim_starlink_sattelite ................ [[32mSUCCESS[0m in 2.67s]
[0m01:58:08.203142 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m01:58:08.207638 [debug] [MainThread]: Using redshift connection "master"
[0m01:58:08.208266 [debug] [MainThread]: On master: BEGIN
[0m01:58:08.208686 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:58:08.209337 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:58:08.209781 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:58:08.587001 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:08.588523 [debug] [MainThread]: On master: COMMIT
[0m01:58:08.589812 [debug] [MainThread]: Using redshift connection "master"
[0m01:58:08.590499 [debug] [MainThread]: On master: COMMIT
[0m01:58:08.667718 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:58:08.669120 [debug] [MainThread]: On master: Close
[0m01:58:08.671631 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:58:08.672800 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m01:58:08.673465 [debug] [MainThread]: Connection 'list_analytics_public' was properly closed.
[0m01:58:08.673903 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_sattelite' was properly closed.
[0m01:58:08.674522 [info ] [MainThread]: 
[0m01:58:08.675427 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 10.01 seconds (10.01s).
[0m01:58:08.677204 [debug] [MainThread]: Command end result
[0m01:58:08.697600 [info ] [MainThread]: 
[0m01:58:08.698159 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:58:08.698519 [info ] [MainThread]: 
[0m01:58:08.698939 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m01:58:08.699562 [debug] [MainThread]: Command `dbt run` succeeded at 01:58:08.699463 after 10.69 seconds
[0m01:58:08.699925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091d2b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c79c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d0fd50>]}
[0m01:58:08.700280 [debug] [MainThread]: Flushing usage events
[0m02:03:12.883770 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c23490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ff2010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f247d0>]}


============================== 02:03:12.886361 | 1574389d-b309-414e-82ea-f1bbbd016df4 ==============================
[0m02:03:12.886361 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:03:12.886712 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:03:12.964551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1574389d-b309-414e-82ea-f1bbbd016df4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c70950>]}
[0m02:03:12.968911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1574389d-b309-414e-82ea-f1bbbd016df4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c5d950>]}
[0m02:03:12.969252 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:03:12.976659 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:03:12.996046 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m02:03:12.996460 [debug] [MainThread]: Partial parsing: added file: dbt_remote://macros/generate_schema_name.sql
[0m02:03:12.996619 [debug] [MainThread]: Partial parsing: deleted file: dbt_remote://macros/generate_schema.sql
[0m02:03:12.998093 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m02:03:13.532537 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:03:13.535542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1574389d-b309-414e-82ea-f1bbbd016df4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109dbf290>]}
[0m02:03:13.541191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1574389d-b309-414e-82ea-f1bbbd016df4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098c3590>]}
[0m02:03:13.541456 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 512 macros, 0 groups, 0 semantic models
[0m02:03:13.541626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1574389d-b309-414e-82ea-f1bbbd016df4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e63a50>]}
[0m02:03:13.542502 [info ] [MainThread]: 
[0m02:03:13.542988 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:03:13.543681 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m02:03:13.544095 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m02:03:13.552716 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m02:03:13.554026 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m02:03:13.554218 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m02:03:13.554397 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m02:03:13.554569 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:03:13.554710 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:03:13.555228 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:13.555431 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:13.555581 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:13.555734 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:14.143930 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:03:14.147365 [debug] [ThreadPool]: On list_analytics: Close
[0m02:03:14.148200 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:03:14.151492 [debug] [ThreadPool]: On list_analytics: Close
[0m02:03:14.155616 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_public)
[0m02:03:14.156929 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_staging)
[0m02:03:14.174169 [debug] [ThreadPool]: Using redshift connection "list_analytics_public"
[0m02:03:14.180046 [debug] [ThreadPool]: Using redshift connection "list_analytics_staging"
[0m02:03:14.180586 [debug] [ThreadPool]: On list_analytics_public: BEGIN
[0m02:03:14.180932 [debug] [ThreadPool]: On list_analytics_staging: BEGIN
[0m02:03:14.181235 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:03:14.181536 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:03:14.182030 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:14.182474 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:14.182817 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:14.183148 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:14.563428 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:14.564295 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:14.565165 [debug] [ThreadPool]: Using redshift connection "list_analytics_staging"
[0m02:03:14.566418 [debug] [ThreadPool]: Using redshift connection "list_analytics_public"
[0m02:03:14.567538 [debug] [ThreadPool]: On list_analytics_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m02:03:14.568707 [debug] [ThreadPool]: On list_analytics_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:03:14.664858 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:14.665536 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:14.668471 [debug] [ThreadPool]: On list_analytics_public: ROLLBACK
[0m02:03:14.671304 [debug] [ThreadPool]: On list_analytics_staging: ROLLBACK
[0m02:03:14.756265 [debug] [ThreadPool]: On list_analytics_public: Close
[0m02:03:14.757364 [debug] [ThreadPool]: On list_analytics_staging: Close
[0m02:03:14.777071 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:14.778216 [debug] [MainThread]: On master: BEGIN
[0m02:03:14.778738 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:03:14.779381 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:14.779706 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:15.145661 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:15.146675 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:15.147529 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:03:15.267434 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:15.270211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1574389d-b309-414e-82ea-f1bbbd016df4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f428d0>]}
[0m02:03:15.271403 [debug] [MainThread]: On master: ROLLBACK
[0m02:03:15.360590 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:15.362016 [debug] [MainThread]: On master: BEGIN
[0m02:03:15.401632 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:15.402616 [debug] [MainThread]: On master: COMMIT
[0m02:03:15.403164 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:15.403572 [debug] [MainThread]: On master: COMMIT
[0m02:03:15.479249 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:15.480307 [debug] [MainThread]: On master: Close
[0m02:03:15.481779 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m02:03:15.482679 [info ] [MainThread]: 
[0m02:03:15.486656 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:03:15.487699 [info ] [Thread-1 (]: 1 of 2 START sql table model staging.stg_starlink_sattelite .................... [RUN]
[0m02:03:15.489903 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:03:15.490767 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:03:15.498719 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:15.500585 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:03:15.491303 => 02:03:15.500081
[0m02:03:15.501739 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:03:15.554709 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:15.556776 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:15.557041 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:03:15.557256 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:03:15.557598 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:15.557823 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:15.917290 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:15.918317 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:15.919111 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "analytics"."staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "analytics"."raw"."starlink_satellites" s
  );
[0m02:03:29.101327 [debug] [Thread-1 (]: SQL status: SUCCESS in 13.0 seconds
[0m02:03:29.116999 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:29.118028 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "analytics"."staging"."stg_starlink_sattelite" rename to "stg_starlink_sattelite__dbt_backup"
[0m02:03:29.308267 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:29.316159 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:29.317075 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "analytics"."staging"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m02:03:29.429894 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:29.474653 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:03:29.475429 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:29.475862 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:03:30.573360 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:03:30.575761 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:30.577073 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:03:30.656174 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:30.677424 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:30.678419 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "analytics"."staging"."stg_starlink_sattelite__dbt_backup" cascade
[0m02:03:30.756990 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:30.760817 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:03:30.762466 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:30.763631 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:03:31.720102 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:03:31.721546 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:03:31.722754 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:03:31.761880 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:31.764254 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:03:15.502497 => 02:03:31.763819
[0m02:03:31.765316 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:03:31.843628 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:03:31.847138 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1574389d-b309-414e-82ea-f1bbbd016df4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109427b10>]}
[0m02:03:31.849110 [info ] [Thread-1 (]: 1 of 2 OK created sql table model staging.stg_starlink_sattelite ............... [[32mSUCCESS[0m in 16.36s]
[0m02:03:31.851214 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:03:31.854549 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m02:03:31.856021 [info ] [Thread-3 (]: 2 of 2 START sql table model public.dim_starlink_sattelite ..................... [RUN]
[0m02:03:31.858019 [debug] [Thread-3 (]: Acquiring new redshift connection 'model.dbt_remote.dim_starlink_sattelite'
[0m02:03:31.859360 [debug] [Thread-3 (]: Began compiling node model.dbt_remote.dim_starlink_sattelite
[0m02:03:31.894522 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:03:31.895050 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m02:03:31.895403 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:03:31.895921 [debug] [Thread-3 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:31.896354 [debug] [Thread-3 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:32.265880 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:32.266973 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:03:32.267963 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_starlink_sattelite'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_starlink_sattelite'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_starlink_sattelite'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m02:03:32.455375 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:32.463656 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_remote.dim_starlink_sattelite"
[0m02:03:32.466349 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (compile): 02:03:31.860205 => 02:03:32.465835
[0m02:03:32.467288 [debug] [Thread-3 (]: Began executing node model.dbt_remote.dim_starlink_sattelite
[0m02:03:32.475964 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_remote.dim_starlink_sattelite"
[0m02:03:32.482767 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:03:32.483696 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

  
    

  create  table
    "analytics"."public"."dim_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    


with max_ingested as (
    select
        s.object_id,
        max(s.export_date) as last_ingested_date
    from "analytics"."staging"."stg_starlink_sattelite" s
    group  by 1)

select
    s."object_id",
  s."object_name",
  s."launch_id",
  s."version_id",
  s."latitude",
  s."longitude",
  s."velocity_kms",
  s."center_name",
  s."time_system",
  s."launch_date",
  s."export_date",
    case when s.export_date != m.last_ingested_date then true else false end as deleted_flag
from
    "analytics"."staging"."stg_starlink_sattelite" s

left join max_ingested m
on m.object_id = s.object_id

where s.rnk = 1
  );
[0m02:03:32.909325 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:32.913106 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:03:32.913492 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "analytics"."public"."dim_starlink_sattelite" rename to "dim_starlink_sattelite__dbt_backup"
[0m02:03:33.136010 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:33.145187 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:03:33.146191 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "analytics"."public"."dim_starlink_sattelite__dbt_tmp" rename to "dim_starlink_sattelite"
[0m02:03:33.259719 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:33.264669 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m02:03:33.265680 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:03:33.266770 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m02:03:35.534473 [debug] [Thread-3 (]: SQL status: SUCCESS in 2.0 seconds
[0m02:03:35.536661 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:03:35.537870 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m02:03:35.615406 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:35.628738 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:03:35.629689 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
drop table if exists "analytics"."public"."dim_starlink_sattelite__dbt_backup" cascade
[0m02:03:35.707509 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:35.709686 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m02:03:35.710614 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:03:35.711575 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m02:03:36.635689 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:03:36.636944 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:03:36.637535 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m02:03:36.675374 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:36.678374 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (execute): 02:03:32.468029 => 02:03:36.677947
[0m02:03:36.679563 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: ROLLBACK
[0m02:03:36.757031 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: Close
[0m02:03:36.759708 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1574389d-b309-414e-82ea-f1bbbd016df4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109514e10>]}
[0m02:03:36.761086 [info ] [Thread-3 (]: 2 of 2 OK created sql table model public.dim_starlink_sattelite ................ [[32mSUCCESS[0m in 4.90s]
[0m02:03:36.762167 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m02:03:36.766186 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:36.767054 [debug] [MainThread]: On master: BEGIN
[0m02:03:36.767515 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:03:36.768298 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:03:36.768868 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:03:37.152930 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:37.154044 [debug] [MainThread]: On master: COMMIT
[0m02:03:37.154845 [debug] [MainThread]: Using redshift connection "master"
[0m02:03:37.155322 [debug] [MainThread]: On master: COMMIT
[0m02:03:37.233019 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:03:37.234277 [debug] [MainThread]: On master: Close
[0m02:03:37.236776 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:03:37.238055 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:03:37.239031 [debug] [MainThread]: Connection 'list_analytics_staging' was properly closed.
[0m02:03:37.240215 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_sattelite' was properly closed.
[0m02:03:37.241456 [info ] [MainThread]: 
[0m02:03:37.242542 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 23.70 seconds (23.70s).
[0m02:03:37.245503 [debug] [MainThread]: Command end result
[0m02:03:37.267568 [info ] [MainThread]: 
[0m02:03:37.268243 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:03:37.268668 [info ] [MainThread]: 
[0m02:03:37.269105 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m02:03:37.269870 [debug] [MainThread]: Command `dbt run` succeeded at 02:03:37.269736 after 24.40 seconds
[0m02:03:37.270357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c53c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049e3d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10494dc90>]}
[0m02:03:37.270835 [debug] [MainThread]: Flushing usage events
[0m02:09:31.833278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ca6990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095449d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109be2fd0>]}


============================== 02:09:31.835577 | 6a86113e-4efe-41d8-b430-a6b32fd83c70 ==============================
[0m02:09:31.835577 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:09:31.835874 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:09:31.911268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6a86113e-4efe-41d8-b430-a6b32fd83c70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fa4490>]}
[0m02:09:31.915456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6a86113e-4efe-41d8-b430-a6b32fd83c70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109be30d0>]}
[0m02:09:31.915773 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:09:31.924332 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:09:31.943688 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:09:31.944048 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/stg_starlink_sattelite.sql
[0m02:09:31.972856 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:09:31.976337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6a86113e-4efe-41d8-b430-a6b32fd83c70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9a47d0>]}
[0m02:09:31.981832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6a86113e-4efe-41d8-b430-a6b32fd83c70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9a0dd0>]}
[0m02:09:31.982081 [info ] [MainThread]: Found 2 models, 2 tests, 1 source, 0 exposures, 0 metrics, 512 macros, 0 groups, 0 semantic models
[0m02:09:31.982249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6a86113e-4efe-41d8-b430-a6b32fd83c70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f135d0>]}
[0m02:09:31.983035 [info ] [MainThread]: 
[0m02:09:31.983430 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:09:31.983998 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m02:09:31.984372 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m02:09:31.992886 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m02:09:31.994212 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m02:09:31.994378 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m02:09:31.994521 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m02:09:31.994653 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:09:31.994779 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:09:31.995275 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:09:31.995465 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:09:31.995605 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:09:31.995742 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:09:32.580775 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:09:32.585747 [debug] [ThreadPool]: On list_analytics: Close
[0m02:09:32.586962 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:09:32.591275 [debug] [ThreadPool]: On list_analytics: Close
[0m02:09:32.593877 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_public)
[0m02:09:32.594895 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_staging)
[0m02:09:32.604787 [debug] [ThreadPool]: Using redshift connection "list_analytics_public"
[0m02:09:32.609258 [debug] [ThreadPool]: Using redshift connection "list_analytics_staging"
[0m02:09:32.609635 [debug] [ThreadPool]: On list_analytics_public: BEGIN
[0m02:09:32.609957 [debug] [ThreadPool]: On list_analytics_staging: BEGIN
[0m02:09:32.610256 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:09:32.610548 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:09:32.611047 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:09:32.611491 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:09:32.611823 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:09:32.612139 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:09:32.994499 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:32.995598 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:32.996724 [debug] [ThreadPool]: Using redshift connection "list_analytics_public"
[0m02:09:32.997615 [debug] [ThreadPool]: Using redshift connection "list_analytics_staging"
[0m02:09:32.998516 [debug] [ThreadPool]: On list_analytics_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:09:32.999647 [debug] [ThreadPool]: On list_analytics_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m02:09:33.096877 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:33.097808 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:33.101426 [debug] [ThreadPool]: On list_analytics_staging: ROLLBACK
[0m02:09:33.104304 [debug] [ThreadPool]: On list_analytics_public: ROLLBACK
[0m02:09:33.188861 [debug] [ThreadPool]: On list_analytics_public: Close
[0m02:09:33.189860 [debug] [ThreadPool]: On list_analytics_staging: Close
[0m02:09:33.211101 [debug] [MainThread]: Using redshift connection "master"
[0m02:09:33.211595 [debug] [MainThread]: On master: BEGIN
[0m02:09:33.211908 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:09:33.212387 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:09:33.212726 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:09:33.597239 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:33.598754 [debug] [MainThread]: Using redshift connection "master"
[0m02:09:33.600226 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:09:33.719148 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:33.723128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6a86113e-4efe-41d8-b430-a6b32fd83c70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae32510>]}
[0m02:09:33.724474 [debug] [MainThread]: On master: ROLLBACK
[0m02:09:33.815355 [debug] [MainThread]: Using redshift connection "master"
[0m02:09:33.816800 [debug] [MainThread]: On master: BEGIN
[0m02:09:33.856213 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:33.857259 [debug] [MainThread]: On master: COMMIT
[0m02:09:33.858179 [debug] [MainThread]: Using redshift connection "master"
[0m02:09:33.858903 [debug] [MainThread]: On master: COMMIT
[0m02:09:33.937054 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:33.938735 [debug] [MainThread]: On master: Close
[0m02:09:33.941348 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m02:09:33.942377 [info ] [MainThread]: 
[0m02:09:33.946547 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:09:33.947530 [info ] [Thread-1 (]: 1 of 2 START sql table model staging.stg_starlink_sattelite .................... [RUN]
[0m02:09:33.949192 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:09:33.949864 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:09:33.953310 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:09:33.954529 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:09:33.950252 => 02:09:33.954239
[0m02:09:33.955062 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:09:34.000893 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:09:34.002858 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:09:34.003108 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:09:34.003326 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:09:34.003718 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:09:34.003963 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:09:34.366047 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:34.367572 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:09:34.368929 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "analytics"."staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date::date as export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "analytics"."raw"."starlink_satellites" s
  );
[0m02:09:55.267210 [debug] [Thread-1 (]: SQL status: SUCCESS in 21.0 seconds
[0m02:09:55.276688 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:09:55.277231 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "analytics"."staging"."stg_starlink_sattelite" rename to "stg_starlink_sattelite__dbt_backup"
[0m02:09:55.468049 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:55.477873 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:09:55.478625 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "analytics"."staging"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m02:09:55.594834 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:55.627949 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:09:55.628498 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:09:55.628847 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:09:56.619146 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:09:56.621220 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:09:56.622344 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:09:56.699978 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:56.717654 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:09:56.718383 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "analytics"."staging"."stg_starlink_sattelite__dbt_backup" cascade
[0m02:09:56.796727 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:56.797788 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:09:56.798179 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:09:56.798467 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:09:57.807339 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:09:57.809092 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:09:57.810245 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:09:57.850087 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:57.852997 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:09:33.955402 => 02:09:57.852525
[0m02:09:57.853992 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:09:57.932139 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:09:57.935630 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6a86113e-4efe-41d8-b430-a6b32fd83c70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8802d0>]}
[0m02:09:57.937734 [info ] [Thread-1 (]: 1 of 2 OK created sql table model staging.stg_starlink_sattelite ............... [[32mSUCCESS[0m in 23.99s]
[0m02:09:57.939370 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:09:57.942339 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m02:09:57.943308 [info ] [Thread-3 (]: 2 of 2 START sql table model public.dim_starlink_sattelite ..................... [RUN]
[0m02:09:57.944420 [debug] [Thread-3 (]: Acquiring new redshift connection 'model.dbt_remote.dim_starlink_sattelite'
[0m02:09:57.944907 [debug] [Thread-3 (]: Began compiling node model.dbt_remote.dim_starlink_sattelite
[0m02:09:57.988404 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:09:57.988813 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m02:09:57.989084 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:09:57.989593 [debug] [Thread-3 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:09:57.989979 [debug] [Thread-3 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:09:58.377466 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:58.379058 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:09:58.380615 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_starlink_sattelite'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_starlink_sattelite'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_starlink_sattelite'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m02:09:58.568310 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:09:58.578149 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_remote.dim_starlink_sattelite"
[0m02:09:58.579370 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (compile): 02:09:57.945244 => 02:09:58.579060
[0m02:09:58.579912 [debug] [Thread-3 (]: Began executing node model.dbt_remote.dim_starlink_sattelite
[0m02:09:58.586285 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_remote.dim_starlink_sattelite"
[0m02:09:58.590224 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:09:58.590786 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

  
    

  create  table
    "analytics"."public"."dim_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    


with max_ingested as (
    select
        s.object_id,
        max(s.export_date) as last_ingested_date
    from "analytics"."staging"."stg_starlink_sattelite" s
    group  by 1)

select
    s."object_id",
  s."object_name",
  s."launch_id",
  s."version_id",
  s."latitude",
  s."longitude",
  s."velocity_kms",
  s."center_name",
  s."time_system",
  s."launch_date",
  s."export_date",
    case when s.export_date != m.last_ingested_date then true else false end as deleted_flag
from
    "analytics"."staging"."stg_starlink_sattelite" s

left join max_ingested m
on m.object_id = s.object_id

where s.rnk = 1
  );
[0m02:10:08.579840 [debug] [Thread-3 (]: SQL status: SUCCESS in 10.0 seconds
[0m02:10:08.588771 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:10:08.589956 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "analytics"."public"."dim_starlink_sattelite" rename to "dim_starlink_sattelite__dbt_backup"
[0m02:10:08.826107 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:08.835298 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:10:08.836061 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "analytics"."public"."dim_starlink_sattelite__dbt_tmp" rename to "dim_starlink_sattelite"
[0m02:10:08.958627 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:08.963734 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m02:10:08.964840 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:10:08.965508 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m02:10:10.095022 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:10:10.096996 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:10:10.097897 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m02:10:10.179575 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:10.187877 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:10:10.188544 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
drop table if exists "analytics"."public"."dim_starlink_sattelite__dbt_backup" cascade
[0m02:10:10.270126 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:10.273462 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m02:10:10.274548 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:10:10.275221 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m02:10:11.200731 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:10:11.201607 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:10:11.202010 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m02:10:11.242448 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:11.243595 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (execute): 02:09:58.580246 => 02:10:11.243410
[0m02:10:11.243982 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: ROLLBACK
[0m02:10:11.324141 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: Close
[0m02:10:11.325560 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6a86113e-4efe-41d8-b430-a6b32fd83c70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b231710>]}
[0m02:10:11.326356 [info ] [Thread-3 (]: 2 of 2 OK created sql table model public.dim_starlink_sattelite ................ [[32mSUCCESS[0m in 13.38s]
[0m02:10:11.327138 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m02:10:11.330102 [debug] [MainThread]: Using redshift connection "master"
[0m02:10:11.330656 [debug] [MainThread]: On master: BEGIN
[0m02:10:11.331040 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:10:11.331727 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:10:11.332168 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:10:11.724551 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:11.725924 [debug] [MainThread]: On master: COMMIT
[0m02:10:11.727170 [debug] [MainThread]: Using redshift connection "master"
[0m02:10:11.728028 [debug] [MainThread]: On master: COMMIT
[0m02:10:11.809115 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:10:11.810484 [debug] [MainThread]: On master: Close
[0m02:10:11.813083 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:10:11.814009 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:10:11.815036 [debug] [MainThread]: Connection 'list_analytics_staging' was properly closed.
[0m02:10:11.815722 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_sattelite' was properly closed.
[0m02:10:11.816672 [info ] [MainThread]: 
[0m02:10:11.817388 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 39.83 seconds (39.83s).
[0m02:10:11.819554 [debug] [MainThread]: Command end result
[0m02:10:11.884146 [info ] [MainThread]: 
[0m02:10:11.884512 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:10:11.884699 [info ] [MainThread]: 
[0m02:10:11.885021 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m02:10:11.885458 [debug] [MainThread]: Command `dbt run` succeeded at 02:10:11.885369 after 40.06 seconds
[0m02:10:11.885724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098d1e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f03d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f10d50>]}
[0m02:10:11.885973 [debug] [MainThread]: Flushing usage events
[0m02:23:08.839701 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102bbd150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106904e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10685af50>]}


============================== 02:23:08.842037 | 30fb8eb5-9782-4896-b401-5487b19411f0 ==============================
[0m02:23:08.842037 [info ] [MainThread]: Running with dbt=1.6.0
[0m02:23:08.842347 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:23:08.919533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '30fb8eb5-9782-4896-b401-5487b19411f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068581d0>]}
[0m02:23:08.923865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '30fb8eb5-9782-4896-b401-5487b19411f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dbfa90>]}
[0m02:23:08.924186 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m02:23:08.932346 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m02:23:08.952323 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m02:23:08.952975 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/schema.yml
[0m02:23:08.953199 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/Starlink/dim_starlink_sattelite.sql
[0m02:23:09.001167 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m02:23:09.004357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '30fb8eb5-9782-4896-b401-5487b19411f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10657e510>]}
[0m02:23:09.010907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '30fb8eb5-9782-4896-b401-5487b19411f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107702c90>]}
[0m02:23:09.011181 [info ] [MainThread]: Found 2 models, 4 tests, 1 source, 0 exposures, 0 metrics, 512 macros, 0 groups, 0 semantic models
[0m02:23:09.011351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '30fb8eb5-9782-4896-b401-5487b19411f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107790250>]}
[0m02:23:09.012201 [info ] [MainThread]: 
[0m02:23:09.012635 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m02:23:09.013222 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m02:23:09.021458 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m02:23:09.021664 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m02:23:09.021808 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:23:09.022320 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:23:09.022472 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:23:09.023684 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m02:23:09.024906 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m02:23:09.025063 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m02:23:09.025194 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:23:09.025383 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:23:09.025522 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:23:09.635160 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:23:09.639694 [debug] [ThreadPool]: On list_analytics: Close
[0m02:23:09.646134 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m02:23:09.648691 [debug] [ThreadPool]: On list_analytics: Close
[0m02:23:09.651739 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_public)
[0m02:23:09.652894 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_staging)
[0m02:23:09.663505 [debug] [ThreadPool]: Using redshift connection "list_analytics_public"
[0m02:23:09.668072 [debug] [ThreadPool]: Using redshift connection "list_analytics_staging"
[0m02:23:09.668475 [debug] [ThreadPool]: On list_analytics_public: BEGIN
[0m02:23:09.668806 [debug] [ThreadPool]: On list_analytics_staging: BEGIN
[0m02:23:09.669119 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:23:09.669421 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:23:09.669955 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:23:09.670484 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:23:09.670883 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:23:09.671234 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:23:10.048490 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:10.049667 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:10.050725 [debug] [ThreadPool]: Using redshift connection "list_analytics_public"
[0m02:23:10.051657 [debug] [ThreadPool]: Using redshift connection "list_analytics_staging"
[0m02:23:10.052605 [debug] [ThreadPool]: On list_analytics_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m02:23:10.053786 [debug] [ThreadPool]: On list_analytics_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m02:23:10.147434 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:10.148792 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:10.152434 [debug] [ThreadPool]: On list_analytics_public: ROLLBACK
[0m02:23:10.155433 [debug] [ThreadPool]: On list_analytics_staging: ROLLBACK
[0m02:23:10.239191 [debug] [ThreadPool]: On list_analytics_public: Close
[0m02:23:10.242548 [debug] [ThreadPool]: On list_analytics_staging: Close
[0m02:23:10.257124 [debug] [MainThread]: Using redshift connection "master"
[0m02:23:10.257640 [debug] [MainThread]: On master: BEGIN
[0m02:23:10.258019 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:23:10.258635 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:23:10.259074 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:23:10.645389 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:10.646924 [debug] [MainThread]: Using redshift connection "master"
[0m02:23:10.648433 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m02:23:10.767230 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:10.771509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '30fb8eb5-9782-4896-b401-5487b19411f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e29550>]}
[0m02:23:10.772738 [debug] [MainThread]: On master: ROLLBACK
[0m02:23:10.865292 [debug] [MainThread]: Using redshift connection "master"
[0m02:23:10.866136 [debug] [MainThread]: On master: BEGIN
[0m02:23:10.906154 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:10.906672 [debug] [MainThread]: On master: COMMIT
[0m02:23:10.907107 [debug] [MainThread]: Using redshift connection "master"
[0m02:23:10.907423 [debug] [MainThread]: On master: COMMIT
[0m02:23:10.986067 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:10.986620 [debug] [MainThread]: On master: Close
[0m02:23:10.987683 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m02:23:10.988077 [info ] [MainThread]: 
[0m02:23:10.990357 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_sattelite
[0m02:23:10.990904 [info ] [Thread-1 (]: 1 of 2 START sql table model staging.stg_starlink_sattelite .................... [RUN]
[0m02:23:10.992088 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_public, now model.dbt_remote.stg_starlink_sattelite)
[0m02:23:10.992527 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_sattelite
[0m02:23:10.997103 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:10.998116 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (compile): 02:23:10.992798 => 02:23:10.997880
[0m02:23:10.998549 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_sattelite
[0m02:23:11.039144 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:11.040967 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:11.041198 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:23:11.041397 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:23:11.041714 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:23:11.041926 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:23:11.406750 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:11.407704 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:11.408417 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */

  
    

  create  table
    "analytics"."staging"."stg_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date::date as export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "analytics"."raw"."starlink_satellites" s
  );
[0m02:23:13.458178 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m02:23:13.468267 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:13.469006 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "analytics"."staging"."stg_starlink_sattelite" rename to "stg_starlink_sattelite__dbt_backup"
[0m02:23:13.661687 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:13.665096 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:13.665439 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
alter table "analytics"."staging"."stg_starlink_sattelite__dbt_tmp" rename to "stg_starlink_sattelite"
[0m02:23:13.780874 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:13.806189 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:23:13.806746 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:13.807089 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:23:14.728714 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:23:14.729594 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:14.729970 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:23:14.806989 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:14.814718 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:14.815143 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_sattelite"} */
drop table if exists "analytics"."staging"."stg_starlink_sattelite__dbt_backup" cascade
[0m02:23:14.891949 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:14.892809 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:23:14.893129 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:14.893363 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: COMMIT
[0m02:23:15.793138 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:23:15.794733 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_sattelite"
[0m02:23:15.795590 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: BEGIN
[0m02:23:15.836186 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:15.838271 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_sattelite (execute): 02:23:10.998824 => 02:23:15.837927
[0m02:23:15.839262 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: ROLLBACK
[0m02:23:15.917430 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_sattelite: Close
[0m02:23:15.920166 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '30fb8eb5-9782-4896-b401-5487b19411f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ddd110>]}
[0m02:23:15.921411 [info ] [Thread-1 (]: 1 of 2 OK created sql table model staging.stg_starlink_sattelite ............... [[32mSUCCESS[0m in 4.93s]
[0m02:23:15.922729 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_sattelite
[0m02:23:15.924854 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_sattelite
[0m02:23:15.925828 [info ] [Thread-3 (]: 2 of 2 START sql table model public.dim_starlink_sattelite ..................... [RUN]
[0m02:23:15.927057 [debug] [Thread-3 (]: Acquiring new redshift connection 'model.dbt_remote.dim_starlink_sattelite'
[0m02:23:15.927575 [debug] [Thread-3 (]: Began compiling node model.dbt_remote.dim_starlink_sattelite
[0m02:23:15.957040 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:15.957489 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m02:23:15.957786 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:23:15.958290 [debug] [Thread-3 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:23:15.958719 [debug] [Thread-3 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:23:16.325856 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:16.326256 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:16.326568 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_starlink_sattelite'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_starlink_sattelite'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_starlink_sattelite'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m02:23:16.503945 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:16.509301 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:16.510344 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (compile): 02:23:15.927912 => 02:23:16.510115
[0m02:23:16.510757 [debug] [Thread-3 (]: Began executing node model.dbt_remote.dim_starlink_sattelite
[0m02:23:16.517903 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:16.561777 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:16.562122 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */

  
    

  create  table
    "analytics"."public"."dim_starlink_sattelite__dbt_tmp"
    
    diststyle even
    
  as (
    


with max_ingested as (
    select
        s.object_id,
        max(s.export_date) as last_ingested_date
    from "analytics"."staging"."stg_starlink_sattelite" s
    group  by 1)

select
    s."object_id",
  s."object_name",
  s."launch_id",
  s."version_id",
  s."latitude",
  s."longitude",
  s."velocity_kms",
  s."center_name",
  s."time_system",
  s."launch_date",
  s."export_date",
    -- true if we ingested id before and it's not available for the latest ingest
    case when s.export_date != m.last_ingested_date then true else false end as deleted_flag
from
    "analytics"."staging"."stg_starlink_sattelite" s

left join max_ingested m
on m.object_id = s.object_id

where s.rnk = 1
  );
[0m02:23:17.062317 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:17.067713 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:17.068294 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "analytics"."public"."dim_starlink_sattelite" rename to "dim_starlink_sattelite__dbt_backup"
[0m02:23:17.290692 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:17.299434 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:17.300137 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
alter table "analytics"."public"."dim_starlink_sattelite__dbt_tmp" rename to "dim_starlink_sattelite"
[0m02:23:17.415657 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:17.421546 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m02:23:17.422748 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:17.423546 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m02:23:18.373069 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:23:18.374177 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:18.374698 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m02:23:18.452150 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:18.458389 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:18.459096 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_sattelite"} */
drop table if exists "analytics"."public"."dim_starlink_sattelite__dbt_backup" cascade
[0m02:23:18.536070 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:18.538269 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m02:23:18.539393 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:18.540142 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: COMMIT
[0m02:23:19.520428 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m02:23:19.522014 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_sattelite"
[0m02:23:19.523164 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: BEGIN
[0m02:23:19.563014 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:19.566152 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_sattelite (execute): 02:23:16.511034 => 02:23:19.565585
[0m02:23:19.567138 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: ROLLBACK
[0m02:23:19.645701 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_sattelite: Close
[0m02:23:19.648268 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '30fb8eb5-9782-4896-b401-5487b19411f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cf1fd0>]}
[0m02:23:19.649900 [info ] [Thread-3 (]: 2 of 2 OK created sql table model public.dim_starlink_sattelite ................ [[32mSUCCESS[0m in 3.72s]
[0m02:23:19.651191 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_sattelite
[0m02:23:19.655001 [debug] [MainThread]: Using redshift connection "master"
[0m02:23:19.655690 [debug] [MainThread]: On master: BEGIN
[0m02:23:19.656447 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:23:19.657431 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m02:23:19.657974 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m02:23:20.031607 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:20.032402 [debug] [MainThread]: On master: COMMIT
[0m02:23:20.033159 [debug] [MainThread]: Using redshift connection "master"
[0m02:23:20.033748 [debug] [MainThread]: On master: COMMIT
[0m02:23:20.113573 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m02:23:20.114388 [debug] [MainThread]: On master: Close
[0m02:23:20.115788 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:23:20.116565 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_sattelite' was properly closed.
[0m02:23:20.117050 [debug] [MainThread]: Connection 'list_analytics_staging' was properly closed.
[0m02:23:20.117509 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_sattelite' was properly closed.
[0m02:23:20.118331 [info ] [MainThread]: 
[0m02:23:20.118985 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 11.11 seconds (11.11s).
[0m02:23:20.120201 [debug] [MainThread]: Command end result
[0m02:23:20.137347 [info ] [MainThread]: 
[0m02:23:20.137907 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:23:20.138257 [info ] [MainThread]: 
[0m02:23:20.138621 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m02:23:20.139338 [debug] [MainThread]: Command `dbt run` succeeded at 02:23:20.139179 after 11.31 seconds
[0m02:23:20.139821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102261c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102304790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102304cd0>]}
[0m02:23:20.140276 [debug] [MainThread]: Flushing usage events
[0m21:17:20.738704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068866d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b1b950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106887450>]}


============================== 21:17:20.741379 | fcc0841e-c249-4a43-a875-2c938f80e1b4 ==============================
[0m21:17:20.741379 [info ] [MainThread]: Running with dbt=1.6.0
[0m21:17:20.741698 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:17:20.763693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fcc0841e-c249-4a43-a875-2c938f80e1b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106863350>]}
[0m21:17:20.777570 [debug] [MainThread]: Command `dbt clean` succeeded at 21:17:20.777486 after 0.05 seconds
[0m21:17:20.777790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1025e7d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102551c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068273d0>]}
[0m21:17:20.777996 [debug] [MainThread]: Flushing usage events
[0m21:18:14.908847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fb2990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10949d4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10981d1d0>]}


============================== 21:18:14.911188 | 578fdfd8-e685-4df7-84a2-598291b1c771 ==============================
[0m21:18:14.911188 [info ] [MainThread]: Running with dbt=1.6.0
[0m21:18:14.911497 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:18:15.005954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '578fdfd8-e685-4df7-84a2-598291b1c771', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109758210>]}
[0m21:18:15.010178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '578fdfd8-e685-4df7-84a2-598291b1c771', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109558ed0>]}
[0m21:18:15.010713 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m21:18:15.011203 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found 1 package(s) specified in packages.yml, but only 0 package(s) installed in dbt_packages. Run "dbt deps" to install package dependencies.
[0m21:18:15.011580 [debug] [MainThread]: Command `dbt run` failed at 21:18:15.011505 after 0.11 seconds
[0m21:18:15.011800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109741f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10981f850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a5d6d0>]}
[0m21:18:15.011984 [debug] [MainThread]: Flushing usage events
[0m21:18:23.595862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106df3310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dfd9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106df0710>]}


============================== 21:18:23.598131 | b0d3b9a5-817f-401a-9eec-91024508de14 ==============================
[0m21:18:23.598131 [info ] [MainThread]: Running with dbt=1.6.0
[0m21:18:23.598430 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:18:23.614393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b0d3b9a5-817f-401a-9eec-91024508de14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f113d0>]}
[0m21:18:23.615279 [debug] [MainThread]: Set downloads directory='/var/folders/mq/g3w56qvd2qjdkn68h0xg37nr0000gn/T/dbt-downloads-yjl4hil3'
[0m21:18:23.615572 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:18:23.847336 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m21:18:23.850341 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m21:18:23.995854 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m21:18:24.010346 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m21:18:24.447964 [info ] [MainThread]: Installed from version 1.1.1
[0m21:18:24.448268 [info ] [MainThread]: Up to date!
[0m21:18:24.448536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'b0d3b9a5-817f-401a-9eec-91024508de14', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b6aa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b33590>]}
[0m21:18:24.449282 [debug] [MainThread]: Command `dbt deps` succeeded at 21:18:24.449203 after 0.86 seconds
[0m21:18:24.449517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102527d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102491c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106af2c90>]}
[0m21:18:24.449744 [debug] [MainThread]: Flushing usage events
[0m21:18:27.630345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109228650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ffef90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f69ed0>]}


============================== 21:18:27.632569 | 8e8c06cb-9d44-44fe-8e45-1d5b8bf4f052 ==============================
[0m21:18:27.632569 [info ] [MainThread]: Running with dbt=1.6.0
[0m21:18:27.632878 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:18:27.710007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8e8c06cb-9d44-44fe-8e45-1d5b8bf4f052', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f54210>]}
[0m21:18:27.714282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8e8c06cb-9d44-44fe-8e45-1d5b8bf4f052', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10987f790>]}
[0m21:18:27.714609 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m21:18:27.723306 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m21:18:27.723714 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m21:18:27.723912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '8e8c06cb-9d44-44fe-8e45-1d5b8bf4f052', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f6a190>]}
[0m21:18:28.257820 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m21:18:28.260975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8e8c06cb-9d44-44fe-8e45-1d5b8bf4f052', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091a3f90>]}
[0m21:18:28.267836 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8e8c06cb-9d44-44fe-8e45-1d5b8bf4f052', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d36010>]}
[0m21:18:28.268127 [info ] [MainThread]: Found 2 models, 4 tests, 1 source, 0 exposures, 0 metrics, 512 macros, 0 groups, 0 semantic models
[0m21:18:28.268297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8e8c06cb-9d44-44fe-8e45-1d5b8bf4f052', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106231610>]}
[0m21:18:28.269085 [info ] [MainThread]: 
[0m21:18:28.269478 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m21:18:28.270012 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m21:18:28.277972 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m21:18:28.278332 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m21:18:28.278532 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m21:18:28.279694 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m21:18:28.279860 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:18:28.280042 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m21:18:28.280630 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:18:28.280796 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:18:28.280953 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:18:28.281141 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:18:28.282028 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:18:28.874521 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m21:18:28.875990 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m21:18:28.879443 [debug] [ThreadPool]: On list_analytics: Close
[0m21:18:28.882491 [debug] [ThreadPool]: On list_analytics: Close
[0m21:18:28.886069 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_public)
[0m21:18:28.887073 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_staging)
[0m21:18:28.898054 [debug] [ThreadPool]: Using redshift connection "list_analytics_public"
[0m21:18:28.902484 [debug] [ThreadPool]: Using redshift connection "list_analytics_staging"
[0m21:18:28.902861 [debug] [ThreadPool]: On list_analytics_public: BEGIN
[0m21:18:28.903195 [debug] [ThreadPool]: On list_analytics_staging: BEGIN
[0m21:18:28.903496 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:18:28.903794 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:18:28.904275 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:18:28.904713 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:18:28.905041 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:18:28.905355 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:18:48.778466 [debug] [ThreadPool]: SQL status: SUCCESS in 20.0 seconds
[0m21:18:48.779106 [debug] [ThreadPool]: SQL status: SUCCESS in 20.0 seconds
[0m21:18:48.779708 [debug] [ThreadPool]: Using redshift connection "list_analytics_public"
[0m21:18:48.780151 [debug] [ThreadPool]: Using redshift connection "list_analytics_staging"
[0m21:18:48.780644 [debug] [ThreadPool]: On list_analytics_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m21:18:48.781144 [debug] [ThreadPool]: On list_analytics_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m21:18:48.883947 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:18:48.885717 [debug] [ThreadPool]: On list_analytics_staging: ROLLBACK
[0m21:18:48.886106 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:18:48.887665 [debug] [ThreadPool]: On list_analytics_public: ROLLBACK
[0m21:18:48.972764 [debug] [ThreadPool]: On list_analytics_staging: Close
[0m21:18:48.975397 [debug] [ThreadPool]: On list_analytics_public: Close
[0m21:18:48.982825 [debug] [MainThread]: Using redshift connection "master"
[0m21:18:48.983217 [debug] [MainThread]: On master: BEGIN
[0m21:18:48.983432 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:18:48.983771 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:18:48.983992 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:18:49.361435 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:18:49.361998 [debug] [MainThread]: Using redshift connection "master"
[0m21:18:49.362422 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m21:18:49.480189 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:18:49.481984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8e8c06cb-9d44-44fe-8e45-1d5b8bf4f052', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109cb1850>]}
[0m21:18:49.482628 [debug] [MainThread]: On master: ROLLBACK
[0m21:18:49.574029 [debug] [MainThread]: Using redshift connection "master"
[0m21:18:49.574703 [debug] [MainThread]: On master: BEGIN
[0m21:18:49.616385 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:18:49.616890 [debug] [MainThread]: On master: COMMIT
[0m21:18:49.617308 [debug] [MainThread]: Using redshift connection "master"
[0m21:18:49.617628 [debug] [MainThread]: On master: COMMIT
[0m21:18:49.696512 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:18:49.697016 [debug] [MainThread]: On master: Close
[0m21:18:49.697904 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m21:18:49.698259 [info ] [MainThread]: 
[0m21:18:49.701129 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_satellite
[0m21:18:49.701605 [info ] [Thread-1 (]: 1 of 2 START sql table model staging.stg_starlink_satellite .................... [RUN]
[0m21:18:49.702530 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_public, now model.dbt_remote.stg_starlink_satellite)
[0m21:18:49.702860 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_satellite
[0m21:18:49.706262 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_satellite"
[0m21:18:49.707300 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_satellite (compile): 21:18:49.703075 => 21:18:49.707121
[0m21:18:49.707629 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_satellite
[0m21:18:49.741496 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_satellite"
[0m21:18:49.743390 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_satellite"
[0m21:18:49.743626 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: BEGIN
[0m21:18:49.743821 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:49.744129 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:18:49.744324 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:18:50.107591 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:18:50.108137 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_satellite"
[0m21:18:50.108491 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_satellite"} */

  
    

  create  table
    "analytics"."staging"."stg_starlink_satellite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date::date as export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "analytics"."raw"."starlink_satellites" s
  );
[0m21:18:52.219704 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m21:18:52.233520 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_satellite"
[0m21:18:52.234244 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_satellite"} */
alter table "analytics"."staging"."stg_starlink_satellite__dbt_tmp" rename to "stg_starlink_satellite"
[0m21:18:52.434544 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:18:52.461599 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: COMMIT
[0m21:18:52.462235 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_satellite"
[0m21:18:52.462581 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: COMMIT
[0m21:18:53.612623 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m21:18:53.614432 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_satellite"
[0m21:18:53.615166 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: BEGIN
[0m21:18:53.695404 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:18:53.712208 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_satellite"
[0m21:18:53.712839 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_satellite"} */
drop table if exists "analytics"."staging"."stg_starlink_satellite__dbt_backup" cascade
[0m21:18:53.792006 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:18:53.793508 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: COMMIT
[0m21:18:53.794109 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_satellite"
[0m21:18:53.794571 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: COMMIT
[0m21:18:53.840925 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:18:53.841536 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_satellite"
[0m21:18:53.841986 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: BEGIN
[0m21:18:53.882738 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:18:53.885282 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_satellite (execute): 21:18:49.707832 => 21:18:53.884805
[0m21:18:53.886551 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: ROLLBACK
[0m21:18:53.966602 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: Close
[0m21:18:53.968061 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e8c06cb-9d44-44fe-8e45-1d5b8bf4f052', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a198350>]}
[0m21:18:53.968871 [info ] [Thread-1 (]: 1 of 2 OK created sql table model staging.stg_starlink_satellite ............... [[32mSUCCESS[0m in 4.27s]
[0m21:18:53.969651 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_satellite
[0m21:18:53.971626 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_satellite
[0m21:18:53.972382 [info ] [Thread-3 (]: 2 of 2 START sql table model public.dim_starlink_satellite ..................... [RUN]
[0m21:18:53.973510 [debug] [Thread-3 (]: Acquiring new redshift connection 'model.dbt_remote.dim_starlink_satellite'
[0m21:18:53.974031 [debug] [Thread-3 (]: Began compiling node model.dbt_remote.dim_starlink_satellite
[0m21:18:54.002465 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:18:54.003004 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: BEGIN
[0m21:18:54.003315 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:18:54.003828 [debug] [Thread-3 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:18:54.004262 [debug] [Thread-3 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:18:54.392647 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:18:54.393542 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:18:54.394465 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_satellite"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_starlink_satellite'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_starlink_satellite'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_starlink_satellite'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m21:18:54.578949 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:18:54.585091 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_remote.dim_starlink_satellite"
[0m21:18:54.586151 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_satellite (compile): 21:18:53.974355 => 21:18:54.585924
[0m21:18:54.586564 [debug] [Thread-3 (]: Began executing node model.dbt_remote.dim_starlink_satellite
[0m21:18:54.592386 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_remote.dim_starlink_satellite"
[0m21:18:54.596204 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:18:54.596719 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_satellite"} */

  
    

  create  table
    "analytics"."public"."dim_starlink_satellite__dbt_tmp"
    
    diststyle even
    
  as (
    


with max_ingested as (
    select
        s.object_id,
        max(s.export_date) as last_ingested_date
    from "analytics"."staging"."stg_starlink_satellite" s
    group  by 1)

select
    s."object_id",
  s."object_name",
  s."launch_id",
  s."version_id",
  s."latitude",
  s."longitude",
  s."velocity_kms",
  s."center_name",
  s."time_system",
  s."launch_date",
  s."export_date",
    -- true if we ingested id before and it's not available for the latest ingest
    case when s.export_date != m.last_ingested_date then true else false end as deleted_flag
from
    "analytics"."staging"."stg_starlink_satellite" s

left join max_ingested m
on m.object_id = s.object_id

where s.rnk = 1
  );
[0m21:19:01.477326 [debug] [Thread-3 (]: SQL status: SUCCESS in 7.0 seconds
[0m21:19:01.486108 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:19:01.487045 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_satellite"} */
alter table "analytics"."public"."dim_starlink_satellite__dbt_tmp" rename to "dim_starlink_satellite"
[0m21:19:01.726905 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:19:01.729744 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: COMMIT
[0m21:19:01.730409 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:19:01.730891 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: COMMIT
[0m21:19:02.663810 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m21:19:02.664524 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:19:02.664805 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: BEGIN
[0m21:19:02.746058 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:19:02.749967 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:19:02.750437 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_satellite"} */
drop table if exists "analytics"."public"."dim_starlink_satellite__dbt_backup" cascade
[0m21:19:02.831076 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:19:02.832534 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: COMMIT
[0m21:19:02.833165 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:19:02.833623 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: COMMIT
[0m21:19:02.880701 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:19:02.881606 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:19:02.882208 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: BEGIN
[0m21:19:02.923290 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:19:02.924511 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_satellite (execute): 21:18:54.586832 => 21:19:02.924305
[0m21:19:02.924938 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: ROLLBACK
[0m21:19:03.003872 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: Close
[0m21:19:03.005056 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e8c06cb-9d44-44fe-8e45-1d5b8bf4f052', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bba8110>]}
[0m21:19:03.005583 [info ] [Thread-3 (]: 2 of 2 OK created sql table model public.dim_starlink_satellite ................ [[32mSUCCESS[0m in 9.03s]
[0m21:19:03.006085 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_satellite
[0m21:19:03.008050 [debug] [MainThread]: Using redshift connection "master"
[0m21:19:03.008377 [debug] [MainThread]: On master: BEGIN
[0m21:19:03.008604 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:19:03.008961 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:19:03.009198 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:19:03.366182 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:19:03.366598 [debug] [MainThread]: On master: COMMIT
[0m21:19:03.366874 [debug] [MainThread]: Using redshift connection "master"
[0m21:19:03.367070 [debug] [MainThread]: On master: COMMIT
[0m21:19:03.442755 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:19:03.443137 [debug] [MainThread]: On master: Close
[0m21:19:03.443814 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:19:03.444035 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_satellite' was properly closed.
[0m21:19:03.444229 [debug] [MainThread]: Connection 'list_analytics_staging' was properly closed.
[0m21:19:03.444407 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_satellite' was properly closed.
[0m21:19:03.444636 [info ] [MainThread]: 
[0m21:19:03.444868 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 35.18 seconds (35.18s).
[0m21:19:03.445414 [debug] [MainThread]: Command end result
[0m21:19:03.456779 [info ] [MainThread]: 
[0m21:19:03.457101 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:19:03.457302 [info ] [MainThread]: 
[0m21:19:03.457492 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m21:19:03.457830 [debug] [MainThread]: Command `dbt run` succeeded at 21:19:03.457769 after 35.84 seconds
[0m21:19:03.458053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a1dc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ab3d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ac0d50>]}
[0m21:19:03.458269 [debug] [MainThread]: Flushing usage events
[0m21:53:14.256686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090129d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109279950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10927a110>]}


============================== 21:53:14.259498 | 469323db-2906-4137-a67a-5f470d8ae0d7 ==============================
[0m21:53:14.259498 [info ] [MainThread]: Running with dbt=1.6.0
[0m21:53:14.259838 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/data-engineer-code-exercise--hantypen/dbt_remote/logs', 'version_check': 'True', 'profiles_dir': '/Users/annaantypenko/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:53:14.356763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '469323db-2906-4137-a67a-5f470d8ae0d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c7be90>]}
[0m21:53:14.361008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '469323db-2906-4137-a67a-5f470d8ae0d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10950bfd0>]}
[0m21:53:14.361482 [info ] [MainThread]: Registered adapter: redshift=1.6.0
[0m21:53:14.370535 [debug] [MainThread]: checksum: 08dabea3fc65f9f8dd48613681c2bcd827397a7ba9ce4c6d52980aba1215e8c9, vars: {}, profile: , target: , version: 1.6.0
[0m21:53:14.398599 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:53:14.398841 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:53:14.399178 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m21:53:14.403470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '469323db-2906-4137-a67a-5f470d8ae0d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10994c790>]}
[0m21:53:14.411434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '469323db-2906-4137-a67a-5f470d8ae0d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10957fcd0>]}
[0m21:53:14.411729 [info ] [MainThread]: Found 2 models, 4 tests, 1 source, 0 exposures, 0 metrics, 512 macros, 0 groups, 0 semantic models
[0m21:53:14.411899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '469323db-2906-4137-a67a-5f470d8ae0d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ce30d0>]}
[0m21:53:14.412781 [info ] [MainThread]: 
[0m21:53:14.413181 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m21:53:14.413732 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m21:53:14.414118 [debug] [ThreadPool]: Acquiring new redshift connection 'list_analytics'
[0m21:53:14.422368 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m21:53:14.423548 [debug] [ThreadPool]: Using redshift connection "list_analytics"
[0m21:53:14.423711 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m21:53:14.423855 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
[0m21:53:14.423991 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:53:14.424115 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:53:14.424640 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:53:14.424832 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:53:14.424972 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:53:14.425101 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:53:14.986579 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m21:53:14.987426 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m21:53:14.991410 [debug] [ThreadPool]: On list_analytics: Close
[0m21:53:14.994314 [debug] [ThreadPool]: On list_analytics: Close
[0m21:53:14.998257 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_staging)
[0m21:53:14.999365 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_public)
[0m21:53:15.009486 [debug] [ThreadPool]: Using redshift connection "list_analytics_staging"
[0m21:53:15.013888 [debug] [ThreadPool]: Using redshift connection "list_analytics_public"
[0m21:53:15.014270 [debug] [ThreadPool]: On list_analytics_staging: BEGIN
[0m21:53:15.014596 [debug] [ThreadPool]: On list_analytics_public: BEGIN
[0m21:53:15.014899 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:53:15.015192 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:53:15.015681 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:53:15.016115 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:53:15.016444 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:53:15.016764 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:53:15.403687 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:15.405041 [debug] [ThreadPool]: Using redshift connection "list_analytics_public"
[0m21:53:15.406197 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:15.407196 [debug] [ThreadPool]: On list_analytics_public: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m21:53:15.408153 [debug] [ThreadPool]: Using redshift connection "list_analytics_staging"
[0m21:53:15.409203 [debug] [ThreadPool]: On list_analytics_staging: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_analytics_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m21:53:15.502303 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:15.506336 [debug] [ThreadPool]: On list_analytics_public: ROLLBACK
[0m21:53:15.507205 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:15.509860 [debug] [ThreadPool]: On list_analytics_staging: ROLLBACK
[0m21:53:15.593490 [debug] [ThreadPool]: On list_analytics_public: Close
[0m21:53:15.598291 [debug] [ThreadPool]: On list_analytics_staging: Close
[0m21:53:15.612163 [debug] [MainThread]: Using redshift connection "master"
[0m21:53:15.612700 [debug] [MainThread]: On master: BEGIN
[0m21:53:15.613095 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:53:15.613726 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:53:15.614144 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:53:15.997959 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:15.998592 [debug] [MainThread]: Using redshift connection "master"
[0m21:53:15.999112 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
where ref.relation_name != dep.relation_name
[0m21:53:16.115038 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:16.118448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '469323db-2906-4137-a67a-5f470d8ae0d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095407d0>]}
[0m21:53:16.119943 [debug] [MainThread]: On master: ROLLBACK
[0m21:53:16.210109 [debug] [MainThread]: Using redshift connection "master"
[0m21:53:16.210717 [debug] [MainThread]: On master: BEGIN
[0m21:53:16.250036 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:16.250880 [debug] [MainThread]: On master: COMMIT
[0m21:53:16.251457 [debug] [MainThread]: Using redshift connection "master"
[0m21:53:16.251879 [debug] [MainThread]: On master: COMMIT
[0m21:53:16.330204 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:16.331883 [debug] [MainThread]: On master: Close
[0m21:53:16.334436 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m21:53:16.335839 [info ] [MainThread]: 
[0m21:53:16.340934 [debug] [Thread-1 (]: Began running node model.dbt_remote.stg_starlink_satellite
[0m21:53:16.341766 [info ] [Thread-1 (]: 1 of 2 START sql table model staging.stg_starlink_satellite .................... [RUN]
[0m21:53:16.342924 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_analytics_staging, now model.dbt_remote.stg_starlink_satellite)
[0m21:53:16.343499 [debug] [Thread-1 (]: Began compiling node model.dbt_remote.stg_starlink_satellite
[0m21:53:16.348873 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_remote.stg_starlink_satellite"
[0m21:53:16.350367 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_satellite (compile): 21:53:16.343842 => 21:53:16.350053
[0m21:53:16.350860 [debug] [Thread-1 (]: Began executing node model.dbt_remote.stg_starlink_satellite
[0m21:53:16.399633 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_remote.stg_starlink_satellite"
[0m21:53:16.401452 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_satellite"
[0m21:53:16.401693 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: BEGIN
[0m21:53:16.401897 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:53:16.402220 [debug] [Thread-1 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:53:16.402440 [debug] [Thread-1 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:53:16.770075 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:16.771592 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_satellite"
[0m21:53:16.772801 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_satellite"} */

  
    

  create  table
    "analytics"."staging"."stg_starlink_satellite__dbt_tmp"
    
    diststyle even
    
  as (
    
    select
        s.spacetrack.object_id,
        s.spacetrack.object_name,
        s.launch as launch_id,
        s.version as version_id,
        s.latitude,
        s.longitude,
        s.velocity_kms,
        s.spacetrack.center_name,
        s.spacetrack.time_system,
        s.spacetrack.launch_date,
        s.export_date::date as export_date,
        row_number() over (partition by s.spacetrack.object_id order by s.export_date desc) as rnk
from "analytics"."raw"."starlink_satellites" s
  );
[0m21:53:18.952668 [debug] [Thread-1 (]: SQL status: SUCCESS in 2.0 seconds
[0m21:53:18.966415 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_satellite"
[0m21:53:18.967195 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_satellite"} */
alter table "analytics"."staging"."stg_starlink_satellite" rename to "stg_starlink_satellite__dbt_backup"
[0m21:53:19.166580 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:19.175255 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_satellite"
[0m21:53:19.175838 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_satellite"} */
alter table "analytics"."staging"."stg_starlink_satellite__dbt_tmp" rename to "stg_starlink_satellite"
[0m21:53:19.295458 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:19.328626 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: COMMIT
[0m21:53:19.329124 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_satellite"
[0m21:53:19.329481 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: COMMIT
[0m21:53:20.344613 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m21:53:20.345810 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_satellite"
[0m21:53:20.346441 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: BEGIN
[0m21:53:20.427941 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:20.446715 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_satellite"
[0m21:53:20.447341 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_starlink_satellite"} */
drop table if exists "analytics"."staging"."stg_starlink_satellite__dbt_backup" cascade
[0m21:53:20.528425 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:20.531703 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: COMMIT
[0m21:53:20.533113 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_satellite"
[0m21:53:20.534196 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: COMMIT
[0m21:53:21.410078 [debug] [Thread-1 (]: SQL status: SUCCESS in 1.0 seconds
[0m21:53:21.411850 [debug] [Thread-1 (]: Using redshift connection "model.dbt_remote.stg_starlink_satellite"
[0m21:53:21.412910 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: BEGIN
[0m21:53:21.454195 [debug] [Thread-1 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:21.457158 [debug] [Thread-1 (]: Timing info for model.dbt_remote.stg_starlink_satellite (execute): 21:53:16.351147 => 21:53:21.456738
[0m21:53:21.458142 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: ROLLBACK
[0m21:53:21.538410 [debug] [Thread-1 (]: On model.dbt_remote.stg_starlink_satellite: Close
[0m21:53:21.540945 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '469323db-2906-4137-a67a-5f470d8ae0d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109576310>]}
[0m21:53:21.542402 [info ] [Thread-1 (]: 1 of 2 OK created sql table model staging.stg_starlink_satellite ............... [[32mSUCCESS[0m in 5.20s]
[0m21:53:21.543836 [debug] [Thread-1 (]: Finished running node model.dbt_remote.stg_starlink_satellite
[0m21:53:21.546614 [debug] [Thread-3 (]: Began running node model.dbt_remote.dim_starlink_satellite
[0m21:53:21.547411 [info ] [Thread-3 (]: 2 of 2 START sql table model public.dim_starlink_satellite ..................... [RUN]
[0m21:53:21.548676 [debug] [Thread-3 (]: Acquiring new redshift connection 'model.dbt_remote.dim_starlink_satellite'
[0m21:53:21.549195 [debug] [Thread-3 (]: Began compiling node model.dbt_remote.dim_starlink_satellite
[0m21:53:21.593238 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:53:21.593680 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: BEGIN
[0m21:53:21.593953 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:53:21.594408 [debug] [Thread-3 (]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:53:21.594779 [debug] [Thread-3 (]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:53:21.975613 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:21.977411 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:53:21.979318 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_satellite"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_starlink_satellite'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_starlink_satellite'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_starlink_satellite'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m21:53:22.163593 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:22.174274 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_remote.dim_starlink_satellite"
[0m21:53:22.175516 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_satellite (compile): 21:53:21.549536 => 21:53:22.175238
[0m21:53:22.176011 [debug] [Thread-3 (]: Began executing node model.dbt_remote.dim_starlink_satellite
[0m21:53:22.182854 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_remote.dim_starlink_satellite"
[0m21:53:22.186335 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:53:22.186822 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_satellite"} */

  
    

  create  table
    "analytics"."public"."dim_starlink_satellite__dbt_tmp"
    
    diststyle even
    
  as (
    


with max_ingested as (
    select
        s.object_id,
        max(s.export_date) as last_ingested_date
    from "analytics"."staging"."stg_starlink_satellite" s
    group  by 1)

select
    s."object_id",
  s."object_name",
  s."launch_id",
  s."version_id",
  s."latitude",
  s."longitude",
  s."velocity_kms",
  s."center_name",
  s."time_system",
  s."launch_date",
  s."export_date",
    -- true if we ingested id before and it's not available for the latest ingest
    case when s.export_date != m.last_ingested_date then true else false end as deleted_flag
from
    "analytics"."staging"."stg_starlink_satellite" s

left join max_ingested m
on m.object_id = s.object_id

where s.rnk = 1
  );
[0m21:53:22.638681 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:22.647540 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:53:22.648162 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_satellite"} */
alter table "analytics"."public"."dim_starlink_satellite" rename to "dim_starlink_satellite__dbt_backup"
[0m21:53:22.886376 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:22.895210 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:53:22.895871 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_satellite"} */
alter table "analytics"."public"."dim_starlink_satellite__dbt_tmp" rename to "dim_starlink_satellite"
[0m21:53:23.016048 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:23.021865 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: COMMIT
[0m21:53:23.022903 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:53:23.023598 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: COMMIT
[0m21:53:23.950829 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m21:53:23.953244 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:53:23.954545 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: BEGIN
[0m21:53:24.039279 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:24.047222 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:53:24.047856 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: /* {"app": "dbt", "dbt_version": "1.6.0", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.dim_starlink_satellite"} */
drop table if exists "analytics"."public"."dim_starlink_satellite__dbt_backup" cascade
[0m21:53:24.129509 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:24.133061 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: COMMIT
[0m21:53:24.134655 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:53:24.135751 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: COMMIT
[0m21:53:24.973411 [debug] [Thread-3 (]: SQL status: SUCCESS in 1.0 seconds
[0m21:53:24.975217 [debug] [Thread-3 (]: Using redshift connection "model.dbt_remote.dim_starlink_satellite"
[0m21:53:24.976435 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: BEGIN
[0m21:53:25.018513 [debug] [Thread-3 (]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:25.021252 [debug] [Thread-3 (]: Timing info for model.dbt_remote.dim_starlink_satellite (execute): 21:53:22.176334 => 21:53:25.020762
[0m21:53:25.022364 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: ROLLBACK
[0m21:53:25.103421 [debug] [Thread-3 (]: On model.dbt_remote.dim_starlink_satellite: Close
[0m21:53:25.106802 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '469323db-2906-4137-a67a-5f470d8ae0d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109889010>]}
[0m21:53:25.108484 [info ] [Thread-3 (]: 2 of 2 OK created sql table model public.dim_starlink_satellite ................ [[32mSUCCESS[0m in 3.56s]
[0m21:53:25.109928 [debug] [Thread-3 (]: Finished running node model.dbt_remote.dim_starlink_satellite
[0m21:53:25.114241 [debug] [MainThread]: Using redshift connection "master"
[0m21:53:25.114894 [debug] [MainThread]: On master: BEGIN
[0m21:53:25.115302 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:53:25.115960 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:53:25.116415 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:53:25.494758 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:25.496037 [debug] [MainThread]: On master: COMMIT
[0m21:53:25.497166 [debug] [MainThread]: Using redshift connection "master"
[0m21:53:25.498414 [debug] [MainThread]: On master: COMMIT
[0m21:53:25.579295 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:53:25.580838 [debug] [MainThread]: On master: Close
[0m21:53:25.583609 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:53:25.584730 [debug] [MainThread]: Connection 'model.dbt_remote.stg_starlink_satellite' was properly closed.
[0m21:53:25.586011 [debug] [MainThread]: Connection 'list_analytics_public' was properly closed.
[0m21:53:25.586590 [debug] [MainThread]: Connection 'model.dbt_remote.dim_starlink_satellite' was properly closed.
[0m21:53:25.587080 [info ] [MainThread]: 
[0m21:53:25.587621 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 11.17 seconds (11.17s).
[0m21:53:25.589188 [debug] [MainThread]: Command end result
[0m21:53:25.605594 [info ] [MainThread]: 
[0m21:53:25.606187 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:53:25.606679 [info ] [MainThread]: 
[0m21:53:25.607086 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m21:53:25.607743 [debug] [MainThread]: Command `dbt run` succeeded at 21:53:25.607628 after 11.36 seconds
[0m21:53:25.608166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109012950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109012750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a43d50>]}
[0m21:53:25.608604 [debug] [MainThread]: Flushing usage events
[0m15:44:52.697073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107137400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10928f100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10926a100>]}


============================== 15:44:52.704635 | 39ce3427-fab8-418d-85e5-40fb3ded9e78 ==============================
[0m15:44:52.704635 [info ] [MainThread]: Running with dbt=1.7.1
[0m15:44:52.705004 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:44:52.756104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '39ce3427-fab8-418d-85e5-40fb3ded9e78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10926a6d0>]}
[0m15:44:52.756936 [debug] [MainThread]: Set downloads directory='/var/folders/mq/g3w56qvd2qjdkn68h0xg37nr0000gn/T/dbt-downloads-eppsvutn'
[0m15:44:52.757266 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m15:44:52.954591 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m15:44:52.959321 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m15:44:53.123378 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m15:44:53.139140 [info ] [MainThread]: Updating lock file in file path: /Users/annaantypenko/Desktop/Code/publishing-dbt/package-lock.yml
[0m15:44:53.162218 [debug] [MainThread]: Set downloads directory='/var/folders/mq/g3w56qvd2qjdkn68h0xg37nr0000gn/T/dbt-downloads-ydkn_b7j'
[0m15:44:53.166064 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m15:44:53.627614 [info ] [MainThread]: Installed from version 1.1.1
[0m15:44:53.627963 [info ] [MainThread]: Up to date!
[0m15:44:53.628558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '39ce3427-fab8-418d-85e5-40fb3ded9e78', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10937dee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10937df70>]}
[0m15:44:53.652548 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.99090785, "process_user_time": 1.467851, "process_kernel_time": 0.216521, "process_mem_max_rss": "100171776", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m15:44:53.653139 [debug] [MainThread]: Command `dbt deps` succeeded at 15:44:53.653015 after 0.99 seconds
[0m15:44:53.653448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107137400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10927a760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109340340>]}
[0m15:44:53.653779 [debug] [MainThread]: Flushing usage events
[0m15:45:07.156761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049d98e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107577ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075570d0>]}


============================== 15:45:07.159087 | 7051c01e-b80f-42d1-85c1-57b91b6fb525 ==============================
[0m15:45:07.159087 [info ] [MainThread]: Running with dbt=1.7.1
[0m15:45:07.159429 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt debug --config-dir', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:45:07.159832 [info ] [MainThread]: To view your profiles.yml file, run:

open /Users/annaantypenko/.dbt
[0m15:45:07.160968 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.034517832, "process_user_time": 1.102943, "process_kernel_time": 0.085996, "process_mem_max_rss": "93110272", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m15:45:07.161438 [debug] [MainThread]: Command `dbt debug` succeeded at 15:45:07.161346 after 0.04 seconds
[0m15:45:07.161668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049d98e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075362b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10753c310>]}
[0m15:45:07.161900 [debug] [MainThread]: Flushing usage events
[0m15:48:17.486040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b02c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117b6e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117df670>]}


============================== 15:48:17.488871 | aa3310d3-13da-418e-a104-fed99ede8015 ==============================
[0m15:48:17.488871 [info ] [MainThread]: Running with dbt=1.7.1
[0m15:48:17.489213 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'version_check': 'True', 'profiles_dir': '/Users/annaantypenko/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s stg_appointment_deleted_event', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:48:18.554450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aa3310d3-13da-418e-a104-fed99ede8015', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121697f0>]}
[0m15:48:18.602276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'aa3310d3-13da-418e-a104-fed99ede8015', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127c3a90>]}
[0m15:48:18.603584 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m15:48:18.613501 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m15:48:18.621836 [info ] [MainThread]: Unable to do partial parsing because of a version mismatch
[0m15:48:18.622286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'aa3310d3-13da-418e-a104-fed99ede8015', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112437370>]}
[0m15:48:19.520794 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m15:48:19.524344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aa3310d3-13da-418e-a104-fed99ede8015', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ba3a30>]}
[0m15:48:19.531857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aa3310d3-13da-418e-a104-fed99ede8015', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11242f9d0>]}
[0m15:48:19.532147 [info ] [MainThread]: Found 3 models, 4 tests, 1 source, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m15:48:19.532404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aa3310d3-13da-418e-a104-fed99ede8015', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11287bfd0>]}
[0m15:48:19.533322 [info ] [MainThread]: 
[0m15:48:19.533870 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m15:48:19.534492 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m15:48:19.545205 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m15:48:19.545480 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m15:48:19.545652 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:48:19.547643 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m15:48:19.547848 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m15:48:21.377957 [debug] [ThreadPool]: SQL status: SUCCESS in 2.0 seconds
[0m15:48:21.380486 [debug] [ThreadPool]: On list_prod: Close
[0m15:48:21.383608 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m15:48:21.391167 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod_public'
[0m15:48:21.396696 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m15:48:21.401773 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m15:48:21.402204 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m15:48:21.402580 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m15:48:21.402957 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:48:21.403299 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:48:21.403854 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m15:48:21.404306 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m15:48:21.404695 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m15:48:21.405072 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m15:48:22.994219 [debug] [ThreadPool]: SQL status: SUCCESS in 2.0 seconds
[0m15:48:22.996327 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m15:48:22.997653 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m15:48:22.999765 [debug] [ThreadPool]: SQL status: SUCCESS in 2.0 seconds
[0m15:48:23.000960 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m15:48:23.002175 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m15:48:23.271323 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m15:48:23.272493 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m15:48:23.273006 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m15:48:23.273861 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m15:48:23.536534 [debug] [ThreadPool]: On list_prod_staging: Close
[0m15:48:23.538449 [debug] [ThreadPool]: On list_prod_public: Close
[0m15:48:23.557416 [debug] [MainThread]: Using redshift connection "master"
[0m15:48:23.558057 [debug] [MainThread]: On master: BEGIN
[0m15:48:23.558483 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:48:23.559082 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m15:48:23.559521 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m15:48:25.179520 [debug] [MainThread]: SQL status: SUCCESS in 2.0 seconds
[0m15:48:25.180481 [debug] [MainThread]: Using redshift connection "master"
[0m15:48:25.181334 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m15:48:25.452958 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m15:48:25.458659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aa3310d3-13da-418e-a104-fed99ede8015', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132a0af0>]}
[0m15:48:25.459809 [debug] [MainThread]: On master: ROLLBACK
[0m15:48:25.717984 [debug] [MainThread]: Using redshift connection "master"
[0m15:48:25.718771 [debug] [MainThread]: On master: BEGIN
[0m15:48:25.846943 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m15:48:25.847419 [debug] [MainThread]: On master: COMMIT
[0m15:48:25.847790 [debug] [MainThread]: Using redshift connection "master"
[0m15:48:25.848071 [debug] [MainThread]: On master: COMMIT
[0m15:48:26.103316 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m15:48:26.104143 [debug] [MainThread]: On master: Close
[0m15:48:26.105644 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m15:48:26.106255 [info ] [MainThread]: 
[0m15:48:26.118584 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m15:48:26.119740 [info ] [Thread-1  ]: 1 of 1 START sql view model public.stg_appointment_deleted_event ............... [RUN]
[0m15:48:26.120935 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_deleted_event)
[0m15:48:26.121541 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m15:48:26.124939 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m15:48:26.126094 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 15:48:26.121870 => 15:48:26.125805
[0m15:48:26.126564 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m15:48:26.167398 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m15:48:26.169464 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m15:48:26.169933 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m15:48:26.170241 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m15:48:26.170736 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m15:48:26.171012 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m15:48:27.765034 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m15:48:27.765379 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m15:48:27.765614 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */


  create view "prod"."public"."stg_appointment_deleted_event__dbt_tmp" as (
    select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
limit 100
  ) ;
[0m15:48:28.154837 [debug] [Thread-1  ]: Redshift adapter: Redshift error: External tables are not supported in views
[0m15:48:28.157111 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m15:48:28.411616 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 15:48:26.126822 => 15:48:28.411012
[0m15:48:28.412435 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m15:48:28.430695 [debug] [Thread-1  ]: Database Error in model stg_appointment_deleted_event (models/starlink/satellite/stg_appointment_deleted_event.sql)
  External tables are not supported in views
  compiled Code at target/run/dbt_remote/models/starlink/satellite/stg_appointment_deleted_event.sql
[0m15:48:28.431416 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa3310d3-13da-418e-a104-fed99ede8015', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f275e0>]}
[0m15:48:28.432327 [error] [Thread-1  ]: 1 of 1 ERROR creating sql view model public.stg_appointment_deleted_event ...... [[31mERROR[0m in 2.31s]
[0m15:48:28.433186 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m15:48:28.435022 [debug] [MainThread]: Using redshift connection "master"
[0m15:48:28.435489 [debug] [MainThread]: On master: BEGIN
[0m15:48:28.435853 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:48:28.436385 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m15:48:28.436767 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m15:48:30.026434 [debug] [MainThread]: SQL status: SUCCESS in 2.0 seconds
[0m15:48:30.028574 [debug] [MainThread]: On master: COMMIT
[0m15:48:30.030210 [debug] [MainThread]: Using redshift connection "master"
[0m15:48:30.031358 [debug] [MainThread]: On master: COMMIT
[0m15:48:30.290834 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m15:48:30.293089 [debug] [MainThread]: On master: Close
[0m15:48:30.296660 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:48:30.297535 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m15:48:30.298291 [debug] [MainThread]: Connection 'list_prod_public' was properly closed.
[0m15:48:30.299248 [info ] [MainThread]: 
[0m15:48:30.300120 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 10.77 seconds (10.77s).
[0m15:48:30.302063 [debug] [MainThread]: Command end result
[0m15:48:30.321595 [info ] [MainThread]: 
[0m15:48:30.322318 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:48:30.322904 [info ] [MainThread]: 
[0m15:48:30.323430 [error] [MainThread]:   Database Error in model stg_appointment_deleted_event (models/starlink/satellite/stg_appointment_deleted_event.sql)
  External tables are not supported in views
  compiled Code at target/run/dbt_remote/models/starlink/satellite/stg_appointment_deleted_event.sql
[0m15:48:30.323899 [info ] [MainThread]: 
[0m15:48:30.324371 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:48:30.326555 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 12.872666, "process_user_time": 2.683163, "process_kernel_time": 0.237734, "process_mem_max_rss": "131874816", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m15:48:30.327176 [debug] [MainThread]: Command `dbt run` failed at 15:48:30.327030 after 12.87 seconds
[0m15:48:30.327617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b02c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11283b280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a66730>]}
[0m15:48:30.328069 [debug] [MainThread]: Flushing usage events
[0m15:48:51.624698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106305c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ffae50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109023670>]}


============================== 15:48:51.633662 | a6b58282-0c60-4345-b60f-d0068f1c3cdf ==============================
[0m15:48:51.633662 [info ] [MainThread]: Running with dbt=1.7.1
[0m15:48:51.634022 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run -s stg_appointment_deleted_event', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:48:51.987814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a6b58282-0c60-4345-b60f-d0068f1c3cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ffae50>]}
[0m15:48:52.035572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a6b58282-0c60-4345-b60f-d0068f1c3cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ab6c10>]}
[0m15:48:52.036818 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m15:48:52.051059 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m15:48:52.118083 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:48:52.118504 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/starlink/satellite/stg_appointment_deleted_event.sql
[0m15:48:52.230701 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m15:48:52.234338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a6b58282-0c60-4345-b60f-d0068f1c3cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a69d0d0>]}
[0m15:48:52.247552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a6b58282-0c60-4345-b60f-d0068f1c3cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2d9970>]}
[0m15:48:52.247870 [info ] [MainThread]: Found 3 models, 4 tests, 1 source, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m15:48:52.248084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a6b58282-0c60-4345-b60f-d0068f1c3cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2d98e0>]}
[0m15:48:52.248822 [info ] [MainThread]: 
[0m15:48:52.249363 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m15:48:52.250005 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m15:48:52.260767 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m15:48:52.261042 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m15:48:52.261217 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:48:52.263099 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m15:48:52.263306 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m15:48:54.148397 [debug] [ThreadPool]: SQL status: SUCCESS in 2.0 seconds
[0m15:48:54.149558 [debug] [ThreadPool]: On list_prod: Close
[0m15:48:54.150783 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now create_prod_staging)
[0m15:48:54.151318 [debug] [ThreadPool]: Creating schema "database: "prod"
schema: "staging"
"
[0m15:48:54.156382 [debug] [ThreadPool]: Using redshift connection "create_prod_staging"
[0m15:48:54.156624 [debug] [ThreadPool]: On create_prod_staging: BEGIN
[0m15:48:54.156828 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:48:54.157140 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m15:48:54.157363 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m15:48:55.360058 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m15:48:55.361887 [debug] [ThreadPool]: Using redshift connection "create_prod_staging"
[0m15:48:55.363016 [debug] [ThreadPool]: On create_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "create_prod_staging"} */
create schema if not exists "staging"
[0m15:48:55.952769 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m15:48:55.956612 [debug] [ThreadPool]: On create_prod_staging: COMMIT
[0m15:48:55.957690 [debug] [ThreadPool]: Using redshift connection "create_prod_staging"
[0m15:48:55.958293 [debug] [ThreadPool]: On create_prod_staging: COMMIT
[0m15:48:56.916061 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m15:48:56.918088 [debug] [ThreadPool]: On create_prod_staging: Close
[0m15:48:56.924673 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_prod_staging, now list_prod_staging)
[0m15:48:56.926764 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod_public'
[0m15:48:56.940777 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m15:48:56.946713 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m15:48:56.947179 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m15:48:56.947630 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m15:48:56.948049 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:48:56.948454 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:48:56.949093 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m15:48:56.949595 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m15:48:56.949979 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m15:48:56.950329 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m15:48:58.225466 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m15:48:58.227430 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m15:48:58.228464 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m15:48:58.541219 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m15:48:58.545713 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m15:48:58.728482 [debug] [ThreadPool]: SQL status: SUCCESS in 2.0 seconds
[0m15:48:58.730462 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m15:48:58.731470 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m15:48:58.852112 [debug] [ThreadPool]: On list_prod_staging: Close
[0m15:48:59.046697 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m15:48:59.051643 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m15:48:59.358687 [debug] [ThreadPool]: On list_prod_public: Close
[0m15:48:59.384063 [debug] [MainThread]: Using redshift connection "master"
[0m15:48:59.384658 [debug] [MainThread]: On master: BEGIN
[0m15:48:59.385093 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:48:59.385904 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m15:48:59.386357 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m15:49:00.590129 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m15:49:00.592040 [debug] [MainThread]: Using redshift connection "master"
[0m15:49:00.593039 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m15:49:00.905324 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m15:49:00.910476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a6b58282-0c60-4345-b60f-d0068f1c3cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a643520>]}
[0m15:49:00.911697 [debug] [MainThread]: On master: ROLLBACK
[0m15:49:01.209965 [debug] [MainThread]: Using redshift connection "master"
[0m15:49:01.210500 [debug] [MainThread]: On master: BEGIN
[0m15:49:01.361193 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m15:49:01.363870 [debug] [MainThread]: On master: COMMIT
[0m15:49:01.364381 [debug] [MainThread]: Using redshift connection "master"
[0m15:49:01.364753 [debug] [MainThread]: On master: COMMIT
[0m15:49:01.667459 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m15:49:01.669043 [debug] [MainThread]: On master: Close
[0m15:49:01.671836 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m15:49:01.672659 [info ] [MainThread]: 
[0m15:49:01.676919 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m15:49:01.677795 [info ] [Thread-1  ]: 1 of 1 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m15:49:01.679048 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_deleted_event)
[0m15:49:01.679680 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m15:49:01.685832 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m15:49:01.686954 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 15:49:01.680062 => 15:49:01.686629
[0m15:49:01.687489 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m15:49:01.737924 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m15:49:01.739775 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m15:49:01.740070 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m15:49:01.740333 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m15:49:01.740704 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m15:49:01.740977 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m15:49:03.520286 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m15:49:03.520645 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m15:49:03.520911 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
limit 100
  );
[0m15:49:16.610937 [debug] [Thread-1  ]: SQL status: SUCCESS in 13.0 seconds
[0m15:49:16.622221 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m15:49:16.622513 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m15:49:17.268099 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m15:49:17.285417 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m15:49:17.285810 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m15:49:17.286031 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m15:49:18.293115 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m15:49:18.295301 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m15:49:18.296239 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m15:49:18.555553 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m15:49:18.564352 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m15:49:18.567260 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m15:49:18.567512 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m15:49:18.827397 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m15:49:18.830847 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m15:49:18.832080 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m15:49:18.832915 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m15:49:18.969372 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m15:49:18.971161 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m15:49:18.972430 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m15:49:19.101781 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m15:49:19.104690 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 15:49:01.687800 => 15:49:19.104137
[0m15:49:19.105508 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m15:49:19.365044 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m15:49:19.368080 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6b58282-0c60-4345-b60f-d0068f1c3cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9dedf0>]}
[0m15:49:19.369504 [info ] [Thread-1  ]: 1 of 1 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 17.69s]
[0m15:49:19.370698 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m15:49:19.373336 [debug] [MainThread]: Using redshift connection "master"
[0m15:49:19.373725 [debug] [MainThread]: On master: BEGIN
[0m15:49:19.373927 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:49:19.374256 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m15:49:19.374462 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m15:49:20.967321 [debug] [MainThread]: SQL status: SUCCESS in 2.0 seconds
[0m15:49:20.968677 [debug] [MainThread]: On master: COMMIT
[0m15:49:20.969979 [debug] [MainThread]: Using redshift connection "master"
[0m15:49:20.970835 [debug] [MainThread]: On master: COMMIT
[0m15:49:21.227711 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m15:49:21.229098 [debug] [MainThread]: On master: Close
[0m15:49:21.231854 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:49:21.232981 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m15:49:21.233721 [debug] [MainThread]: Connection 'list_prod_public' was properly closed.
[0m15:49:21.234526 [info ] [MainThread]: 
[0m15:49:21.235285 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 28.99 seconds (28.99s).
[0m15:49:21.236640 [debug] [MainThread]: Command end result
[0m15:49:21.247500 [info ] [MainThread]: 
[0m15:49:21.247816 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:49:21.248015 [info ] [MainThread]: 
[0m15:49:21.248225 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:49:21.249325 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 29.67946, "process_user_time": 1.996113, "process_kernel_time": 0.233371, "process_mem_max_rss": "126222336", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m15:49:21.249646 [debug] [MainThread]: Command `dbt run` succeeded at 15:49:21.249572 after 29.68 seconds
[0m15:49:21.249879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106305c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ab6c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2d7c40>]}
[0m15:49:21.250119 [debug] [MainThread]: Flushing usage events
[0m16:00:42.691874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d5a670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e69160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e77310>]}


============================== 16:00:42.694698 | 12af1d6d-340b-4882-ab87-7f7d2b6d607b ==============================
[0m16:00:42.694698 [info ] [MainThread]: Running with dbt=1.7.1
[0m16:00:42.695047 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s fact_apointment_schedule', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:00:42.875537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '12af1d6d-340b-4882-ab87-7f7d2b6d607b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e69160>]}
[0m16:00:42.923778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '12af1d6d-340b-4882-ab87-7f7d2b6d607b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096ec9d0>]}
[0m16:00:42.925679 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m16:00:42.936030 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m16:00:42.972191 [debug] [MainThread]: Partial parsing enabled: 2 files deleted, 3 files added, 0 files changed.
[0m16:00:42.972573 [debug] [MainThread]: Partial parsing: added file: dbt_remote://models/starlink/satellite/stg_appointment_added_event.sql
[0m16:00:42.972780 [debug] [MainThread]: Partial parsing: added file: dbt_remote://models/starlink/satellite/fact_apointment_schedule.sql
[0m16:00:42.972977 [debug] [MainThread]: Partial parsing: added file: dbt_remote://models/starlink/satellite/stg_appointment_edited_event.sql
[0m16:00:42.973172 [debug] [MainThread]: Partial parsing: deleted file: dbt_remote://models/starlink/satellite/stg_starlink_satellite.sql
[0m16:00:42.973352 [debug] [MainThread]: Partial parsing: deleted file: dbt_remote://models/starlink/satellite/dim_starlink_satellite.sql
[0m16:00:43.106923 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_starlink_satellite' in the 'models' section of file 'models/starlink/satellite/schema.yml'
[0m16:00:43.108331 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'dim_starlink_satellite' in the 'models' section of file 'models/starlink/satellite/schema.yml'
[0m16:00:43.160335 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_remote.unique_stg_starlink_satellite_object_id.672191eec0' (models/starlink/satellite/schema.yml) depends on a node named 'stg_starlink_satellite' in package '' which was not found
[0m16:00:43.160671 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_remote.not_null_stg_starlink_satellite_object_id.c67a815a84' (models/starlink/satellite/schema.yml) depends on a node named 'stg_starlink_satellite' in package '' which was not found
[0m16:00:43.160899 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_remote.unique_dim_starlink_satellite_object_id.5723d54d45' (models/starlink/satellite/schema.yml) depends on a node named 'dim_starlink_satellite' in package '' which was not found
[0m16:00:43.161115 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_remote.not_null_dim_starlink_satellite_object_id.de34d0077e' (models/starlink/satellite/schema.yml) depends on a node named 'dim_starlink_satellite' in package '' which was not found
[0m16:00:43.165750 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m16:00:43.169609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '12af1d6d-340b-4882-ab87-7f7d2b6d607b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a298d90>]}
[0m16:00:43.177374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '12af1d6d-340b-4882-ab87-7f7d2b6d607b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f2ea90>]}
[0m16:00:43.177681 [info ] [MainThread]: Found 4 models, 1 source, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m16:00:43.177884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '12af1d6d-340b-4882-ab87-7f7d2b6d607b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f2ea00>]}
[0m16:00:43.178592 [info ] [MainThread]: 
[0m16:00:43.179077 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m16:00:43.179670 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m16:00:43.190379 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m16:00:43.190686 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m16:00:43.190867 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:00:43.192824 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:00:43.193026 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:00:44.985215 [debug] [ThreadPool]: SQL status: SUCCESS in 2.0 seconds
[0m16:00:44.987259 [debug] [ThreadPool]: On list_prod: Close
[0m16:00:44.989797 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m16:00:44.997005 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod_public'
[0m16:00:45.000316 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:00:45.004628 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:00:45.004991 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m16:00:45.005315 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m16:00:45.005610 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:00:45.005906 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:00:45.006369 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:00:45.006766 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:00:45.007097 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:00:45.007400 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:00:46.124825 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:00:46.126823 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:00:46.128000 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m16:00:46.403103 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:00:46.408010 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m16:00:46.605258 [debug] [ThreadPool]: SQL status: SUCCESS in 2.0 seconds
[0m16:00:46.605901 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:00:46.606393 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m16:00:46.672958 [debug] [ThreadPool]: On list_prod_public: Close
[0m16:00:46.881024 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:00:46.886249 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m16:00:47.153431 [debug] [ThreadPool]: On list_prod_staging: Close
[0m16:00:47.166079 [debug] [MainThread]: Using redshift connection "master"
[0m16:00:47.166614 [debug] [MainThread]: On master: BEGIN
[0m16:00:47.166982 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:00:47.167519 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:00:47.167910 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:00:48.259555 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m16:00:48.260051 [debug] [MainThread]: Using redshift connection "master"
[0m16:00:48.260379 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m16:00:48.560438 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:00:48.563772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '12af1d6d-340b-4882-ab87-7f7d2b6d607b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2b1cd0>]}
[0m16:00:48.565331 [debug] [MainThread]: On master: ROLLBACK
[0m16:00:48.836723 [debug] [MainThread]: Using redshift connection "master"
[0m16:00:48.838495 [debug] [MainThread]: On master: BEGIN
[0m16:00:48.967669 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:00:48.969666 [debug] [MainThread]: On master: COMMIT
[0m16:00:48.971195 [debug] [MainThread]: Using redshift connection "master"
[0m16:00:48.971840 [debug] [MainThread]: On master: COMMIT
[0m16:00:49.227791 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:00:49.229839 [debug] [MainThread]: On master: Close
[0m16:00:49.233607 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m16:00:49.234538 [info ] [MainThread]: 
[0m16:00:49.239841 [debug] [Thread-1  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m16:00:49.240794 [info ] [Thread-1  ]: 1 of 1 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m16:00:49.242102 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.fact_apointment_schedule)
[0m16:00:49.242744 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m16:00:49.255190 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m16:00:49.256628 [debug] [Thread-1  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 16:00:49.243126 => 16:00:49.256211
[0m16:00:49.257203 [debug] [Thread-1  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m16:00:49.306046 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m16:00:49.307797 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:00:49.308069 [debug] [Thread-1  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:00:49.308309 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m16:00:49.308659 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:00:49.308913 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:00:50.391174 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:00:50.393123 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:00:50.394239 [debug] [Thread-1  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited)

select * from find_dublicates
where rnk = 1
  );
[0m16:00:50.524960 [debug] [Thread-1  ]: Redshift adapter: Redshift error: relation "staging.stg_appointment_added_event" does not exist
[0m16:00:50.525389 [debug] [Thread-1  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m16:00:50.781110 [debug] [Thread-1  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 16:00:49.257528 => 16:00:50.780878
[0m16:00:50.781417 [debug] [Thread-1  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m16:00:50.788789 [debug] [Thread-1  ]: Database Error in model fact_apointment_schedule (models/starlink/satellite/fact_apointment_schedule.sql)
  relation "staging.stg_appointment_added_event" does not exist
  compiled Code at target/run/dbt_remote/models/starlink/satellite/fact_apointment_schedule.sql
[0m16:00:50.789105 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12af1d6d-340b-4882-ab87-7f7d2b6d607b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3816d0>]}
[0m16:00:50.789511 [error] [Thread-1  ]: 1 of 1 ERROR creating sql table model public.fact_apointment_schedule .......... [[31mERROR[0m in 1.55s]
[0m16:00:50.789875 [debug] [Thread-1  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m16:00:50.791062 [debug] [MainThread]: Using redshift connection "master"
[0m16:00:50.791294 [debug] [MainThread]: On master: BEGIN
[0m16:00:50.791470 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:00:50.791737 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:00:50.791922 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:00:52.367293 [debug] [MainThread]: SQL status: SUCCESS in 2.0 seconds
[0m16:00:52.369379 [debug] [MainThread]: On master: COMMIT
[0m16:00:52.370441 [debug] [MainThread]: Using redshift connection "master"
[0m16:00:52.371101 [debug] [MainThread]: On master: COMMIT
[0m16:00:52.630563 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:00:52.632740 [debug] [MainThread]: On master: Close
[0m16:00:52.636406 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:00:52.637262 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m16:00:52.638008 [debug] [MainThread]: Connection 'list_prod_public' was properly closed.
[0m16:00:52.638904 [info ] [MainThread]: 
[0m16:00:52.640225 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 9.46 seconds (9.46s).
[0m16:00:52.641776 [debug] [MainThread]: Command end result
[0m16:00:52.661328 [info ] [MainThread]: 
[0m16:00:52.661974 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:00:52.662845 [info ] [MainThread]: 
[0m16:00:52.663397 [error] [MainThread]:   Database Error in model fact_apointment_schedule (models/starlink/satellite/fact_apointment_schedule.sql)
  relation "staging.stg_appointment_added_event" does not exist
  compiled Code at target/run/dbt_remote/models/starlink/satellite/fact_apointment_schedule.sql
[0m16:00:52.663950 [info ] [MainThread]: 
[0m16:00:52.664645 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m16:00:52.667203 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 10.000417, "process_user_time": 1.940884, "process_kernel_time": 0.216662, "process_mem_max_rss": "129581056", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m16:00:52.667935 [debug] [MainThread]: Command `dbt run` failed at 16:00:52.667783 after 10.00 seconds
[0m16:00:52.668396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d5a670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e69160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098c7d00>]}
[0m16:00:52.668890 [debug] [MainThread]: Flushing usage events
[0m16:06:10.478440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10290a910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a419a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a27bb0>]}


============================== 16:06:10.481341 | 675ade14-90af-4887-8c99-5c761397e5ed ==============================
[0m16:06:10.481341 [info ] [MainThread]: Running with dbt=1.7.1
[0m16:06:10.481679 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'debug': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:06:10.665585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '675ade14-90af-4887-8c99-5c761397e5ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a419a0>]}
[0m16:06:10.715304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '675ade14-90af-4887-8c99-5c761397e5ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052a6be0>]}
[0m16:06:10.716723 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m16:06:10.726130 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m16:06:10.763843 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 4 files changed.
[0m16:06:10.764337 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/starlink/satellite/schema.yml
[0m16:06:10.764596 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/starlink/satellite/stg_appointment_edited_event.sql
[0m16:06:10.764823 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/starlink/satellite/stg_appointment_added_event.sql
[0m16:06:10.765049 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/starlink/satellite/stg_appointment_deleted_event.sql
[0m16:06:10.863902 [error] [MainThread]: Encountered an error:
Compilation Error in model stg_appointment_edited_event (models/starlink/satellite/stg_appointment_edited_event.sql)
  The source name (first) argument to source() must be a string, got <class 'dbt.clients.jinja.create_undefined.<locals>.Undefined'>
[0m16:06:10.865125 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.4200695, "process_user_time": 1.451176, "process_kernel_time": 0.149872, "process_mem_max_rss": "113000448", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m16:06:10.865517 [debug] [MainThread]: Command `dbt run` failed at 16:06:10.865437 after 0.42 seconds
[0m16:06:10.865748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10290a910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ac8df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bf1f40>]}
[0m16:06:10.865983 [debug] [MainThread]: Flushing usage events
[0m16:07:52.032166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1026948e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047c99a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047afbb0>]}


============================== 16:07:52.034996 | 170abc29-73f2-498e-a809-a3b1830128d5 ==============================
[0m16:07:52.034996 [info ] [MainThread]: Running with dbt=1.7.1
[0m16:07:52.035352 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'send_anonymous_usage_stats': 'True'}
[0m16:07:52.212700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '170abc29-73f2-498e-a809-a3b1830128d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047c99a0>]}
[0m16:07:52.260250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '170abc29-73f2-498e-a809-a3b1830128d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10502ebe0>]}
[0m16:07:52.260920 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m16:07:52.272134 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m16:07:52.309045 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 4 files changed.
[0m16:07:52.309550 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/starlink/satellite/schema.yml
[0m16:07:52.309805 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/starlink/satellite/stg_appointment_edited_event.sql
[0m16:07:52.310032 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/starlink/satellite/stg_appointment_deleted_event.sql
[0m16:07:52.310254 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/starlink/satellite/stg_appointment_added_event.sql
[0m16:07:52.403252 [error] [MainThread]: Encountered an error:
Compilation Error in model stg_appointment_edited_event (models/starlink/satellite/stg_appointment_edited_event.sql)
  The source name (first) argument to source() must be a string, got <class 'dbt.clients.jinja.create_undefined.<locals>.Undefined'>
[0m16:07:52.404430 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.40611967, "process_user_time": 1.41963, "process_kernel_time": 0.130037, "process_mem_max_rss": "113000448", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m16:07:52.404777 [debug] [MainThread]: Command `dbt run` failed at 16:07:52.404700 after 0.41 seconds
[0m16:07:52.405005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1026948e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052d43d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105970790>]}
[0m16:07:52.405234 [debug] [MainThread]: Flushing usage events
[0m16:09:24.293265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ac5580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bd3610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bdfd00>]}


============================== 16:09:24.295714 | 397ff834-d18b-49de-9519-de2564ebf3c9 ==============================
[0m16:09:24.295714 [info ] [MainThread]: Running with dbt=1.7.1
[0m16:09:24.296069 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:09:24.461734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '397ff834-d18b-49de-9519-de2564ebf3c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bb9250>]}
[0m16:09:24.511136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '397ff834-d18b-49de-9519-de2564ebf3c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10960df40>]}
[0m16:09:24.511688 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m16:09:24.520579 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m16:09:24.551167 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 4 files changed.
[0m16:09:24.551643 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/starlink/satellite/schema.yml
[0m16:09:24.551898 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/starlink/satellite/stg_appointment_added_event.sql
[0m16:09:24.552129 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/starlink/satellite/stg_appointment_edited_event.sql
[0m16:09:24.552365 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/starlink/satellite/stg_appointment_deleted_event.sql
[0m16:09:24.778869 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m16:09:24.782426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '397ff834-d18b-49de-9519-de2564ebf3c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0440d0>]}
[0m16:09:24.791154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '397ff834-d18b-49de-9519-de2564ebf3c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c91a00>]}
[0m16:09:24.791501 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m16:09:24.791715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '397ff834-d18b-49de-9519-de2564ebf3c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c91a90>]}
[0m16:09:24.792548 [info ] [MainThread]: 
[0m16:09:24.793085 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m16:09:24.793798 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m16:09:24.799546 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m16:09:24.808053 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m16:09:24.809817 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m16:09:24.810038 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m16:09:24.810245 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m16:09:24.810426 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:09:24.810595 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:09:24.812516 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:09:24.812763 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:09:24.812955 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:09:24.813137 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:09:26.108594 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:09:26.111267 [debug] [ThreadPool]: On list_prod: Close
[0m16:09:26.111987 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:09:26.114023 [debug] [ThreadPool]: On list_prod: Close
[0m16:09:26.118030 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m16:09:26.119472 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m16:09:26.131143 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:09:26.137522 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:09:26.138022 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m16:09:26.138417 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m16:09:26.138777 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:09:26.139122 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:09:26.139658 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:09:26.140089 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:09:26.140425 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:09:26.140747 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:09:27.249782 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:09:27.251657 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:09:27.252626 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:09:27.253540 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:09:27.254295 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m16:09:27.255235 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m16:09:27.561993 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:09:27.563818 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m16:09:27.564279 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:09:27.565677 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m16:09:27.827452 [debug] [ThreadPool]: On list_prod_staging: Close
[0m16:09:27.828678 [debug] [ThreadPool]: On list_prod_public: Close
[0m16:09:27.836202 [debug] [MainThread]: Using redshift connection "master"
[0m16:09:27.836520 [debug] [MainThread]: On master: BEGIN
[0m16:09:27.836745 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:09:27.837099 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:09:27.837338 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:09:28.910043 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m16:09:28.910812 [debug] [MainThread]: Using redshift connection "master"
[0m16:09:28.911494 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m16:09:29.209118 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:09:29.210195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '397ff834-d18b-49de-9519-de2564ebf3c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0bde50>]}
[0m16:09:29.210570 [debug] [MainThread]: On master: ROLLBACK
[0m16:09:29.479114 [debug] [MainThread]: Using redshift connection "master"
[0m16:09:29.480425 [debug] [MainThread]: On master: BEGIN
[0m16:09:29.608846 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:09:29.609162 [debug] [MainThread]: On master: COMMIT
[0m16:09:29.609410 [debug] [MainThread]: Using redshift connection "master"
[0m16:09:29.609595 [debug] [MainThread]: On master: COMMIT
[0m16:09:29.864239 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:09:29.864748 [debug] [MainThread]: On master: Close
[0m16:09:29.865760 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m16:09:29.866138 [info ] [MainThread]: 
[0m16:09:29.869134 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m16:09:29.869650 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m16:09:29.870184 [info ] [Thread-1  ]: 1 of 3 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m16:09:29.870712 [info ] [Thread-2  ]: 2 of 3 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m16:09:29.871821 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_added_event)
[0m16:09:29.872542 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_edited_event)
[0m16:09:29.872940 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m16:09:29.873301 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m16:09:29.877318 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m16:09:29.880781 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m16:09:29.881591 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 16:09:29.873525 => 16:09:29.881379
[0m16:09:29.882027 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 16:09:29.877635 => 16:09:29.881794
[0m16:09:29.882375 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m16:09:29.882712 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m16:09:29.938552 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m16:09:29.939358 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m16:09:29.940715 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:09:29.940951 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:09:29.941158 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m16:09:29.941452 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:09:29.941665 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:09:29.943129 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:09:29.943352 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:09:29.943581 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m16:09:29.943846 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:09:29.944076 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:09:31.039188 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:09:31.041448 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:09:31.042651 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:09:31.043498 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:09:31.044365 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m16:09:31.045140 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m16:09:38.829402 [debug] [Thread-1  ]: SQL status: SUCCESS in 8.0 seconds
[0m16:09:38.846371 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:09:38.847173 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m16:09:38.906800 [debug] [Thread-2  ]: SQL status: SUCCESS in 8.0 seconds
[0m16:09:38.913459 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:09:38.914129 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m16:09:39.487414 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:09:39.523706 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:09:39.524336 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:09:39.524776 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:09:39.551793 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:09:39.554186 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:09:39.554782 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:09:39.555276 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:09:41.246880 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:09:41.248434 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:09:41.250230 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:09:41.251520 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:09:41.507080 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:09:41.513412 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m16:09:41.517246 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:09:41.517579 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m16:09:41.774704 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:09:41.779072 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:09:41.780688 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:09:41.781969 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:09:41.916873 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:09:41.919272 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:09:41.920649 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:09:42.048930 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:09:42.049970 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 16:09:29.896053 => 16:09:42.049769
[0m16:09:42.050444 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:09:42.050829 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m16:09:42.051209 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:09:42.308801 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:09:42.310188 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m16:09:42.319524 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m16:09:42.321691 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:09:42.323073 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '397ff834-d18b-49de-9519-de2564ebf3c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2e3d60>]}
[0m16:09:42.323745 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m16:09:42.324846 [info ] [Thread-2  ]: 2 of 3 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 12.45s]
[0m16:09:42.326212 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m16:09:42.583578 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:09:42.586319 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:09:42.587328 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:09:42.587992 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:09:42.724591 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:09:42.727379 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:09:42.728771 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:09:42.858688 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:09:42.863333 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 16:09:29.882943 => 16:09:42.862581
[0m16:09:42.864106 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m16:09:43.121185 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m16:09:43.126000 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '397ff834-d18b-49de-9519-de2564ebf3c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0a71c0>]}
[0m16:09:43.127489 [info ] [Thread-1  ]: 1 of 3 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 13.25s]
[0m16:09:43.128575 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m16:09:43.129884 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m16:09:43.130877 [info ] [Thread-4  ]: 3 of 3 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m16:09:43.132528 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m16:09:43.133213 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m16:09:43.140475 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m16:09:43.141739 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 16:09:43.133608 => 16:09:43.141395
[0m16:09:43.142287 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m16:09:43.149346 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m16:09:43.151988 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:09:43.152478 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:09:43.152910 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m16:09:43.153548 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:09:43.153990 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:09:44.252279 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:09:44.253122 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:09:44.253828 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited)

select * from find_dublicates
where rnk = 1
  );
[0m16:10:00.456721 [debug] [Thread-4  ]: SQL status: SUCCESS in 16.0 seconds
[0m16:10:00.470116 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:10:00.471059 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m16:10:01.109363 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:10:01.116594 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:10:01.117849 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:10:01.118655 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:10:02.078566 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:10:02.081203 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:10:02.082238 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:10:02.340913 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:10:02.356018 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m16:10:02.358501 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:10:02.359307 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m16:10:02.618111 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:10:02.622703 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:10:02.624407 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:10:02.625699 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:10:02.762868 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:10:02.764997 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:10:02.765922 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:10:02.895333 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:10:02.899558 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 16:09:43.142603 => 16:10:02.898735
[0m16:10:02.900996 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m16:10:03.157343 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m16:10:03.161622 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '397ff834-d18b-49de-9519-de2564ebf3c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3da370>]}
[0m16:10:03.163572 [info ] [Thread-4  ]: 3 of 3 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 20.03s]
[0m16:10:03.165013 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m16:10:03.168259 [debug] [MainThread]: Using redshift connection "master"
[0m16:10:03.169084 [debug] [MainThread]: On master: BEGIN
[0m16:10:03.169634 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:10:03.170395 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:10:03.170947 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:10:04.259472 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m16:10:04.259836 [debug] [MainThread]: On master: COMMIT
[0m16:10:04.260149 [debug] [MainThread]: Using redshift connection "master"
[0m16:10:04.260382 [debug] [MainThread]: On master: COMMIT
[0m16:10:04.516594 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:10:04.518150 [debug] [MainThread]: On master: Close
[0m16:10:04.521646 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:10:04.522482 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m16:10:04.523247 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m16:10:04.523969 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m16:10:04.524911 [info ] [MainThread]: 
[0m16:10:04.525588 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 39.73 seconds (39.73s).
[0m16:10:04.528037 [debug] [MainThread]: Command end result
[0m16:10:04.546577 [info ] [MainThread]: 
[0m16:10:04.547223 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:10:04.547701 [info ] [MainThread]: 
[0m16:10:04.548185 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m16:10:04.550757 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 40.2906, "process_user_time": 2.285675, "process_kernel_time": 0.238378, "process_mem_max_rss": "135036928", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m16:10:04.551485 [debug] [MainThread]: Command `dbt run` succeeded at 16:10:04.551326 after 40.29 seconds
[0m16:10:04.551955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ac5580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a398d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3931c0>]}
[0m16:10:04.552447 [debug] [MainThread]: Flushing usage events
[0m16:34:05.938856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103246670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107557160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107563310>]}


============================== 16:34:05.941845 | 9be35c4e-68c4-4026-9810-ec481ea56cba ==============================
[0m16:34:05.941845 [info ] [MainThread]: Running with dbt=1.7.1
[0m16:34:05.942232 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:34:06.128264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9be35c4e-68c4-4026-9810-ec481ea56cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107557160>]}
[0m16:34:06.175456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9be35c4e-68c4-4026-9810-ec481ea56cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100c49d0>]}
[0m16:34:06.176061 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m16:34:06.186523 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m16:34:06.224859 [debug] [MainThread]: Partial parsing enabled: 5 files deleted, 5 files added, 0 files changed.
[0m16:34:06.225234 [debug] [MainThread]: Partial parsing: added file: dbt_remote://models/acuity_scheduling/stg_appointment_deleted_event.sql
[0m16:34:06.225445 [debug] [MainThread]: Partial parsing: added file: dbt_remote://models/acuity_scheduling/fact_apointment_schedule.sql
[0m16:34:06.225637 [debug] [MainThread]: Partial parsing: added file: dbt_remote://models/acuity_scheduling/stg_appointment_added_event.sql
[0m16:34:06.225820 [debug] [MainThread]: Partial parsing: added file: dbt_remote://models/acuity_scheduling/stg_appointment_edited_event.sql
[0m16:34:06.226059 [debug] [MainThread]: Partial parsing: added file: dbt_remote://models/acuity_scheduling/schema.yml
[0m16:34:06.226277 [debug] [MainThread]: Partial parsing: deleted file: dbt_remote://models/starlink/satellite/stg_appointment_added_event.sql
[0m16:34:06.226438 [debug] [MainThread]: Partial parsing: deleted file: dbt_remote://models/starlink/satellite/stg_appointment_deleted_event.sql
[0m16:34:06.226597 [debug] [MainThread]: Partial parsing: deleted file: dbt_remote://models/starlink/satellite/stg_appointment_edited_event.sql
[0m16:34:06.226756 [debug] [MainThread]: Partial parsing: deleted file: dbt_remote://models/starlink/satellite/fact_apointment_schedule.sql
[0m16:34:06.456266 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m16:34:06.460333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9be35c4e-68c4-4026-9810-ec481ea56cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110eea0d0>]}
[0m16:34:06.468864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9be35c4e-68c4-4026-9810-ec481ea56cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11095e970>]}
[0m16:34:06.469213 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m16:34:06.469425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9be35c4e-68c4-4026-9810-ec481ea56cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11095e880>]}
[0m16:34:06.470415 [info ] [MainThread]: 
[0m16:34:06.471046 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m16:34:06.472028 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m16:34:06.482081 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m16:34:06.482556 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m16:34:06.482755 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m16:34:06.484386 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m16:34:06.484651 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:34:06.484876 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m16:34:06.487006 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:34:06.487271 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:34:06.487484 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:34:06.487745 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:34:06.488871 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:34:07.796482 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:07.798325 [debug] [ThreadPool]: On list_prod: Close
[0m16:34:07.798673 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:07.799566 [debug] [ThreadPool]: On list_prod: Close
[0m16:34:07.801269 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m16:34:07.806934 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:34:07.807488 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m16:34:07.807699 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m16:34:07.810567 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:34:07.810786 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:34:07.810979 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m16:34:07.811271 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:34:07.811465 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:34:07.811662 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:34:07.811899 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:34:07.812579 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:34:08.915303 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:08.917383 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:34:08.918716 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m16:34:09.193471 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:09.199442 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m16:34:09.398550 [debug] [ThreadPool]: SQL status: SUCCESS in 2.0 seconds
[0m16:34:09.400318 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:34:09.401464 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m16:34:09.465166 [debug] [ThreadPool]: On list_prod_public: Close
[0m16:34:09.678398 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:09.683805 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m16:34:09.950481 [debug] [ThreadPool]: On list_prod_staging: Close
[0m16:34:09.972233 [debug] [MainThread]: Using redshift connection "master"
[0m16:34:09.972916 [debug] [MainThread]: On master: BEGIN
[0m16:34:09.973340 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:34:09.974002 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:34:09.974442 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:34:11.083573 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:11.085597 [debug] [MainThread]: Using redshift connection "master"
[0m16:34:11.087012 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m16:34:11.389598 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:11.395086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9be35c4e-68c4-4026-9810-ec481ea56cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11095ecd0>]}
[0m16:34:11.396195 [debug] [MainThread]: On master: ROLLBACK
[0m16:34:11.668784 [debug] [MainThread]: Using redshift connection "master"
[0m16:34:11.670320 [debug] [MainThread]: On master: BEGIN
[0m16:34:11.800785 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:11.802516 [debug] [MainThread]: On master: COMMIT
[0m16:34:11.804136 [debug] [MainThread]: Using redshift connection "master"
[0m16:34:11.805350 [debug] [MainThread]: On master: COMMIT
[0m16:34:12.065603 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:12.067429 [debug] [MainThread]: On master: Close
[0m16:34:12.071194 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m16:34:12.072134 [info ] [MainThread]: 
[0m16:34:12.078387 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m16:34:12.079266 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m16:34:12.080219 [info ] [Thread-1  ]: 1 of 3 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m16:34:12.081176 [info ] [Thread-2  ]: 2 of 3 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m16:34:12.082480 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_added_event)
[0m16:34:12.083963 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_edited_event)
[0m16:34:12.084770 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m16:34:12.085472 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m16:34:12.091992 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m16:34:12.102894 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m16:34:12.104190 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 16:34:12.092594 => 16:34:12.103871
[0m16:34:12.104813 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 16:34:12.085869 => 16:34:12.104492
[0m16:34:12.105313 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m16:34:12.105822 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m16:34:12.162275 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m16:34:12.163834 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m16:34:12.166106 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:34:12.167205 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:34:12.167426 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:34:12.167643 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:34:12.167865 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m16:34:12.168071 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m16:34:12.168376 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:34:12.168629 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:34:12.168849 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:34:12.169056 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:34:13.260699 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:13.261270 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:34:13.261755 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m16:34:13.732995 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:34:13.733848 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:34:13.734589 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m16:34:15.583107 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:34:15.589698 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:34:15.591448 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:34:15.592594 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:34:16.075939 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:34:17.088313 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:17.089207 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:34:17.089763 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:34:17.218468 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:17.230735 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m16:34:17.237079 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:34:17.237631 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m16:34:17.496509 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:17.499734 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:34:17.500685 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:34:17.502010 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:34:18.370241 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:18.372988 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:34:18.374417 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:34:18.504865 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:18.512931 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:34:18.520348 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:34:18.522017 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:34:18.522706 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:34:18.523309 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m16:34:19.491978 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:19.492855 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:34:19.493417 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:34:19.622839 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:19.634155 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m16:34:19.635745 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:34:19.636243 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m16:34:19.723980 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:19.760280 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:34:19.761030 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:34:19.761506 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:34:19.893762 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:19.898036 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:34:19.899455 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:34:19.900300 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:34:21.277693 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:34:21.279658 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:21.282430 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:34:21.283282 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:34:21.414484 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:21.422616 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:34:21.426249 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:34:21.427154 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:34:21.427849 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m16:34:21.686538 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:21.696634 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m16:34:21.698655 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:34:21.699333 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m16:34:21.955779 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:21.957195 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:34:21.957744 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:34:21.958174 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:34:22.094414 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:22.096589 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:34:22.097920 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:34:22.228060 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:22.232005 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 16:34:12.106140 => 16:34:22.231516
[0m16:34:22.232868 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m16:34:22.331669 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:22.341271 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:34:22.342298 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:34:22.342929 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:34:22.489238 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m16:34:22.493572 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9be35c4e-68c4-4026-9810-ec481ea56cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11109e5e0>]}
[0m16:34:22.495186 [info ] [Thread-2  ]: 2 of 3 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 10.41s]
[0m16:34:22.496859 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m16:34:23.201918 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:23.205482 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:34:23.206553 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:34:23.466294 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:23.479450 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m16:34:23.481226 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:34:23.481793 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m16:34:23.742668 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:23.746286 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:34:23.747245 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:34:23.747895 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:34:23.883275 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:23.885190 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:34:23.886460 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:34:24.017712 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:24.022764 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 16:34:12.125814 => 16:34:24.021906
[0m16:34:24.024216 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m16:34:24.284284 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m16:34:24.288768 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9be35c4e-68c4-4026-9810-ec481ea56cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111094fd0>]}
[0m16:34:24.290443 [info ] [Thread-1  ]: 1 of 3 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 12.21s]
[0m16:34:24.292082 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m16:34:24.293805 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m16:34:24.295074 [info ] [Thread-4  ]: 3 of 3 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m16:34:24.296477 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m16:34:24.297128 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m16:34:24.332619 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:34:24.333130 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:34:24.333488 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m16:34:24.333985 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:34:24.334367 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:34:25.441832 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:25.444095 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:34:25.446266 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m16:34:25.817326 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:25.826399 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m16:34:25.828102 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 16:34:24.297494 => 16:34:25.827679
[0m16:34:25.828767 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m16:34:25.837675 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m16:34:25.841269 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:34:25.841885 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited)

select "appointment_id",
  "first_name",
  "last_name",
  "email",
  "appointment_date",
  "appointment_time_start",
  "appointment_time_end",
  "appointment_type",
  "calendar_name",
  "appointment_created_at",
  "ingested_at_timestamp" from find_dublicates
where rnk = 1
  );
[0m16:34:30.532801 [debug] [Thread-4  ]: SQL status: SUCCESS in 5.0 seconds
[0m16:34:30.535742 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:34:30.536421 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:34:30.536925 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:34:31.598666 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:31.601378 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:34:31.602720 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:34:31.733013 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:31.743139 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m16:34:31.745144 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:34:31.745845 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m16:34:32.006150 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:32.009549 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:34:32.010605 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:34:32.011266 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:34:32.745501 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:32.748223 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:34:32.749737 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:34:32.880037 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:32.888986 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:34:32.889934 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m16:34:33.910966 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:33.919946 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:34:33.921026 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:34:33.922053 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:34:34.875362 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:34.878891 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:34:34.880291 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:34:35.140002 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:35.146011 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m16:34:35.147975 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:34:35.148629 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m16:34:35.405601 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:35.407231 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:34:35.407879 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:34:35.408392 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:34:35.542208 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:35.543903 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:34:35.544569 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:34:35.674369 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:35.679643 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 16:34:25.829140 => 16:34:35.678752
[0m16:34:35.681103 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m16:34:35.938333 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m16:34:35.943743 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9be35c4e-68c4-4026-9810-ec481ea56cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11151eee0>]}
[0m16:34:35.946190 [info ] [Thread-4  ]: 3 of 3 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 11.65s]
[0m16:34:35.948168 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m16:34:35.950792 [debug] [MainThread]: Using redshift connection "master"
[0m16:34:35.951405 [debug] [MainThread]: On master: BEGIN
[0m16:34:35.951922 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:34:35.952680 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:34:35.953227 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:34:37.045198 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m16:34:37.045578 [debug] [MainThread]: On master: COMMIT
[0m16:34:37.045884 [debug] [MainThread]: Using redshift connection "master"
[0m16:34:37.046118 [debug] [MainThread]: On master: COMMIT
[0m16:34:37.304258 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:34:37.305217 [debug] [MainThread]: On master: Close
[0m16:34:37.307028 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:34:37.307567 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m16:34:37.308048 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m16:34:37.308503 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m16:34:37.309075 [info ] [MainThread]: 
[0m16:34:37.309652 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 30.84 seconds (30.84s).
[0m16:34:37.311107 [debug] [MainThread]: Command end result
[0m16:34:37.329053 [info ] [MainThread]: 
[0m16:34:37.329598 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:34:37.329996 [info ] [MainThread]: 
[0m16:34:37.330403 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m16:34:37.332548 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 31.427359, "process_user_time": 2.589879, "process_kernel_time": 0.283287, "process_mem_max_rss": "134053888", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m16:34:37.333239 [debug] [MainThread]: Command `dbt run` succeeded at 16:34:37.333078 after 31.43 seconds
[0m16:34:37.333692 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103246670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100c49d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e9b550>]}
[0m16:34:37.334150 [debug] [MainThread]: Flushing usage events
[0m16:39:07.970578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cc68e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dbae20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f1f700>]}


============================== 16:39:07.973507 | b376acab-ffa3-4cb8-94e2-669804461ee9 ==============================
[0m16:39:07.973507 [info ] [MainThread]: Running with dbt=1.7.1
[0m16:39:07.973882 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'send_anonymous_usage_stats': 'True'}
[0m16:39:08.158404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b376acab-ffa3-4cb8-94e2-669804461ee9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dbae20>]}
[0m16:39:08.206132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b376acab-ffa3-4cb8-94e2-669804461ee9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11013b7c0>]}
[0m16:39:08.206757 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m16:39:08.215368 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m16:39:08.251068 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:39:08.251519 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/acuity_scheduling/fact_apointment_schedule.sql
[0m16:39:08.437678 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_remote.fact_apointment_schedule' (models/acuity_scheduling/fact_apointment_schedule.sql) depends on a node named 'stg_appointment_cancelled_event' which was not found
[0m16:39:08.438984 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.5020452, "process_user_time": 1.510618, "process_kernel_time": 0.144012, "process_mem_max_rss": "116654080", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m16:39:08.439351 [debug] [MainThread]: Command `dbt run` failed at 16:39:08.439270 after 0.50 seconds
[0m16:39:08.439583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cc68e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c22160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c556d0>]}
[0m16:39:08.439824 [debug] [MainThread]: Flushing usage events
[0m16:39:26.649652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104706490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10680f730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10681f1f0>]}


============================== 16:39:26.652251 | f5218a06-f18b-428f-b365-6bb4bdb37298 ==============================
[0m16:39:26.652251 [info ] [MainThread]: Running with dbt=1.7.1
[0m16:39:26.652601 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:39:26.827853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f5218a06-f18b-428f-b365-6bb4bdb37298', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106839c70>]}
[0m16:39:26.875634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f5218a06-f18b-428f-b365-6bb4bdb37298', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10709e130>]}
[0m16:39:26.876243 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m16:39:26.886771 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m16:39:26.924231 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:39:26.924673 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/acuity_scheduling/fact_apointment_schedule.sql
[0m16:39:27.112833 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m16:39:27.116862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f5218a06-f18b-428f-b365-6bb4bdb37298', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c05f40>]}
[0m16:39:27.125104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f5218a06-f18b-428f-b365-6bb4bdb37298', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078ce7c0>]}
[0m16:39:27.125427 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m16:39:27.125639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f5218a06-f18b-428f-b365-6bb4bdb37298', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078ce790>]}
[0m16:39:27.126599 [info ] [MainThread]: 
[0m16:39:27.127078 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m16:39:27.127774 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m16:39:27.138062 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m16:39:27.138832 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m16:39:27.139060 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m16:39:27.140975 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m16:39:27.141227 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:39:27.141410 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m16:39:27.143318 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:39:27.143519 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:39:27.143703 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:39:27.143919 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:39:27.144873 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:39:28.454414 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:28.461393 [debug] [ThreadPool]: On list_prod: Close
[0m16:39:28.462282 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:28.464675 [debug] [ThreadPool]: On list_prod: Close
[0m16:39:28.469126 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m16:39:28.476496 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m16:39:28.486982 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:39:28.482077 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:39:28.487651 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m16:39:28.488020 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m16:39:28.488373 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:39:28.488719 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:39:28.489337 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:39:28.489820 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:39:28.490208 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:39:28.490576 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:39:29.612076 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:29.614007 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:29.615223 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:39:29.616236 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:39:29.617258 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m16:39:29.618195 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m16:39:29.893987 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:29.895959 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:29.899730 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m16:39:29.902326 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m16:39:30.166521 [debug] [ThreadPool]: On list_prod_staging: Close
[0m16:39:30.167365 [debug] [ThreadPool]: On list_prod_public: Close
[0m16:39:30.185972 [debug] [MainThread]: Using redshift connection "master"
[0m16:39:30.186485 [debug] [MainThread]: On master: BEGIN
[0m16:39:30.186848 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:39:30.187393 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:39:30.187777 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:39:31.280075 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:31.280462 [debug] [MainThread]: Using redshift connection "master"
[0m16:39:31.280783 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m16:39:31.577909 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:31.583464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f5218a06-f18b-428f-b365-6bb4bdb37298', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078ce550>]}
[0m16:39:31.585195 [debug] [MainThread]: On master: ROLLBACK
[0m16:39:31.855417 [debug] [MainThread]: Using redshift connection "master"
[0m16:39:31.856913 [debug] [MainThread]: On master: BEGIN
[0m16:39:31.985839 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:31.987411 [debug] [MainThread]: On master: COMMIT
[0m16:39:31.989335 [debug] [MainThread]: Using redshift connection "master"
[0m16:39:31.990524 [debug] [MainThread]: On master: COMMIT
[0m16:39:32.248119 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:32.249993 [debug] [MainThread]: On master: Close
[0m16:39:32.253866 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m16:39:32.254825 [info ] [MainThread]: 
[0m16:39:32.260598 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m16:39:32.261891 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m16:39:32.263412 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m16:39:32.262791 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m16:39:32.264508 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m16:39:32.265467 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m16:39:32.267014 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_added_event)
[0m16:39:32.268207 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_deleted_event)
[0m16:39:32.269483 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m16:39:32.270187 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m16:39:32.270795 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m16:39:32.271384 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m16:39:32.277270 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m16:39:32.282330 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m16:39:32.287021 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m16:39:32.288414 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 16:39:32.271733 => 16:39:32.288076
[0m16:39:32.288954 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m16:39:32.289600 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 16:39:32.282708 => 16:39:32.289276
[0m16:39:32.290120 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 16:39:32.277712 => 16:39:32.289871
[0m16:39:32.310154 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m16:39:32.328871 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m16:39:32.334530 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m16:39:32.337851 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m16:39:32.341004 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m16:39:32.342540 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:39:32.343727 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:39:32.343977 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:39:32.344241 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:39:32.345315 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:39:32.345528 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m16:39:32.345753 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m16:39:32.345978 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:39:32.346281 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:39:32.346558 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:39:32.346773 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m16:39:32.346998 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:39:32.347213 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:39:32.347463 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:39:32.348675 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:39:33.461184 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:33.463407 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:33.464497 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:33.465499 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:39:33.466316 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:39:33.467134 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:39:33.467869 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m16:39:33.468659 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m16:39:33.469883 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m16:39:35.767011 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:39:35.773097 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:39:35.774852 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:39:35.776005 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:39:35.811902 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:39:36.006470 [debug] [Thread-3  ]: SQL status: SUCCESS in 3.0 seconds
[0m16:39:36.726234 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:36.729089 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:39:36.730492 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:39:36.860752 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:36.877258 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m16:39:36.883510 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:39:36.883956 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m16:39:37.142468 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:37.146829 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:39:37.148449 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:39:37.149780 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:39:37.995074 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:37.997345 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:39:37.998706 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:39:38.127887 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:38.136180 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:39:38.143584 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:39:38.146041 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:39:38.146699 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:39:38.147354 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m16:39:39.068277 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:39.070297 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:39:39.071603 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:39:39.200201 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:39.211680 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m16:39:39.213610 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:39:39.214275 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m16:39:39.312794 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:39.351147 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:39:39.351805 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:39:39.352249 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:39:39.481798 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:39.485877 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:39:39.487409 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:39:39.488018 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:39:40.862658 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:39:40.864730 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:40.868088 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:39:40.869584 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:39:40.998067 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:41.006188 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:39:41.013418 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:39:41.014530 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:39:41.015245 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m16:39:41.015897 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:39:41.907420 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:41.909570 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:39:41.910887 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:39:42.041621 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:42.053321 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m16:39:42.055267 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:39:42.055911 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m16:39:42.143921 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:42.153546 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:39:42.155179 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:39:42.156107 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:39:42.316240 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:42.320727 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:39:42.321661 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:39:42.322442 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:39:43.893528 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:39:43.895648 [debug] [Thread-3  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:39:43.898058 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:39:43.898925 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:39:44.029396 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:44.037492 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:39:44.041793 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:39:44.042424 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:39:44.043063 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m16:39:44.301329 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:44.312309 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m16:39:44.314350 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:39:44.314994 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m16:39:44.571620 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:44.575372 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:39:44.576550 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:39:44.577476 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:39:44.713373 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:44.715421 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:39:44.716778 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:39:44.846032 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:44.850781 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 16:39:32.290395 => 16:39:44.849875
[0m16:39:44.852146 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:39:44.852915 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m16:39:44.853572 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:39:44.943740 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:44.953053 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:39:44.953730 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:39:44.954157 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:39:45.109131 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m16:39:45.111094 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:45.119820 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f5218a06-f18b-428f-b365-6bb4bdb37298', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e33880>]}
[0m16:39:45.122774 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m16:39:45.125526 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:39:45.123857 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 12.85s]
[0m16:39:45.126358 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m16:39:45.127143 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m16:39:45.383597 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:45.387918 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:39:45.389283 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:39:45.390113 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:39:45.816327 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:45.817952 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:45.819824 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:39:45.821939 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:39:45.950580 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:45.954178 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 16:39:32.338041 => 16:39:45.953473
[0m16:39:45.955311 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:39:45.956052 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m16:39:45.956698 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:39:46.213639 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m16:39:46.214029 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:46.216463 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m16:39:46.217253 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:39:46.217774 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f5218a06-f18b-428f-b365-6bb4bdb37298', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107de0bb0>]}
[0m16:39:46.218039 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m16:39:46.218451 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 13.95s]
[0m16:39:46.219047 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m16:39:46.477333 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:46.482684 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:39:46.484487 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:39:46.486015 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:39:46.622020 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:46.624417 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:39:46.625773 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:39:46.755275 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:46.759657 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 16:39:32.334766 => 16:39:46.758793
[0m16:39:46.761090 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m16:39:47.020326 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m16:39:47.024027 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f5218a06-f18b-428f-b365-6bb4bdb37298', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e33a00>]}
[0m16:39:47.025720 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 14.75s]
[0m16:39:47.027189 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m16:39:47.028996 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m16:39:47.029922 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m16:39:47.031417 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m16:39:47.032058 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m16:39:47.067909 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:39:47.068418 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:39:47.068794 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m16:39:47.069294 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:39:47.069685 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:39:48.180829 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:39:48.182977 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:39:48.184855 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m16:39:48.557046 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:39:48.568450 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m16:39:48.569966 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 16:39:47.032431 => 16:39:48.569552
[0m16:39:48.570633 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m16:39:48.581224 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m16:39:48.585791 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:39:48.586373 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        cancelled.cancelled_flag

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m16:40:03.212021 [debug] [Thread-4  ]: SQL status: SUCCESS in 15.0 seconds
[0m16:40:03.213638 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:40:03.214168 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:40:03.214558 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:40:04.297955 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:40:04.298732 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:40:04.299179 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:40:04.429988 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:40:04.435991 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m16:40:04.437778 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:40:04.438424 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m16:40:04.695984 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:40:04.699621 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:40:04.700602 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:40:04.701502 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:40:05.717275 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:40:05.718320 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:40:05.718968 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:40:05.847626 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:40:05.852694 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:40:05.853311 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m16:40:06.874350 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:40:06.882612 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:40:06.883742 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:40:06.884388 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:40:07.821079 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:40:07.824781 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:40:07.825918 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:40:08.085976 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:40:08.090163 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m16:40:08.091522 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:40:08.091994 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m16:40:08.349090 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:40:08.353331 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:40:08.354963 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:40:08.356283 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:40:08.492716 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:40:08.494940 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:40:08.496214 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:40:08.625912 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:40:08.630124 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 16:39:48.571019 => 16:40:08.629266
[0m16:40:08.631091 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m16:40:08.886979 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m16:40:08.891011 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f5218a06-f18b-428f-b365-6bb4bdb37298', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080a3af0>]}
[0m16:40:08.892887 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 21.86s]
[0m16:40:08.894222 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m16:40:08.897388 [debug] [MainThread]: Using redshift connection "master"
[0m16:40:08.898213 [debug] [MainThread]: On master: BEGIN
[0m16:40:08.898761 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:40:08.899545 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:40:08.900104 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:40:09.992526 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m16:40:09.992933 [debug] [MainThread]: On master: COMMIT
[0m16:40:09.993284 [debug] [MainThread]: Using redshift connection "master"
[0m16:40:09.993547 [debug] [MainThread]: On master: COMMIT
[0m16:40:10.249991 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:40:10.250696 [debug] [MainThread]: On master: Close
[0m16:40:10.251986 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:40:10.252460 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m16:40:10.252862 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m16:40:10.253216 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m16:40:10.253532 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m16:40:10.253937 [info ] [MainThread]: 
[0m16:40:10.254346 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 43.13 seconds (43.13s).
[0m16:40:10.255556 [debug] [MainThread]: Command end result
[0m16:40:10.270156 [info ] [MainThread]: 
[0m16:40:10.270672 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:40:10.271131 [info ] [MainThread]: 
[0m16:40:10.271639 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m16:40:10.273720 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 43.674248, "process_user_time": 2.671893, "process_kernel_time": 0.265923, "process_mem_max_rss": "134348800", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m16:40:10.274450 [debug] [MainThread]: Command `dbt run` succeeded at 16:40:10.274307 after 43.68 seconds
[0m16:40:10.274884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104706490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e310d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10709e130>]}
[0m16:40:10.275285 [debug] [MainThread]: Flushing usage events
[0m16:43:10.531569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cb6580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dc7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dd3d00>]}


============================== 16:43:10.533843 | 04f7efa2-0ee7-4014-8015-aadaf2757160 ==============================
[0m16:43:10.533843 [info ] [MainThread]: Running with dbt=1.7.1
[0m16:43:10.534186 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:43:10.690001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '04f7efa2-0ee7-4014-8015-aadaf2757160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106db1250>]}
[0m16:43:10.737484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '04f7efa2-0ee7-4014-8015-aadaf2757160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077fff40>]}
[0m16:43:10.737920 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m16:43:10.747211 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m16:43:10.775871 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:43:10.776329 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/acuity_scheduling/schema.yml
[0m16:43:10.962442 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m16:43:10.966205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '04f7efa2-0ee7-4014-8015-aadaf2757160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081bd0d0>]}
[0m16:43:10.973044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '04f7efa2-0ee7-4014-8015-aadaf2757160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e83970>]}
[0m16:43:10.973345 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m16:43:10.973550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04f7efa2-0ee7-4014-8015-aadaf2757160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e83940>]}
[0m16:43:10.974379 [info ] [MainThread]: 
[0m16:43:10.974860 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m16:43:10.975546 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m16:43:10.985926 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m16:43:10.986497 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m16:43:10.986687 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m16:43:10.988362 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m16:43:10.988615 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:43:10.988800 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m16:43:10.990682 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:43:10.990884 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:43:10.991069 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:43:10.991284 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:43:10.992279 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:43:12.256917 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:12.259810 [debug] [ThreadPool]: On list_prod: Close
[0m16:43:12.260425 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:12.262114 [debug] [ThreadPool]: On list_prod: Close
[0m16:43:12.265389 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m16:43:12.272770 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m16:43:12.276869 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:43:12.281907 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:43:12.282309 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m16:43:12.282653 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m16:43:12.282964 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:43:12.283262 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:43:12.283756 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:43:12.284143 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:43:12.284468 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:43:12.284821 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:43:13.395037 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:13.396402 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:13.397297 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:43:13.397973 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:43:13.399050 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m16:43:13.400177 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m16:43:13.675560 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:13.680136 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m16:43:13.680905 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:13.683188 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m16:43:13.944035 [debug] [ThreadPool]: On list_prod_public: Close
[0m16:43:13.948659 [debug] [ThreadPool]: On list_prod_staging: Close
[0m16:43:13.974076 [debug] [MainThread]: Using redshift connection "master"
[0m16:43:13.974662 [debug] [MainThread]: On master: BEGIN
[0m16:43:13.975264 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:43:13.975932 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:43:13.976381 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:43:15.069586 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:15.071494 [debug] [MainThread]: Using redshift connection "master"
[0m16:43:15.072854 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m16:43:15.376745 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:15.381055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04f7efa2-0ee7-4014-8015-aadaf2757160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e83700>]}
[0m16:43:15.382222 [debug] [MainThread]: On master: ROLLBACK
[0m16:43:15.653583 [debug] [MainThread]: Using redshift connection "master"
[0m16:43:15.655440 [debug] [MainThread]: On master: BEGIN
[0m16:43:15.784641 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:15.786638 [debug] [MainThread]: On master: COMMIT
[0m16:43:15.788232 [debug] [MainThread]: Using redshift connection "master"
[0m16:43:15.789343 [debug] [MainThread]: On master: COMMIT
[0m16:43:16.046093 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:16.047999 [debug] [MainThread]: On master: Close
[0m16:43:16.051259 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m16:43:16.052036 [info ] [MainThread]: 
[0m16:43:16.056416 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m16:43:16.057230 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m16:43:16.058395 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m16:43:16.059231 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m16:43:16.060344 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m16:43:16.061731 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m16:43:16.063421 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_added_event)
[0m16:43:16.064670 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_deleted_event)
[0m16:43:16.065916 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m16:43:16.066510 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m16:43:16.067044 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m16:43:16.067538 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m16:43:16.073207 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m16:43:16.078231 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m16:43:16.082768 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m16:43:16.084057 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 16:43:16.067842 => 16:43:16.083674
[0m16:43:16.084623 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 16:43:16.078580 => 16:43:16.084359
[0m16:43:16.085109 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 16:43:16.073589 => 16:43:16.084865
[0m16:43:16.085542 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m16:43:16.085978 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m16:43:16.086385 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m16:43:16.161234 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m16:43:16.161774 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m16:43:16.162557 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m16:43:16.163960 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:43:16.164190 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:43:16.164397 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m16:43:16.164690 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:43:16.164908 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:43:16.166350 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:43:16.166572 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:43:16.166769 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m16:43:16.167019 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:43:16.167229 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:43:16.168826 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:43:16.169040 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:43:16.169231 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m16:43:16.169475 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:43:16.169680 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:43:17.280367 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:17.282253 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:17.283298 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:17.284354 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:43:17.285267 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:43:17.286536 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:43:17.287477 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m16:43:17.288405 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m16:43:17.289287 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m16:43:19.498645 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:43:19.505544 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:43:19.506640 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:43:19.507310 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:43:19.774498 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:43:19.898808 [debug] [Thread-3  ]: SQL status: SUCCESS in 3.0 seconds
[0m16:43:20.512787 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:20.515135 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:43:20.516453 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:43:20.646566 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:20.669266 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m16:43:20.675473 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:43:20.675986 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m16:43:20.938707 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:20.942174 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:43:20.943047 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:43:20.943655 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:43:21.751213 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:21.753554 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:43:21.754833 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:43:21.884576 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:21.893180 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:43:21.900387 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:43:21.903605 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:43:21.904266 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:43:21.904926 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m16:43:23.185384 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:23.187950 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:43:23.189177 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:43:23.335633 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:23.344908 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m16:43:23.346855 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:43:23.347584 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m16:43:23.439448 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:43:23.477178 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:43:23.477810 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:43:23.478351 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:43:23.608961 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:23.612806 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:43:23.614345 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:43:23.615587 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:43:25.029415 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:43:25.031277 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:25.033640 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:43:25.034511 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:43:25.164087 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:25.170588 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:43:25.173775 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:43:25.174514 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:43:25.175165 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m16:43:25.175798 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:43:26.062684 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:26.064669 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:43:26.065644 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:43:26.194631 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:26.203337 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m16:43:26.205125 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:43:26.205792 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m16:43:26.303032 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:26.312049 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:43:26.313044 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:43:26.313781 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:43:26.463364 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:26.467869 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:43:26.469552 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:43:26.470829 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:43:27.804620 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:27.806844 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:27.809398 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:43:27.810197 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:43:27.940933 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:27.949266 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:43:27.952157 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:43:27.952776 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:43:27.953428 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m16:43:28.210571 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:28.224594 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m16:43:28.227454 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:43:28.228089 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m16:43:28.486009 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:28.490964 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:43:28.492872 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:43:28.493981 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:43:28.630610 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:28.632570 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:43:28.633537 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:43:28.762460 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:28.766406 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 16:43:16.118114 => 16:43:28.765845
[0m16:43:28.767535 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:43:28.768752 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m16:43:28.769918 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:43:28.846086 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:28.854500 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:43:28.855507 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:43:28.856226 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:43:29.028271 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m16:43:29.030047 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:29.038921 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04f7efa2-0ee7-4014-8015-aadaf2757160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085bd9d0>]}
[0m16:43:29.041553 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m16:43:29.043502 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:43:29.045119 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m16:43:29.044501 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 12.97s]
[0m16:43:29.046567 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m16:43:29.304937 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:29.310437 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:43:29.312422 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:43:29.313802 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:43:29.699585 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:29.701301 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:29.704547 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:43:29.705613 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:43:29.847457 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:29.851617 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 16:43:16.086647 => 16:43:29.850769
[0m16:43:29.852847 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:43:29.853636 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m16:43:29.854469 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:43:30.153122 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:30.155977 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m16:43:30.156325 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m16:43:30.157191 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:43:30.157567 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m16:43:30.158254 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04f7efa2-0ee7-4014-8015-aadaf2757160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e81910>]}
[0m16:43:30.158727 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 14.10s]
[0m16:43:30.159162 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m16:43:30.416222 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:30.420940 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:43:30.422037 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:43:30.422710 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:43:30.557994 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:30.560412 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:43:30.561690 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:43:30.693667 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:30.698538 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 16:43:16.099473 => 16:43:30.697978
[0m16:43:30.699295 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m16:43:30.956685 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m16:43:30.961390 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04f7efa2-0ee7-4014-8015-aadaf2757160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108255850>]}
[0m16:43:30.963050 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 14.90s]
[0m16:43:30.964193 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m16:43:30.966085 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m16:43:30.967513 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m16:43:30.968993 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m16:43:30.969654 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m16:43:31.003477 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:43:31.003922 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:43:31.004205 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m16:43:31.004597 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:43:31.004874 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:43:32.124963 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:32.127104 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:43:32.128543 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m16:43:32.497294 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:32.510815 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m16:43:32.512295 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 16:43:30.970024 => 16:43:32.511883
[0m16:43:32.512988 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m16:43:32.520952 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m16:43:32.525852 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:43:32.526496 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        cancelled.cancelled_flag

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m16:43:33.650826 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:33.656214 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:43:33.657280 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:43:33.658052 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:43:34.630335 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:34.631268 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:43:34.631904 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:43:34.761924 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:34.768079 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m16:43:34.769417 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:43:34.769840 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m16:43:35.030920 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:35.035053 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:43:35.036202 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:43:35.037295 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:43:36.005439 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:36.007602 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:43:36.008578 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:43:36.140215 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:36.152100 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:43:36.153065 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m16:43:37.181133 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:37.190789 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:43:37.191621 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:43:37.192155 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:43:38.096133 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:38.098890 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:43:38.100194 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:43:38.361351 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:38.374130 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m16:43:38.376598 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:43:38.377322 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m16:43:38.636600 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:38.641288 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:43:38.642433 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:43:38.643040 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:43:38.778205 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:38.780122 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:43:38.781379 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:43:38.911184 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:38.915870 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 16:43:32.513369 => 16:43:38.915046
[0m16:43:38.917296 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m16:43:39.176478 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m16:43:39.180943 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04f7efa2-0ee7-4014-8015-aadaf2757160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085bbf70>]}
[0m16:43:39.182635 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 8.21s]
[0m16:43:39.184164 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m16:43:39.187291 [debug] [MainThread]: Using redshift connection "master"
[0m16:43:39.187912 [debug] [MainThread]: On master: BEGIN
[0m16:43:39.188415 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:43:39.189177 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:43:39.189711 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:43:40.275099 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m16:43:40.275462 [debug] [MainThread]: On master: COMMIT
[0m16:43:40.275775 [debug] [MainThread]: Using redshift connection "master"
[0m16:43:40.276003 [debug] [MainThread]: On master: COMMIT
[0m16:43:40.532853 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:43:40.534510 [debug] [MainThread]: On master: Close
[0m16:43:40.537811 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:43:40.538593 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m16:43:40.539178 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m16:43:40.539771 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m16:43:40.540340 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m16:43:40.541388 [info ] [MainThread]: 
[0m16:43:40.542187 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 29.57 seconds (29.57s).
[0m16:43:40.544135 [debug] [MainThread]: Command end result
[0m16:43:40.563883 [info ] [MainThread]: 
[0m16:43:40.564470 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:43:40.564872 [info ] [MainThread]: 
[0m16:43:40.565338 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m16:43:40.567777 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 30.068714, "process_user_time": 2.714205, "process_kernel_time": 0.250431, "process_mem_max_rss": "135757824", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m16:43:40.568574 [debug] [MainThread]: Command `dbt run` succeeded at 16:43:40.568402 after 30.07 seconds
[0m16:43:40.569056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cb6580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085a0f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077fff40>]}
[0m16:43:40.569533 [debug] [MainThread]: Flushing usage events
[0m16:46:32.297712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102720940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104923be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104948520>]}


============================== 16:46:32.300649 | c472aa4c-4fb7-4e93-81ec-0e1d0a298a7d ==============================
[0m16:46:32.300649 [info ] [MainThread]: Running with dbt=1.7.1
[0m16:46:32.301023 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:46:32.486802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c472aa4c-4fb7-4e93-81ec-0e1d0a298a7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104923be0>]}
[0m16:46:32.536292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c472aa4c-4fb7-4e93-81ec-0e1d0a298a7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c4b490>]}
[0m16:46:32.537647 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m16:46:32.546599 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m16:46:32.584967 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:46:32.585405 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:46:32.585968 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m16:46:32.589859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c472aa4c-4fb7-4e93-81ec-0e1d0a298a7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065210d0>]}
[0m16:46:32.628759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c472aa4c-4fb7-4e93-81ec-0e1d0a298a7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ca84c0>]}
[0m16:46:32.629095 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m16:46:32.629307 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c472aa4c-4fb7-4e93-81ec-0e1d0a298a7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cedbb0>]}
[0m16:46:32.630158 [info ] [MainThread]: 
[0m16:46:32.630647 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m16:46:32.631380 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m16:46:32.638315 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m16:46:32.642511 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m16:46:32.644141 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m16:46:32.644383 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m16:46:32.644573 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m16:46:32.644747 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:46:32.644912 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:46:32.646797 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:46:32.647045 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:46:32.647246 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:46:32.647429 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:46:33.945518 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:33.947297 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:33.950963 [debug] [ThreadPool]: On list_prod: Close
[0m16:46:33.953918 [debug] [ThreadPool]: On list_prod: Close
[0m16:46:33.958306 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m16:46:33.965926 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m16:46:33.972149 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:46:33.979228 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:46:33.979737 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m16:46:33.980175 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m16:46:33.980589 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:46:33.980989 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:46:33.981536 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:46:33.982079 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:46:33.982540 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:46:33.982948 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:46:35.084860 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:35.085529 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:46:35.086040 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:35.086501 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m16:46:35.086941 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:46:35.087487 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m16:46:35.361001 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:35.363026 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:35.367861 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m16:46:35.369908 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m16:46:35.635921 [debug] [ThreadPool]: On list_prod_public: Close
[0m16:46:35.637697 [debug] [ThreadPool]: On list_prod_staging: Close
[0m16:46:35.659061 [debug] [MainThread]: Using redshift connection "master"
[0m16:46:35.659652 [debug] [MainThread]: On master: BEGIN
[0m16:46:35.660078 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:46:35.660695 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:46:35.661150 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:46:36.771765 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:36.772155 [debug] [MainThread]: Using redshift connection "master"
[0m16:46:36.772476 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m16:46:37.074038 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:37.075862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c472aa4c-4fb7-4e93-81ec-0e1d0a298a7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cedbb0>]}
[0m16:46:37.076525 [debug] [MainThread]: On master: ROLLBACK
[0m16:46:37.348857 [debug] [MainThread]: Using redshift connection "master"
[0m16:46:37.350335 [debug] [MainThread]: On master: BEGIN
[0m16:46:37.481057 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:37.483128 [debug] [MainThread]: On master: COMMIT
[0m16:46:37.484759 [debug] [MainThread]: Using redshift connection "master"
[0m16:46:37.485435 [debug] [MainThread]: On master: COMMIT
[0m16:46:37.744358 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:37.746365 [debug] [MainThread]: On master: Close
[0m16:46:37.748983 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m16:46:37.750016 [info ] [MainThread]: 
[0m16:46:37.755157 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m16:46:37.756405 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m16:46:37.757103 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m16:46:37.757946 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m16:46:37.759309 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m16:46:37.760365 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m16:46:37.761688 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_added_event)
[0m16:46:37.762838 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_deleted_event)
[0m16:46:37.763941 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m16:46:37.764506 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m16:46:37.765010 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m16:46:37.765486 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m16:46:37.771238 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m16:46:37.776228 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m16:46:37.781072 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m16:46:37.782187 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 16:46:37.765805 => 16:46:37.781901
[0m16:46:37.782807 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 16:46:37.771632 => 16:46:37.782472
[0m16:46:37.783300 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m16:46:37.783752 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 16:46:37.776757 => 16:46:37.783537
[0m16:46:37.784140 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m16:46:37.803527 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m16:46:37.837173 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m16:46:37.837504 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m16:46:37.840451 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m16:46:37.841983 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:46:37.843184 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:46:37.843411 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:46:37.844461 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:46:37.844683 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:46:37.844895 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m16:46:37.845107 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:46:37.845308 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m16:46:37.845608 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:46:37.845815 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m16:46:37.846063 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:46:37.846283 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:46:37.846534 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:46:37.846751 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:46:37.847451 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:46:38.953771 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:38.954633 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:46:38.955385 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:38.956149 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m16:46:38.956885 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:46:38.957852 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m16:46:38.959187 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:38.959825 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:46:38.960494 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m16:46:41.298664 [debug] [Thread-3  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:46:41.305313 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:46:41.307120 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:46:41.307781 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:46:41.317369 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:46:41.419029 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:46:42.588663 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:42.590647 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:46:42.591677 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:46:42.722007 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:42.730878 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m16:46:42.735838 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:46:42.736248 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m16:46:42.997053 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:43.002124 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:46:43.003954 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:46:43.005339 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:46:43.721280 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:43.723626 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:46:43.724764 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:46:43.856210 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:43.864063 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:46:43.878392 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:46:43.881743 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:46:43.882648 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:46:43.883966 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m16:46:44.869479 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:44.871286 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:46:44.872273 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:46:45.002269 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:45.012826 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m16:46:45.016098 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:46:45.017021 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m16:46:45.104081 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:45.148370 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:46:45.149242 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:46:45.149836 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:46:45.283501 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:45.287792 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:46:45.289883 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:46:45.290487 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:46:46.684973 [debug] [Thread-3  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:46:46.686676 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:46.689579 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:46:46.690431 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:46:46.820408 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:46.828292 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:46:46.830277 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:46:46.831349 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:46:46.832393 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m16:46:46.833379 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:46:47.793335 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:47.796149 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:46:47.797703 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:46:47.928542 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:47.940589 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m16:46:47.943603 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:46:47.944794 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m16:46:48.049697 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:48.055230 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:46:48.056192 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:46:48.057194 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:46:48.205892 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:48.209951 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:46:48.211366 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:46:48.212140 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:46:50.177658 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:46:50.179636 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:46:50.182795 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:46:50.184196 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:46:50.352191 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:50.362884 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:46:50.370262 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:46:50.371273 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:46:50.372123 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m16:46:50.863889 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:50.876193 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m16:46:50.879566 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:46:50.880622 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m16:46:51.370428 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:51.374927 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:46:51.377302 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:46:51.378483 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:46:51.527318 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:51.530226 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:46:51.531294 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:46:51.702177 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:51.704439 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:51.712644 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:46:51.715623 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 16:46:37.837654 => 16:46:51.715015
[0m16:46:51.717058 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:46:51.718206 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:46:51.719029 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m16:46:51.719796 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:46:51.720518 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:46:52.015280 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:52.016747 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m16:46:52.027015 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m16:46:52.030765 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:46:52.031982 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m16:46:52.033901 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c472aa4c-4fb7-4e93-81ec-0e1d0a298a7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106693c10>]}
[0m16:46:52.035714 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 14.27s]
[0m16:46:52.037155 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m16:46:52.351725 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:52.356487 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:46:52.358457 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:46:52.359773 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:46:52.585682 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:52.587470 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:52.589136 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:46:52.591271 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:46:52.721313 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:52.725330 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 16:46:37.784377 => 16:46:52.724565
[0m16:46:52.727169 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:46:52.728330 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m16:46:52.729015 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:46:52.986550 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:52.987888 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m16:46:52.998487 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m16:46:53.001731 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:46:53.003107 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m16:46:53.005420 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c472aa4c-4fb7-4e93-81ec-0e1d0a298a7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064d2760>]}
[0m16:46:53.007169 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 15.24s]
[0m16:46:53.008538 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m16:46:53.263334 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:53.265466 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:46:53.266343 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:46:53.266964 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:46:53.402429 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:53.405101 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:46:53.406484 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:46:53.536934 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:53.541905 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 16:46:37.822302 => 16:46:53.541083
[0m16:46:53.543438 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m16:46:53.803585 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m16:46:53.808242 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c472aa4c-4fb7-4e93-81ec-0e1d0a298a7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106621490>]}
[0m16:46:53.810466 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 16.05s]
[0m16:46:53.812036 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m16:46:53.814409 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m16:46:53.815919 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m16:46:53.818645 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m16:46:53.819882 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m16:46:53.877823 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:46:53.878247 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:46:53.878545 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m16:46:53.878953 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:46:53.879257 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:46:54.971893 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:54.973250 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:46:54.974163 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m16:46:55.337890 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:55.347256 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m16:46:55.348651 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 16:46:53.820495 => 16:46:55.348266
[0m16:46:55.349322 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m16:46:55.361149 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m16:46:55.364241 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:46:55.364598 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        cancelled.cancelled_flag

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m16:46:56.574183 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:56.576849 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:46:56.578564 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:46:56.579676 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:46:57.515308 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:57.516526 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:46:57.517677 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:46:57.645961 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:57.654781 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m16:46:57.657211 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:46:57.657901 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m16:46:57.917544 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:57.921426 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:46:57.923027 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:46:57.924286 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:46:58.687028 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:58.688581 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:46:58.689365 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:46:58.818306 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:46:58.828802 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:46:58.830356 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m16:46:59.852243 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:46:59.861959 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:46:59.863796 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:46:59.865123 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:47:00.795409 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:47:00.796769 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:47:00.797400 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:47:01.054790 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:47:01.066379 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m16:47:01.068483 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:47:01.069907 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m16:47:01.325817 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:47:01.329445 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:47:01.331216 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:47:01.332612 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:47:01.468320 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:47:01.469507 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:47:01.470149 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:47:01.598382 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:47:01.600435 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 16:46:55.349695 => 16:47:01.600049
[0m16:47:01.601146 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m16:47:01.858545 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m16:47:01.861978 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c472aa4c-4fb7-4e93-81ec-0e1d0a298a7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11116fdf0>]}
[0m16:47:01.864072 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 8.04s]
[0m16:47:01.865951 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m16:47:01.869630 [debug] [MainThread]: Using redshift connection "master"
[0m16:47:01.870499 [debug] [MainThread]: On master: BEGIN
[0m16:47:01.871116 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:47:01.872215 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:47:01.872932 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:47:02.985312 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m16:47:02.986612 [debug] [MainThread]: On master: COMMIT
[0m16:47:02.987482 [debug] [MainThread]: Using redshift connection "master"
[0m16:47:02.988035 [debug] [MainThread]: On master: COMMIT
[0m16:47:03.245607 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:47:03.246412 [debug] [MainThread]: On master: Close
[0m16:47:03.247914 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:47:03.248439 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m16:47:03.248911 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m16:47:03.249359 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m16:47:03.249809 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m16:47:03.250361 [info ] [MainThread]: 
[0m16:47:03.250936 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 30.62 seconds (30.62s).
[0m16:47:03.252590 [debug] [MainThread]: Command end result
[0m16:47:03.268461 [info ] [MainThread]: 
[0m16:47:03.268959 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:47:03.269361 [info ] [MainThread]: 
[0m16:47:03.269763 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m16:47:03.271945 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 30.996305, "process_user_time": 2.561484, "process_kernel_time": 0.30892, "process_mem_max_rss": "129417216", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m16:47:03.272614 [debug] [MainThread]: Command `dbt run` succeeded at 16:47:03.272476 after 31.00 seconds
[0m16:47:03.273022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102720940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ca84c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c4b490>]}
[0m16:47:03.273441 [debug] [MainThread]: Flushing usage events
[0m16:47:51.436031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104282580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fce610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fdfd00>]}


============================== 16:47:51.438342 | 5dfdfce6-d88b-4e32-b1bd-4b0e6716a35d ==============================
[0m16:47:51.438342 [info ] [MainThread]: Running with dbt=1.7.1
[0m16:47:51.438681 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'send_anonymous_usage_stats': 'True'}
[0m16:47:51.597209 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5dfdfce6-d88b-4e32-b1bd-4b0e6716a35d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fbd250>]}
[0m16:47:51.645061 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5dfdfce6-d88b-4e32-b1bd-4b0e6716a35d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110acff40>]}
[0m16:47:51.645488 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m16:47:51.654271 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m16:47:51.682708 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:47:51.682947 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:47:51.683313 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m16:47:51.686985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5dfdfce6-d88b-4e32-b1bd-4b0e6716a35d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113e10d0>]}
[0m16:47:51.720832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5dfdfce6-d88b-4e32-b1bd-4b0e6716a35d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110154c0>]}
[0m16:47:51.721147 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m16:47:51.721354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5dfdfce6-d88b-4e32-b1bd-4b0e6716a35d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11092da30>]}
[0m16:47:51.722177 [info ] [MainThread]: 
[0m16:47:51.722727 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m16:47:51.723489 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m16:47:51.733436 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m16:47:51.733676 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m16:47:51.733857 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:47:51.735741 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:47:51.735953 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:47:51.737095 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m16:47:51.738691 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m16:47:51.738893 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m16:47:51.739065 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:47:51.739289 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:47:51.739473 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:47:53.024338 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:47:53.028321 [debug] [ThreadPool]: On list_prod: Close
[0m16:47:53.037837 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:47:53.041922 [debug] [ThreadPool]: On list_prod: Close
[0m16:47:53.047022 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m16:47:53.048922 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m16:47:53.063454 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:47:53.068680 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:47:53.069110 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m16:47:53.069361 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m16:47:53.069589 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:47:53.069810 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:47:53.070437 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:47:53.070974 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:47:53.071265 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:47:53.071500 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:47:54.187623 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:47:54.188808 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:47:54.189440 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:47:54.190092 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m16:47:54.190717 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:47:54.191546 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m16:47:54.466985 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:47:54.469680 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m16:47:54.470456 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:47:54.473833 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m16:47:54.734920 [debug] [ThreadPool]: On list_prod_public: Close
[0m16:47:54.740959 [debug] [ThreadPool]: On list_prod_staging: Close
[0m16:47:54.763004 [debug] [MainThread]: Using redshift connection "master"
[0m16:47:54.763771 [debug] [MainThread]: On master: BEGIN
[0m16:47:54.764234 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:47:54.764860 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:47:54.765307 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:47:55.869828 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m16:47:55.871697 [debug] [MainThread]: Using redshift connection "master"
[0m16:47:55.873071 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m16:47:56.177136 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:47:56.180093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5dfdfce6-d88b-4e32-b1bd-4b0e6716a35d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113fa940>]}
[0m16:47:56.181192 [debug] [MainThread]: On master: ROLLBACK
[0m16:47:56.452195 [debug] [MainThread]: Using redshift connection "master"
[0m16:47:56.453127 [debug] [MainThread]: On master: BEGIN
[0m16:47:56.582561 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:47:56.583380 [debug] [MainThread]: On master: COMMIT
[0m16:47:56.584309 [debug] [MainThread]: Using redshift connection "master"
[0m16:47:56.585421 [debug] [MainThread]: On master: COMMIT
[0m16:47:56.844865 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:47:56.846711 [debug] [MainThread]: On master: Close
[0m16:47:56.848886 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m16:47:56.849747 [info ] [MainThread]: 
[0m16:47:56.855979 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m16:47:56.857884 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m16:47:56.858995 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m16:47:56.860328 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m16:47:56.861963 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m16:47:56.864224 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m16:47:56.866121 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_added_event)
[0m16:47:56.867448 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_deleted_event)
[0m16:47:56.868755 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m16:47:56.869809 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m16:47:56.870994 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m16:47:56.871829 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m16:47:56.879395 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m16:47:56.884899 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m16:47:56.890130 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m16:47:56.891555 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 16:47:56.872331 => 16:47:56.891179
[0m16:47:56.892319 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 16:47:56.885402 => 16:47:56.891921
[0m16:47:56.892928 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 16:47:56.879864 => 16:47:56.892634
[0m16:47:56.893398 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m16:47:56.893875 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m16:47:56.894332 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m16:47:56.954617 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m16:47:56.959615 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m16:47:56.960830 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m16:47:56.962203 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:47:56.963260 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:47:56.963482 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:47:56.964460 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:47:56.964673 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:47:56.964890 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m16:47:56.965109 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:47:56.965304 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m16:47:56.965600 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:47:56.965803 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m16:47:56.966045 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:47:56.966261 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:47:56.966501 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:47:56.966711 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:47:56.967500 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:47:58.073308 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:47:58.075625 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:47:58.077104 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m16:47:58.079173 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:47:58.080628 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:47:58.082024 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:47:58.083467 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:47:58.084853 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m16:47:58.086244 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m16:48:00.544139 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:48:00.550491 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:48:00.552348 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:48:00.553694 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:48:00.559436 [debug] [Thread-3  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:48:00.625373 [debug] [Thread-1  ]: SQL status: SUCCESS in 3.0 seconds
[0m16:48:01.567671 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:48:01.570078 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:48:01.571478 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:48:01.702670 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:01.731431 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m16:48:01.742654 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:48:01.743550 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m16:48:02.004229 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:02.008764 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:48:02.010849 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:48:02.012238 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:48:02.727905 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:48:02.730563 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:48:02.731936 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:48:02.862546 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:02.871030 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:48:02.883851 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:48:02.885315 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:48:02.886426 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:48:02.887503 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m16:48:03.769154 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:48:03.771958 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:48:03.773390 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:48:03.905386 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:03.918333 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m16:48:03.920951 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:48:03.921801 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m16:48:04.007765 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:48:04.055640 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:48:04.056497 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:48:04.056978 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:48:04.187642 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:04.191891 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:48:04.193235 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:48:04.193940 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:48:05.625276 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:48:05.627270 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:48:05.629378 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:48:05.632035 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:48:05.763256 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:05.771066 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:48:05.776161 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:48:05.777545 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:48:05.778604 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m16:48:05.779621 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:48:06.680378 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:48:06.682319 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:48:06.683246 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:48:06.814280 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:06.829179 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m16:48:06.832888 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:48:06.834074 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m16:48:06.913933 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:48:06.919505 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:48:06.920734 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:48:06.921374 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:48:07.097570 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:07.100035 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:48:07.101003 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:48:07.101649 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:48:08.488261 [debug] [Thread-3  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:48:08.489281 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:48:08.491636 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:48:08.492927 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:48:08.624508 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:08.632145 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:48:08.636059 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:48:08.636908 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:48:08.637552 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m16:48:08.898549 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:08.907560 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m16:48:08.910514 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:48:08.911456 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m16:48:09.172111 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:09.176840 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:48:09.179041 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:48:09.180584 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:48:09.318058 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:09.320051 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:48:09.321160 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:48:09.451753 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:09.453703 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 16:47:56.932182 => 16:48:09.453341
[0m16:48:09.454477 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:48:09.455100 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m16:48:09.456236 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:48:09.542114 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:48:09.548009 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:48:09.548885 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:48:09.550103 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:48:09.715108 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:09.724622 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m16:48:09.725573 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m16:48:09.727781 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:48:09.729142 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m16:48:09.731671 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5dfdfce6-d88b-4e32-b1bd-4b0e6716a35d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114d0250>]}
[0m16:48:09.733027 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 12.86s]
[0m16:48:09.734268 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m16:48:09.990438 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:09.995087 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:48:09.997000 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:48:09.998333 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:48:10.374607 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:10.375662 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:48:10.376905 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:48:10.378539 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:48:10.509437 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:10.514581 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 16:47:56.907267 => 16:48:10.513557
[0m16:48:10.516154 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:48:10.517024 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m16:48:10.517863 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:48:10.776967 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m16:48:10.777874 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:10.782880 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m16:48:10.784106 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5dfdfce6-d88b-4e32-b1bd-4b0e6716a35d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114d4670>]}
[0m16:48:10.785571 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:48:10.786305 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m16:48:10.787155 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 13.92s]
[0m16:48:10.788329 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m16:48:11.046890 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:11.050499 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:48:11.051920 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:48:11.052903 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:48:11.189796 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:11.192516 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:48:11.193909 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:48:11.324851 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:11.328378 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 16:47:56.894610 => 16:48:11.327873
[0m16:48:11.329533 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m16:48:11.589019 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m16:48:11.593457 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5dfdfce6-d88b-4e32-b1bd-4b0e6716a35d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ab2c70>]}
[0m16:48:11.595857 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 14.73s]
[0m16:48:11.598372 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m16:48:11.601129 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m16:48:11.603431 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m16:48:11.606432 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m16:48:11.607622 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m16:48:11.668485 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:48:11.668914 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:48:11.669206 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m16:48:11.669607 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:48:11.669906 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:48:12.772808 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:48:12.775002 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:48:12.776885 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m16:48:13.146346 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:13.163828 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m16:48:13.166466 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 16:48:11.608238 => 16:48:13.165855
[0m16:48:13.167378 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m16:48:13.180495 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m16:48:13.186761 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:48:13.187413 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        cancelled.cancelled_flag

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m16:48:14.265020 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:48:14.271142 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:48:14.273104 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:48:14.274159 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:48:15.181966 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:48:15.184345 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:48:15.185706 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:48:15.316495 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:15.330786 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m16:48:15.334220 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:48:15.335259 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m16:48:15.594359 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:15.597146 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:48:15.598125 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:48:15.599035 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:48:16.384712 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:48:16.387372 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:48:16.388521 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:48:16.523479 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:16.538314 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:48:16.539577 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m16:48:17.564217 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:48:17.573737 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:48:17.575384 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:48:17.576433 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:48:18.413099 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:48:18.414634 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:48:18.415352 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:48:18.674097 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:18.686638 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m16:48:18.690877 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:48:18.691995 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m16:48:18.950736 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:18.955575 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:48:18.957292 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:48:18.958582 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:48:19.094852 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:19.096914 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:48:19.098125 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:48:19.228582 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:19.233645 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 16:48:13.167898 => 16:48:19.232756
[0m16:48:19.235191 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m16:48:19.491862 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m16:48:19.494408 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5dfdfce6-d88b-4e32-b1bd-4b0e6716a35d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d37f70>]}
[0m16:48:19.495788 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 7.89s]
[0m16:48:19.497148 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m16:48:19.499897 [debug] [MainThread]: Using redshift connection "master"
[0m16:48:19.500709 [debug] [MainThread]: On master: BEGIN
[0m16:48:19.501291 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:48:19.502087 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:48:19.502642 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:48:20.590129 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m16:48:20.591037 [debug] [MainThread]: On master: COMMIT
[0m16:48:20.591733 [debug] [MainThread]: Using redshift connection "master"
[0m16:48:20.592268 [debug] [MainThread]: On master: COMMIT
[0m16:48:20.847630 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:48:20.848132 [debug] [MainThread]: On master: Close
[0m16:48:20.849038 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:48:20.849364 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m16:48:20.849654 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m16:48:20.849932 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m16:48:20.850234 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m16:48:20.850582 [info ] [MainThread]: 
[0m16:48:20.850937 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 29.13 seconds (29.13s).
[0m16:48:20.852188 [debug] [MainThread]: Command end result
[0m16:48:20.863711 [info ] [MainThread]: 
[0m16:48:20.864150 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:48:20.864457 [info ] [MainThread]: 
[0m16:48:20.864768 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m16:48:20.866388 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 29.462564, "process_user_time": 2.63773, "process_kernel_time": 0.276217, "process_mem_max_rss": "129433600", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m16:48:20.866816 [debug] [MainThread]: Command `dbt run` succeeded at 16:48:20.866716 after 29.46 seconds
[0m16:48:20.867117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104282580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109a3f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ab2c70>]}
[0m16:48:20.867424 [debug] [MainThread]: Flushing usage events
[0m16:50:46.175537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103190c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105284e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052ab670>]}


============================== 16:50:46.178215 | b75d3704-b12b-4b96-9058-dd7dfa99f308 ==============================
[0m16:50:46.178215 [info ] [MainThread]: Running with dbt=1.7.1
[0m16:50:46.178571 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'send_anonymous_usage_stats': 'True'}
[0m16:50:46.336499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b75d3704-b12b-4b96-9058-dd7dfa99f308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105284e50>]}
[0m16:50:46.384747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b75d3704-b12b-4b96-9058-dd7dfa99f308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b42c10>]}
[0m16:50:46.385183 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m16:50:46.394682 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m16:50:46.423258 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:50:46.423648 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/acuity_scheduling/fact_apointment_schedule.sql
[0m16:50:46.613134 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m16:50:46.616762 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b75d3704-b12b-4b96-9058-dd7dfa99f308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066960d0>]}
[0m16:50:46.623470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b75d3704-b12b-4b96-9058-dd7dfa99f308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10635ba60>]}
[0m16:50:46.623765 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m16:50:46.623969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b75d3704-b12b-4b96-9058-dd7dfa99f308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10635ba00>]}
[0m16:50:46.624856 [info ] [MainThread]: 
[0m16:50:46.625365 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m16:50:46.626049 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m16:50:46.636535 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m16:50:46.637120 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m16:50:46.637326 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m16:50:46.639063 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m16:50:46.639313 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:50:46.639499 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m16:50:46.641417 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:50:46.641614 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:50:46.641796 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:50:46.642013 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:50:46.642933 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:50:47.924378 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:50:47.930425 [debug] [ThreadPool]: On list_prod: Close
[0m16:50:47.931422 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:50:47.934210 [debug] [ThreadPool]: On list_prod: Close
[0m16:50:47.937970 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m16:50:47.945418 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m16:50:47.951191 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:50:47.956523 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:50:47.956992 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m16:50:47.957372 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m16:50:47.957764 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:50:47.958110 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:50:47.958692 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:50:47.959169 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:50:47.959563 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:50:47.959925 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:50:49.080120 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:50:49.081611 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:50:49.082696 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:50:49.083388 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:50:49.084272 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m16:50:49.085011 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m16:50:49.357854 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:50:49.359310 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m16:50:49.359741 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:50:49.360939 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m16:50:49.624837 [debug] [ThreadPool]: On list_prod_public: Close
[0m16:50:49.625438 [debug] [ThreadPool]: On list_prod_staging: Close
[0m16:50:49.640329 [debug] [MainThread]: Using redshift connection "master"
[0m16:50:49.640685 [debug] [MainThread]: On master: BEGIN
[0m16:50:49.641080 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:50:49.641483 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:50:49.641776 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:50:50.734133 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m16:50:50.734627 [debug] [MainThread]: Using redshift connection "master"
[0m16:50:50.735035 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m16:50:51.038233 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:50:51.040046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b75d3704-b12b-4b96-9058-dd7dfa99f308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068b8490>]}
[0m16:50:51.040718 [debug] [MainThread]: On master: ROLLBACK
[0m16:50:51.312599 [debug] [MainThread]: Using redshift connection "master"
[0m16:50:51.314400 [debug] [MainThread]: On master: BEGIN
[0m16:50:51.444174 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:50:51.445348 [debug] [MainThread]: On master: COMMIT
[0m16:50:51.446413 [debug] [MainThread]: Using redshift connection "master"
[0m16:50:51.447314 [debug] [MainThread]: On master: COMMIT
[0m16:50:51.706239 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:50:51.708085 [debug] [MainThread]: On master: Close
[0m16:50:51.710709 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m16:50:51.711506 [info ] [MainThread]: 
[0m16:50:51.715907 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m16:50:51.716820 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m16:50:51.718700 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m16:50:51.718082 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m16:50:51.719846 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m16:50:51.720742 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m16:50:51.722106 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_added_event)
[0m16:50:51.723259 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_deleted_event)
[0m16:50:51.724457 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m16:50:51.724971 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m16:50:51.725468 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m16:50:51.725941 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m16:50:51.731479 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m16:50:51.736838 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m16:50:51.741360 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m16:50:51.742473 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 16:50:51.731981 => 16:50:51.742159
[0m16:50:51.743070 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 16:50:51.737292 => 16:50:51.742755
[0m16:50:51.743622 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 16:50:51.726248 => 16:50:51.743343
[0m16:50:51.744067 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m16:50:51.744506 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m16:50:51.744927 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m16:50:51.811197 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m16:50:51.811706 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m16:50:51.814161 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m16:50:51.815561 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:50:51.815791 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:50:51.816824 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:50:51.817034 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m16:50:51.818151 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:50:51.818382 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:50:51.818692 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:50:51.818916 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:50:51.819137 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m16:50:51.819348 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:50:51.819545 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m16:50:51.819796 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:50:51.820613 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:50:51.820863 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:50:51.821125 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:50:52.929696 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:50:52.931795 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:50:52.932857 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:50:52.933588 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:50:52.934425 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:50:52.935205 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m16:50:52.935915 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:50:52.936909 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m16:50:52.938598 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m16:50:55.101902 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:50:55.108582 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:50:55.110410 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:50:55.111159 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:50:55.288718 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:50:55.461307 [debug] [Thread-3  ]: SQL status: SUCCESS in 3.0 seconds
[0m16:50:56.085002 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:50:56.087784 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:50:56.089220 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:50:56.220143 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:50:56.237387 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m16:50:56.244644 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:50:56.245177 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m16:50:56.503701 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:50:56.507990 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:50:56.509603 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:50:56.510863 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:50:57.255207 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:50:57.257557 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:50:57.258924 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:50:57.389936 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:50:57.398084 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:50:57.405545 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:50:57.410716 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:50:57.411400 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:50:57.412088 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m16:50:58.209546 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:50:58.211608 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:50:58.212919 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:50:58.341616 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:50:58.351055 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m16:50:58.352954 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:50:58.353537 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m16:50:58.461932 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:50:58.502133 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:50:58.502762 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:50:58.503195 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:50:58.624611 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:50:58.628859 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:50:58.630461 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:50:58.631650 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:50:59.963110 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:50:59.969466 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:50:59.971212 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:50:59.972174 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:51:00.102389 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:00.109992 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:51:00.112270 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:51:00.112950 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:51:00.113580 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m16:51:00.114206 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:51:01.167824 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:51:01.169869 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:51:01.171810 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:51:01.300893 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:01.309762 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m16:51:01.311685 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:51:01.312329 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m16:51:01.422801 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:51:01.430136 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:51:01.431133 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:51:01.431879 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:51:01.570042 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:01.573696 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:51:01.574858 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:51:01.575593 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:51:02.858526 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:51:02.860320 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:51:02.863231 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:51:02.864381 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:51:02.993598 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:03.002336 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:51:03.008352 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:51:03.009212 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:51:03.010100 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m16:51:03.267465 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:03.280426 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m16:51:03.282245 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:51:03.282902 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m16:51:03.539341 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:03.543054 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:51:03.543937 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:51:03.544874 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:51:03.681704 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:03.683823 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:51:03.685124 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:51:03.824710 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:03.829214 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 16:50:51.776772 => 16:51:03.828343
[0m16:51:03.831036 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:51:03.832323 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m16:51:03.833328 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:51:03.904721 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:51:03.912115 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:51:03.913074 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:51:03.913650 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:51:04.089500 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m16:51:04.091412 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:04.100156 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b75d3704-b12b-4b96-9058-dd7dfa99f308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10635b6a0>]}
[0m16:51:04.103617 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m16:51:04.104531 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 12.38s]
[0m16:51:04.106241 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:51:04.107103 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m16:51:04.107650 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m16:51:04.364981 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:04.370353 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:51:04.372241 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:51:04.373663 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:51:04.906702 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:51:04.908687 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:51:04.912020 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:51:04.913455 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:51:05.042352 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:05.046506 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 16:50:51.745194 => 16:51:05.045687
[0m16:51:05.047757 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:51:05.048447 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m16:51:05.049096 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:51:05.306062 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:05.306892 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m16:51:05.312129 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m16:51:05.313716 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:51:05.314408 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m16:51:05.315461 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b75d3704-b12b-4b96-9058-dd7dfa99f308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106728b50>]}
[0m16:51:05.316378 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 13.59s]
[0m16:51:05.317173 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m16:51:05.573565 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:05.576318 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:51:05.577351 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:51:05.578027 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:51:05.713635 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:05.716216 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:51:05.717584 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:51:05.846673 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:05.851044 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 16:50:51.757961 => 16:51:05.850192
[0m16:51:05.852408 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m16:51:06.109480 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m16:51:06.114142 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b75d3704-b12b-4b96-9058-dd7dfa99f308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069407f0>]}
[0m16:51:06.115732 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 14.39s]
[0m16:51:06.116898 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m16:51:06.118694 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m16:51:06.119885 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m16:51:06.121364 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m16:51:06.121997 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m16:51:06.159128 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:51:06.159644 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:51:06.160009 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m16:51:06.160522 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:51:06.160905 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:51:07.265166 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:51:07.267161 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:51:07.268994 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m16:51:07.636361 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:07.648628 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m16:51:07.650485 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 16:51:06.122363 => 16:51:07.649961
[0m16:51:07.651247 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m16:51:07.660950 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m16:51:07.665661 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:51:07.666283 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        coalesce(cancelled.cancelled_flag, false)

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m16:51:15.227687 [debug] [Thread-4  ]: SQL status: SUCCESS in 8.0 seconds
[0m16:51:15.234340 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:51:15.236127 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:51:15.237544 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:51:16.251358 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:51:16.253105 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:51:16.253922 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:51:16.383081 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:16.390934 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m16:51:16.393513 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:51:16.394344 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m16:51:16.652974 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:16.655321 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:51:16.656169 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:51:16.656782 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:51:17.438179 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:51:17.439503 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:51:17.440400 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:51:17.570071 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:17.580380 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:51:17.581687 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m16:51:18.601866 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:51:18.606088 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:51:18.607037 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:51:18.607618 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:51:19.570664 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:51:19.573441 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:51:19.574209 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:51:19.831208 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:19.840964 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m16:51:19.843332 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:51:19.844005 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m16:51:20.100187 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:20.102591 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:51:20.104104 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:51:20.105324 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:51:20.240953 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:20.241938 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:51:20.242671 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:51:20.371707 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:20.375279 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 16:51:07.651627 => 16:51:20.374454
[0m16:51:20.376699 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m16:51:20.634179 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m16:51:20.639200 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b75d3704-b12b-4b96-9058-dd7dfa99f308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106728550>]}
[0m16:51:20.641602 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 14.52s]
[0m16:51:20.644247 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m16:51:20.649769 [debug] [MainThread]: Using redshift connection "master"
[0m16:51:20.651050 [debug] [MainThread]: On master: BEGIN
[0m16:51:20.652002 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:51:20.653257 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:51:20.654207 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:51:21.748500 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m16:51:21.748862 [debug] [MainThread]: On master: COMMIT
[0m16:51:21.749171 [debug] [MainThread]: Using redshift connection "master"
[0m16:51:21.749400 [debug] [MainThread]: On master: COMMIT
[0m16:51:22.005718 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:51:22.007755 [debug] [MainThread]: On master: Close
[0m16:51:22.011224 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:51:22.012732 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m16:51:22.013769 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m16:51:22.014784 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m16:51:22.015721 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m16:51:22.016398 [info ] [MainThread]: 
[0m16:51:22.017111 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 35.39 seconds (35.39s).
[0m16:51:22.019643 [debug] [MainThread]: Command end result
[0m16:51:22.046431 [info ] [MainThread]: 
[0m16:51:22.047127 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:51:22.047852 [info ] [MainThread]: 
[0m16:51:22.048538 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m16:51:22.051488 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 35.908047, "process_user_time": 2.701714, "process_kernel_time": 0.258824, "process_mem_max_rss": "134873088", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m16:51:22.052310 [debug] [MainThread]: Command `dbt run` succeeded at 16:51:22.052127 after 35.91 seconds
[0m16:51:22.052844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103190c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d8d8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105284e50>]}
[0m16:51:22.053406 [debug] [MainThread]: Flushing usage events
[0m16:54:18.750488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052c5c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075b6e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075df670>]}


============================== 16:54:18.753635 | 5527d30e-e7cd-4b55-953c-59afb72f20b5 ==============================
[0m16:54:18.753635 [info ] [MainThread]: Running with dbt=1.7.1
[0m16:54:18.754010 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:54:18.939738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5527d30e-e7cd-4b55-953c-59afb72f20b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075b6e50>]}
[0m16:54:18.987682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5527d30e-e7cd-4b55-953c-59afb72f20b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108136c10>]}
[0m16:54:18.990477 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m16:54:19.000105 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m16:54:19.035749 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:54:19.036187 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/acuity_scheduling/fact_apointment_schedule.sql
[0m16:54:19.226636 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m16:54:19.230198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5527d30e-e7cd-4b55-953c-59afb72f20b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c8a0d0>]}
[0m16:54:19.237310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5527d30e-e7cd-4b55-953c-59afb72f20b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10894fa60>]}
[0m16:54:19.237591 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m16:54:19.237798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5527d30e-e7cd-4b55-953c-59afb72f20b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10894fa00>]}
[0m16:54:19.238780 [info ] [MainThread]: 
[0m16:54:19.239314 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m16:54:19.240016 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m16:54:19.240520 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m16:54:19.252816 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m16:54:19.253027 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m16:54:19.253198 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:54:19.255104 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:54:19.255311 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:54:19.258429 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m16:54:19.258875 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m16:54:19.259089 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:54:19.259602 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:54:19.260218 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:54:20.587224 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:20.588701 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:20.593101 [debug] [ThreadPool]: On list_prod: Close
[0m16:54:20.596497 [debug] [ThreadPool]: On list_prod: Close
[0m16:54:20.602844 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m16:54:20.604641 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m16:54:20.626409 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:54:20.629520 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:54:20.629901 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m16:54:20.630270 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m16:54:20.630629 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:54:20.630968 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:54:20.631542 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:54:20.632006 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:54:20.632386 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:54:20.632786 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:54:21.752531 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:21.753859 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:21.755035 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m16:54:21.756085 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m16:54:21.756769 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m16:54:21.757628 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m16:54:22.034102 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:22.036023 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:22.041294 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m16:54:22.045324 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m16:54:22.312365 [debug] [ThreadPool]: On list_prod_staging: Close
[0m16:54:22.314380 [debug] [ThreadPool]: On list_prod_public: Close
[0m16:54:22.349470 [debug] [MainThread]: Using redshift connection "master"
[0m16:54:22.350175 [debug] [MainThread]: On master: BEGIN
[0m16:54:22.350615 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:54:22.351284 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:54:22.351772 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:54:23.458986 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:23.461127 [debug] [MainThread]: Using redshift connection "master"
[0m16:54:23.462594 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m16:54:23.765441 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:23.771555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5527d30e-e7cd-4b55-953c-59afb72f20b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10894f4f0>]}
[0m16:54:23.773356 [debug] [MainThread]: On master: ROLLBACK
[0m16:54:24.046225 [debug] [MainThread]: Using redshift connection "master"
[0m16:54:24.048098 [debug] [MainThread]: On master: BEGIN
[0m16:54:24.178725 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:24.180816 [debug] [MainThread]: On master: COMMIT
[0m16:54:24.182431 [debug] [MainThread]: Using redshift connection "master"
[0m16:54:24.183558 [debug] [MainThread]: On master: COMMIT
[0m16:54:24.444516 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:24.446659 [debug] [MainThread]: On master: Close
[0m16:54:24.450044 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m16:54:24.451246 [info ] [MainThread]: 
[0m16:54:24.457553 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m16:54:24.458646 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m16:54:24.459700 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m16:54:24.461129 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m16:54:24.462553 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m16:54:24.463911 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m16:54:24.465900 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_added_event)
[0m16:54:24.467642 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_deleted_event)
[0m16:54:24.469323 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m16:54:24.470188 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m16:54:24.471321 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m16:54:24.472443 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m16:54:24.480366 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m16:54:24.485783 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m16:54:24.490704 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m16:54:24.491995 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 16:54:24.473009 => 16:54:24.491657
[0m16:54:24.492696 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 16:54:24.480798 => 16:54:24.492313
[0m16:54:24.493311 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 16:54:24.486162 => 16:54:24.493030
[0m16:54:24.493844 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m16:54:24.494360 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m16:54:24.494833 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m16:54:24.560856 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m16:54:24.561399 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m16:54:24.561783 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m16:54:24.563035 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:54:24.563255 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:54:24.563452 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m16:54:24.563738 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:54:24.563949 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:54:24.565371 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:54:24.565591 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:54:24.565785 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m16:54:24.566032 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:54:24.566241 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:54:24.567840 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:54:24.568048 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:54:24.568237 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m16:54:24.568498 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:54:24.568716 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:54:25.682279 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:25.684365 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:25.686011 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:25.687409 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:54:25.688836 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:54:25.690218 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:54:25.691803 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m16:54:25.693434 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m16:54:25.694979 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m16:54:27.947141 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:54:27.951290 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:54:27.952344 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:54:27.952962 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:54:28.225380 [debug] [Thread-1  ]: SQL status: SUCCESS in 3.0 seconds
[0m16:54:28.330507 [debug] [Thread-3  ]: SQL status: SUCCESS in 3.0 seconds
[0m16:54:28.893643 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:28.896460 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:54:28.897929 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:54:29.028039 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:29.040885 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m16:54:29.050300 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:54:29.051101 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m16:54:29.312489 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:29.316039 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:54:29.317081 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:54:29.317799 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:54:30.069415 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:30.071729 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:54:30.073092 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:54:30.204084 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:30.212412 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:54:30.226823 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:54:30.227864 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:54:30.228661 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m16:54:30.229651 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:54:31.221710 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:31.223166 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:54:31.223868 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:54:31.353646 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:31.368336 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m16:54:31.372761 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:54:31.373596 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m16:54:31.476824 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:31.523799 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:54:31.524535 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:54:31.525002 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:54:31.639202 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:31.643783 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:54:31.645352 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:54:31.646630 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:54:33.352847 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:54:33.353985 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:54:33.355697 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:54:33.356350 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:54:33.487091 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:33.495584 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:54:33.503476 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:54:33.505004 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:54:33.505869 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:54:33.506701 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m16:54:34.796301 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:34.798808 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:54:34.800205 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:54:34.929961 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:34.944778 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m16:54:34.948697 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:54:34.949782 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m16:54:35.027842 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:54:35.037600 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:54:35.038985 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:54:35.039914 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:54:35.209135 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:35.213826 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:54:35.215605 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:54:35.216872 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:54:36.760436 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:54:36.762545 [debug] [Thread-3  ]: SQL status: SUCCESS in 2.0 seconds
[0m16:54:36.765766 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:54:36.767172 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:54:36.897311 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:36.906411 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:54:36.913965 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:54:36.913098 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:54:36.915106 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m16:54:37.173970 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:37.190792 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m16:54:37.193467 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:54:37.194318 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m16:54:37.454272 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:37.459383 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:54:37.461152 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:54:37.462551 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m16:54:37.600169 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:37.602984 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m16:54:37.604428 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m16:54:37.735380 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:37.738301 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 16:54:24.509107 => 16:54:37.737870
[0m16:54:37.739315 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:54:37.740014 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m16:54:37.740698 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:54:37.810678 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:37.820538 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:54:37.822396 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:54:37.823662 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:54:38.000109 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:38.002218 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m16:54:38.015302 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m16:54:38.018206 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:54:38.019281 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m16:54:38.021208 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5527d30e-e7cd-4b55-953c-59afb72f20b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cf1a60>]}
[0m16:54:38.022889 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 13.55s]
[0m16:54:38.024401 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m16:54:38.277777 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:38.282348 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:54:38.284199 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:54:38.285547 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m16:54:38.666569 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:38.668538 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:38.671923 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m16:54:38.673320 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m16:54:38.803669 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:38.806721 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 16:54:24.495116 => 16:54:38.806296
[0m16:54:38.807765 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:54:38.808474 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m16:54:38.809125 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:54:39.065614 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m16:54:39.066598 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:39.071824 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m16:54:39.072976 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5527d30e-e7cd-4b55-953c-59afb72f20b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d0dc40>]}
[0m16:54:39.074458 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:54:39.075346 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 14.61s]
[0m16:54:39.075990 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m16:54:39.076953 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m16:54:39.335733 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:39.341190 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:54:39.343046 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:54:39.344458 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m16:54:39.479060 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:39.481572 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m16:54:39.482919 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m16:54:39.612912 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:39.617692 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 16:54:24.546708 => 16:54:39.616909
[0m16:54:39.619163 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m16:54:39.876189 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m16:54:39.879046 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5527d30e-e7cd-4b55-953c-59afb72f20b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ae2040>]}
[0m16:54:39.880313 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 15.41s]
[0m16:54:39.881483 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m16:54:39.883258 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m16:54:39.884315 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m16:54:39.886144 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m16:54:39.887039 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m16:54:39.932444 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:54:39.932986 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:54:39.933358 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m16:54:39.933887 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:54:39.934274 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:54:41.049447 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:41.051015 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:54:41.052386 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m16:54:41.418779 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:41.435325 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m16:54:41.437627 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 16:54:39.887526 => 16:54:41.436994
[0m16:54:41.438750 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m16:54:41.451953 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m16:54:41.458031 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:54:41.458791 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        coalesce(cancelled.cancelled_flag, false) as cancelled_flag

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m16:54:42.733207 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:42.739715 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:54:42.741552 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:54:42.742993 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:54:43.736041 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:43.738785 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:54:43.740168 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:54:43.870348 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:43.885109 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m16:54:43.888748 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:54:43.889857 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m16:54:44.149615 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:44.150554 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:54:44.150982 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:54:44.151313 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:54:44.852693 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:44.854719 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:54:44.855974 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:54:44.984856 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:45.000126 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:54:45.001292 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m16:54:46.023598 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:46.032684 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:54:46.034140 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:54:46.035112 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:54:46.950896 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:46.954367 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:54:46.955690 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:54:47.216043 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:47.230610 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m16:54:47.234870 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:54:47.235907 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m16:54:47.494866 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:47.497824 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:54:47.499316 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:54:47.500707 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m16:54:47.635840 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:47.638392 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m16:54:47.639730 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m16:54:47.769396 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:47.774017 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 16:54:41.439254 => 16:54:47.773158
[0m16:54:47.775443 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m16:54:48.032980 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m16:54:48.037940 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5527d30e-e7cd-4b55-953c-59afb72f20b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109adbc70>]}
[0m16:54:48.040538 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 8.15s]
[0m16:54:48.043137 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m16:54:48.048100 [debug] [MainThread]: Using redshift connection "master"
[0m16:54:48.049108 [debug] [MainThread]: On master: BEGIN
[0m16:54:48.049893 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:54:48.051195 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m16:54:48.051977 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m16:54:49.154569 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m16:54:49.154960 [debug] [MainThread]: On master: COMMIT
[0m16:54:49.155287 [debug] [MainThread]: Using redshift connection "master"
[0m16:54:49.155536 [debug] [MainThread]: On master: COMMIT
[0m16:54:49.420737 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m16:54:49.422368 [debug] [MainThread]: On master: Close
[0m16:54:49.425864 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:54:49.426943 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m16:54:49.427945 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m16:54:49.428949 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m16:54:49.429958 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m16:54:49.431314 [info ] [MainThread]: 
[0m16:54:49.432562 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 30.19 seconds (30.19s).
[0m16:54:49.437202 [debug] [MainThread]: Command end result
[0m16:54:49.468059 [info ] [MainThread]: 
[0m16:54:49.468679 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:54:49.469280 [info ] [MainThread]: 
[0m16:54:49.469763 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m16:54:49.472205 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 30.75818, "process_user_time": 2.930301, "process_kernel_time": 0.31264, "process_mem_max_rss": "134594560", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m16:54:49.472939 [debug] [MainThread]: Command `dbt run` succeeded at 16:54:49.472763 after 30.76 seconds
[0m16:54:49.473473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052c5c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a980a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082f3040>]}
[0m16:54:49.474018 [debug] [MainThread]: Flushing usage events
[0m17:04:29.533011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102fc2c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051bce50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051e3670>]}


============================== 17:04:29.535765 | 5c9c1b1a-2c02-41a7-a2b8-344b59618208 ==============================
[0m17:04:29.535765 [info ] [MainThread]: Running with dbt=1.7.1
[0m17:04:29.536103 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'version_check': 'True', 'profiles_dir': '/Users/annaantypenko/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m17:04:29.720617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5c9c1b1a-2c02-41a7-a2b8-344b59618208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051bce50>]}
[0m17:04:29.768972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5c9c1b1a-2c02-41a7-a2b8-344b59618208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b76c10>]}
[0m17:04:29.769744 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m17:04:29.779529 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m17:04:29.817961 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:04:29.818211 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:04:29.818592 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m17:04:29.822201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5c9c1b1a-2c02-41a7-a2b8-344b59618208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066210d0>]}
[0m17:04:29.859244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5c9c1b1a-2c02-41a7-a2b8-344b59618208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10629d160>]}
[0m17:04:29.859577 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m17:04:29.859786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5c9c1b1a-2c02-41a7-a2b8-344b59618208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106251e20>]}
[0m17:04:29.860636 [info ] [MainThread]: 
[0m17:04:29.861159 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:04:29.861905 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:04:29.872353 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:04:29.872906 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:04:29.873107 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:04:29.874808 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:04:29.875007 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:04:29.875184 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:04:29.877093 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:04:29.877292 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:04:29.877476 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:04:29.877696 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:04:29.878752 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:04:31.192903 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:31.194576 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:31.198631 [debug] [ThreadPool]: On list_prod: Close
[0m17:04:31.202055 [debug] [ThreadPool]: On list_prod: Close
[0m17:04:31.206403 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m17:04:31.207756 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m17:04:31.226134 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:04:31.226855 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:04:31.227243 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m17:04:31.227630 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m17:04:31.227992 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:04:31.228331 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:04:31.228896 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:04:31.229351 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:04:31.229727 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:04:31.230084 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:04:32.360064 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:32.361888 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:32.363237 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:04:32.364428 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:04:32.365776 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m17:04:32.367184 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m17:04:32.645990 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:32.647947 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:32.653114 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m17:04:32.657264 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m17:04:32.925108 [debug] [ThreadPool]: On list_prod_public: Close
[0m17:04:32.926970 [debug] [ThreadPool]: On list_prod_staging: Close
[0m17:04:32.953534 [debug] [MainThread]: Using redshift connection "master"
[0m17:04:32.954261 [debug] [MainThread]: On master: BEGIN
[0m17:04:32.954772 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:04:32.955508 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:04:32.956050 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:04:34.070827 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:34.074399 [debug] [MainThread]: Using redshift connection "master"
[0m17:04:34.074945 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m17:04:34.373191 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:34.378698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5c9c1b1a-2c02-41a7-a2b8-344b59618208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051e3370>]}
[0m17:04:34.380479 [debug] [MainThread]: On master: ROLLBACK
[0m17:04:34.652754 [debug] [MainThread]: Using redshift connection "master"
[0m17:04:34.654649 [debug] [MainThread]: On master: BEGIN
[0m17:04:34.785505 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:34.786739 [debug] [MainThread]: On master: COMMIT
[0m17:04:34.787596 [debug] [MainThread]: Using redshift connection "master"
[0m17:04:34.788105 [debug] [MainThread]: On master: COMMIT
[0m17:04:35.046881 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:35.049302 [debug] [MainThread]: On master: Close
[0m17:04:35.052396 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m17:04:35.053671 [info ] [MainThread]: 
[0m17:04:35.061583 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m17:04:35.063135 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m17:04:35.064031 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m17:04:35.065203 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m17:04:35.066415 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m17:04:35.068239 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m17:04:35.070212 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_added_event)
[0m17:04:35.072264 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_deleted_event)
[0m17:04:35.074065 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m17:04:35.074851 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m17:04:35.075463 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m17:04:35.076043 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m17:04:35.082926 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m17:04:35.088003 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:04:35.092988 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:04:35.094609 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 17:04:35.076435 => 17:04:35.094237
[0m17:04:35.095238 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 17:04:35.083268 => 17:04:35.094913
[0m17:04:35.095759 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 17:04:35.088377 => 17:04:35.095512
[0m17:04:35.096196 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m17:04:35.096647 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m17:04:35.097067 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m17:04:35.163066 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:04:35.165580 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:04:35.166633 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m17:04:35.168223 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:04:35.169649 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:04:35.170719 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:04:35.170927 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:04:35.171156 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:04:35.171406 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:04:35.171629 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:04:35.171834 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:04:35.172038 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m17:04:35.172339 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:04:35.172606 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:04:35.172859 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:04:35.173074 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:04:35.173281 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:04:35.173481 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:04:36.326625 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:36.327981 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:04:36.329273 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:36.330797 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:36.332228 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m17:04:36.333865 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:04:36.335190 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:04:36.336462 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m17:04:36.337548 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m17:04:39.073002 [debug] [Thread-3  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:04:39.075123 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:04:39.075783 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:04:39.076313 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:04:39.396470 [debug] [Thread-1  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:04:39.544599 [debug] [Thread-2  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:04:40.155248 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:40.157109 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:04:40.157769 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:04:40.289469 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:40.311259 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m17:04:40.323782 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:04:40.324718 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m17:04:40.915762 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:40.919992 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:04:40.921554 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:04:40.922794 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:04:41.857878 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:41.859349 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:04:41.859991 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:04:41.990855 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:41.999376 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:04:42.015135 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:04:42.015940 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:04:42.016709 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m17:04:42.017986 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:04:42.974651 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:42.975768 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:04:42.976381 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:04:43.106723 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:43.120439 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m17:04:43.123805 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:04:43.124789 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m17:04:43.220599 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:43.273213 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:04:43.274046 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:04:43.274572 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:04:43.392651 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:43.396892 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:04:43.398563 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:04:43.399836 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:04:44.807973 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:44.809880 [debug] [Thread-3  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:04:44.812002 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:04:44.814572 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:04:44.946009 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:44.953581 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:04:44.955519 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:04:44.956763 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:04:44.957738 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m17:04:44.958365 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:04:46.162929 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:46.165897 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:04:46.167601 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:04:46.300439 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:46.309861 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m17:04:46.312456 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:04:46.313608 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m17:04:46.405585 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:46.411012 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:04:46.412807 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:04:46.414174 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:04:46.575991 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:46.580301 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:04:46.581774 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:04:46.582780 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:04:47.971019 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:04:47.972960 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:47.976179 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:04:47.977599 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:04:48.110809 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:48.122864 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:04:48.130014 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:04:48.131470 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:04:48.132535 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m17:04:48.393503 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:48.400309 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m17:04:48.402781 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:04:48.403558 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m17:04:48.665045 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:48.668287 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:04:48.669434 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:04:48.670214 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:04:48.807155 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:48.809084 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:04:48.810415 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:04:48.941922 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:48.946242 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 17:04:35.128765 => 17:04:48.945327
[0m17:04:48.948070 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:04:48.949611 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m17:04:48.950416 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:04:49.048900 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:49.053979 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:04:49.055312 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:04:49.056094 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:04:49.211478 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m17:04:49.213621 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:49.223328 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c9c1b1a-2c02-41a7-a2b8-344b59618208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b5bf40>]}
[0m17:04:49.228043 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m17:04:49.231909 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:04:49.229733 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 14.15s]
[0m17:04:49.233407 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m17:04:49.235115 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m17:04:49.495960 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:49.500556 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:04:49.502409 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:04:49.503720 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:04:50.092059 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:50.093940 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:50.096050 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:04:50.098625 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:04:50.230597 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:50.235109 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 17:04:35.097343 => 17:04:50.234305
[0m17:04:50.236928 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:04:50.238350 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m17:04:50.239837 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:04:50.501689 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m17:04:50.503483 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:50.513456 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m17:04:50.515324 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c9c1b1a-2c02-41a7-a2b8-344b59618208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10679a970>]}
[0m17:04:50.517585 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:04:50.518637 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m17:04:50.519840 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 15.45s]
[0m17:04:50.521216 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m17:04:50.781357 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:50.786435 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:04:50.788303 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:04:50.789645 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:04:50.927201 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:50.929920 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:04:50.931231 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:04:51.064291 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:51.068223 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 17:04:35.109944 => 17:04:51.067716
[0m17:04:51.069214 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m17:04:51.331180 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m17:04:51.336298 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c9c1b1a-2c02-41a7-a2b8-344b59618208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051e3370>]}
[0m17:04:51.338848 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 16.26s]
[0m17:04:51.341132 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m17:04:51.344086 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m17:04:51.345636 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m17:04:51.347943 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m17:04:51.349197 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m17:04:51.406483 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:04:51.406895 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:04:51.407186 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m17:04:51.407597 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:04:51.407900 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:04:52.523370 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:52.525398 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:04:52.527264 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m17:04:52.892449 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:52.910476 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m17:04:52.913162 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 17:04:51.349686 => 17:04:52.912519
[0m17:04:52.914216 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m17:04:52.927635 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m17:04:52.934186 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:04:52.934975 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        coalesce(cancelled.cancelled_flag, false) as cancelled_flag

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m17:04:54.383166 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:54.389261 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:04:54.391024 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:04:54.392354 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:04:55.291350 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:55.292031 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:04:55.292425 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:04:55.422755 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:55.427294 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m17:04:55.428720 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:04:55.429241 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m17:04:55.691240 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:55.695477 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:04:55.697036 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:04:55.698287 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:04:56.479974 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:56.482291 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:04:56.483588 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:04:56.615256 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:56.629817 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:04:56.631477 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m17:04:57.662237 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:57.671742 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:04:57.673601 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:04:57.674865 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:04:58.691997 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:04:58.695406 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:04:58.696778 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:04:58.958046 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:58.972008 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m17:04:58.974680 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:04:58.975508 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m17:04:59.234826 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:59.237584 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:04:59.238610 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:04:59.239275 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:04:59.376041 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:59.378566 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:04:59.379893 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:04:59.510004 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:04:59.514202 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 17:04:52.914820 => 17:04:59.513364
[0m17:04:59.515633 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m17:04:59.773899 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m17:04:59.778230 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c9c1b1a-2c02-41a7-a2b8-344b59618208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bfe160>]}
[0m17:04:59.780679 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 8.43s]
[0m17:04:59.783382 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m17:04:59.789123 [debug] [MainThread]: Using redshift connection "master"
[0m17:04:59.790350 [debug] [MainThread]: On master: BEGIN
[0m17:04:59.791231 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:04:59.792533 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:04:59.793433 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:05:00.898439 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:05:00.898827 [debug] [MainThread]: On master: COMMIT
[0m17:05:00.899155 [debug] [MainThread]: Using redshift connection "master"
[0m17:05:00.899401 [debug] [MainThread]: On master: COMMIT
[0m17:05:01.158288 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:05:01.159955 [debug] [MainThread]: On master: Close
[0m17:05:01.163346 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:05:01.164447 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m17:05:01.165463 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m17:05:01.166480 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m17:05:01.167462 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m17:05:01.168779 [info ] [MainThread]: 
[0m17:05:01.170035 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 31.31 seconds (31.31s).
[0m17:05:01.173328 [debug] [MainThread]: Command end result
[0m17:05:01.199023 [info ] [MainThread]: 
[0m17:05:01.199638 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:05:01.200116 [info ] [MainThread]: 
[0m17:05:01.200586 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m17:05:01.203044 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 31.70388, "process_user_time": 2.71908, "process_kernel_time": 0.304039, "process_mem_max_rss": "128696320", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m17:05:01.203860 [debug] [MainThread]: Command `dbt run` succeeded at 17:05:01.203672 after 31.70 seconds
[0m17:05:01.204381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102fc2c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106796220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065e05e0>]}
[0m17:05:01.204931 [debug] [MainThread]: Flushing usage events
[0m17:16:20.676408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1024c5670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104795160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047a3310>]}


============================== 17:16:20.679814 | de0ad645-4773-47b1-8408-f8b3d1a3edd9 ==============================
[0m17:16:20.679814 [info ] [MainThread]: Running with dbt=1.7.1
[0m17:16:20.680253 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m17:16:20.876020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'de0ad645-4773-47b1-8408-f8b3d1a3edd9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104795160>]}
[0m17:16:20.926605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'de0ad645-4773-47b1-8408-f8b3d1a3edd9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059529a0>]}
[0m17:16:20.929305 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m17:16:20.938664 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m17:16:20.978094 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m17:16:20.978617 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/acuity_scheduling/schema.yml
[0m17:16:20.978854 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/acuity_scheduling/fact_apointment_schedule.sql
[0m17:16:21.180737 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m17:16:21.184335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'de0ad645-4773-47b1-8408-f8b3d1a3edd9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066de0d0>]}
[0m17:16:21.191837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'de0ad645-4773-47b1-8408-f8b3d1a3edd9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062a3a90>]}
[0m17:16:21.192185 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m17:16:21.192401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de0ad645-4773-47b1-8408-f8b3d1a3edd9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062a3970>]}
[0m17:16:21.193412 [info ] [MainThread]: 
[0m17:16:21.194132 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:16:21.194965 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:16:21.205130 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:16:21.205616 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:16:21.205804 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:16:21.207606 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:16:21.207914 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:16:21.208109 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:16:21.210278 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:16:21.210605 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:16:21.210829 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:16:21.211079 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:16:21.212155 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:16:22.524312 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:22.526142 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:22.530877 [debug] [ThreadPool]: On list_prod: Close
[0m17:16:22.533543 [debug] [ThreadPool]: On list_prod: Close
[0m17:16:22.537972 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m17:16:22.545367 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m17:16:22.557553 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:16:22.551804 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:16:22.558097 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m17:16:22.558476 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m17:16:22.558847 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:16:22.559187 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:16:22.559750 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:16:22.560255 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:16:22.560656 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:16:22.561024 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:16:23.694004 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:23.695424 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:23.696111 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:16:23.696822 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:16:23.697556 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m17:16:23.698242 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m17:16:23.977697 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:23.979368 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:23.983472 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m17:16:23.985596 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m17:16:24.254066 [debug] [ThreadPool]: On list_prod_staging: Close
[0m17:16:24.255605 [debug] [ThreadPool]: On list_prod_public: Close
[0m17:16:24.281537 [debug] [MainThread]: Using redshift connection "master"
[0m17:16:24.282125 [debug] [MainThread]: On master: BEGIN
[0m17:16:24.282564 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:16:24.283420 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:16:24.283890 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:16:25.408211 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:25.410273 [debug] [MainThread]: Using redshift connection "master"
[0m17:16:25.411577 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m17:16:25.717769 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:25.718889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de0ad645-4773-47b1-8408-f8b3d1a3edd9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106876b50>]}
[0m17:16:25.719276 [debug] [MainThread]: On master: ROLLBACK
[0m17:16:25.990920 [debug] [MainThread]: Using redshift connection "master"
[0m17:16:25.991970 [debug] [MainThread]: On master: BEGIN
[0m17:16:26.122479 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:26.122791 [debug] [MainThread]: On master: COMMIT
[0m17:16:26.123044 [debug] [MainThread]: Using redshift connection "master"
[0m17:16:26.123230 [debug] [MainThread]: On master: COMMIT
[0m17:16:26.382723 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:26.383228 [debug] [MainThread]: On master: Close
[0m17:16:26.384187 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m17:16:26.384555 [info ] [MainThread]: 
[0m17:16:26.387378 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m17:16:26.387767 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m17:16:26.388319 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m17:16:26.388727 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m17:16:26.389158 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m17:16:26.389666 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m17:16:26.390496 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_added_event)
[0m17:16:26.391086 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_deleted_event)
[0m17:16:26.391712 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m17:16:26.392058 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m17:16:26.392398 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m17:16:26.392713 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m17:16:26.396409 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m17:16:26.399540 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:16:26.402453 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:16:26.403491 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 17:16:26.399769 => 17:16:26.403307
[0m17:16:26.403880 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 17:16:26.392913 => 17:16:26.403672
[0m17:16:26.404211 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 17:16:26.396711 => 17:16:26.404054
[0m17:16:26.404480 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m17:16:26.404766 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m17:16:26.405038 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m17:16:26.445328 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m17:16:26.446317 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:16:26.449316 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:16:26.450935 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:16:26.451172 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:16:26.452230 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:16:26.453265 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:16:26.453472 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:16:26.453690 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:16:26.453905 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:16:26.454198 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:16:26.454404 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:16:26.454603 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m17:16:26.454810 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:16:26.455054 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:16:26.455313 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:16:26.455952 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:16:26.456205 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:16:27.573945 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:27.574597 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:16:27.575117 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:27.575629 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:27.576102 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m17:16:27.576617 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:16:27.577048 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:16:27.577746 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m17:16:27.578377 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m17:16:30.047213 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:16:30.048800 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:16:30.049299 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:16:30.049640 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:16:30.139433 [debug] [Thread-1  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:16:30.390259 [debug] [Thread-3  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:16:31.020778 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:31.021880 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:16:31.022545 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:16:31.153982 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:31.172401 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m17:16:31.179650 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:16:31.180252 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m17:16:31.440933 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:31.441790 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:16:31.442145 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:16:31.442408 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:16:32.184719 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:32.185583 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:16:32.186123 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:16:32.316116 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:32.321942 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:16:32.322312 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:16:32.322661 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m17:16:32.323041 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:16:32.323428 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:16:33.308344 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:33.311024 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:16:33.311688 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:16:33.441329 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:33.446732 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m17:16:33.448441 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:16:33.449085 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m17:16:33.550691 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:33.589898 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:16:33.590733 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:16:33.591255 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:16:33.721666 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:33.725677 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:16:33.726980 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:16:33.727764 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:16:35.010233 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:35.011173 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:16:35.011791 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:35.012347 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:16:35.141628 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:35.145761 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:16:35.146308 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:16:35.146745 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m17:16:35.147243 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:16:35.147745 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:16:36.097579 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:36.100274 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:16:36.101579 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:16:36.233180 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:36.242021 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m17:16:36.244024 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:16:36.244699 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m17:16:36.334571 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:36.338281 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:16:36.339077 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:16:36.339687 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:16:36.504699 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:36.506447 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:16:36.507110 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:16:36.507618 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:16:37.753231 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:37.753970 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:37.754654 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:16:37.755483 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:16:37.885169 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:37.893724 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:16:37.897187 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:16:37.897954 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:16:37.898619 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m17:16:38.159236 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:38.169050 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m17:16:38.171032 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:16:38.171697 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m17:16:38.432833 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:38.437802 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:16:38.439577 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:16:38.440879 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:16:38.887349 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:38.889244 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:16:38.890611 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:16:39.022573 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:39.027712 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 17:16:26.446510 => 17:16:39.026903
[0m17:16:39.028603 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:16:39.029376 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m17:16:39.030027 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:16:39.137456 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:39.144558 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:16:39.146364 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:16:39.147339 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:16:39.289981 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:39.291514 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m17:16:39.305132 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m17:16:39.308364 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:16:39.309455 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m17:16:39.311049 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de0ad645-4773-47b1-8408-f8b3d1a3edd9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f9f280>]}
[0m17:16:39.312639 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 12.92s]
[0m17:16:39.314159 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m17:16:39.570596 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:39.575517 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:16:39.577204 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:16:39.578424 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:16:40.050853 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:40.052036 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:40.053324 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:16:40.054777 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:16:40.186062 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:40.189657 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 17:16:26.424084 => 17:16:40.189107
[0m17:16:40.191179 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:16:40.191991 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m17:16:40.192833 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:16:40.454845 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m17:16:40.455600 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:40.456459 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de0ad645-4773-47b1-8408-f8b3d1a3edd9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f06a60>]}
[0m17:16:40.459791 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m17:16:40.460449 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 14.07s]
[0m17:16:40.461442 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:16:40.461960 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m17:16:40.462300 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m17:16:40.722330 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:40.725614 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:16:40.727075 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:16:40.728917 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:16:40.866396 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:40.868111 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:16:40.869930 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:16:41.000009 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:41.003561 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 17:16:26.405211 => 17:16:41.002760
[0m17:16:41.004941 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m17:16:41.265102 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m17:16:41.268278 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de0ad645-4773-47b1-8408-f8b3d1a3edd9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068619a0>]}
[0m17:16:41.269630 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 14.88s]
[0m17:16:41.270704 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m17:16:41.272656 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m17:16:41.274379 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m17:16:41.278054 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m17:16:41.279729 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m17:16:41.324392 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:16:41.325000 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:16:41.325372 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m17:16:41.325989 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:16:41.326365 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:16:42.448890 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:42.450167 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:16:42.451041 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m17:16:42.824596 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:42.834969 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m17:16:42.837953 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 17:16:41.280244 => 17:16:42.837316
[0m17:16:42.838992 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m17:16:42.855849 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m17:16:42.862346 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:16:42.863018 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        coalesce(cancelled.cancelled_flag, false) as cancelled_flag,
        datediff(minute,appointment_time_start,appointment_time_end) as appointment_lenght_minutes

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m17:16:53.755174 [debug] [Thread-4  ]: SQL status: SUCCESS in 11.0 seconds
[0m17:16:53.760194 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:16:53.761103 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:16:53.761682 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:16:54.785384 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:54.788103 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:16:54.789402 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:16:54.921777 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:54.936580 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m17:16:54.939837 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:16:54.940883 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m17:16:55.203965 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:55.209178 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:16:55.210706 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:16:55.211731 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:16:56.265120 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:56.267889 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:16:56.269247 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:16:56.399498 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:56.416619 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:16:56.418464 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m17:16:57.446557 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:57.456369 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:16:57.458530 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:16:57.459884 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:16:58.441421 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:16:58.443617 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:16:58.444441 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:16:58.704826 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:58.713187 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m17:16:58.715825 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:16:58.716628 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m17:16:58.976752 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:58.981531 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:16:58.983275 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:16:58.984558 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:16:59.120626 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:59.123144 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:16:59.124432 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:16:59.255691 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:16:59.260603 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 17:16:42.839595 => 17:16:59.259770
[0m17:16:59.262145 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m17:16:59.522523 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m17:16:59.527485 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de0ad645-4773-47b1-8408-f8b3d1a3edd9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109104370>]}
[0m17:16:59.529934 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 18.25s]
[0m17:16:59.532603 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m17:16:59.537242 [debug] [MainThread]: Using redshift connection "master"
[0m17:16:59.538200 [debug] [MainThread]: On master: BEGIN
[0m17:16:59.538843 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:16:59.539981 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:16:59.540679 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:17:00.638204 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:17:00.638574 [debug] [MainThread]: On master: COMMIT
[0m17:17:00.638883 [debug] [MainThread]: Using redshift connection "master"
[0m17:17:00.639113 [debug] [MainThread]: On master: COMMIT
[0m17:17:00.896558 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:17:00.897767 [debug] [MainThread]: On master: Close
[0m17:17:00.899681 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:17:00.900325 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m17:17:00.900831 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m17:17:00.901297 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m17:17:00.901760 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m17:17:00.902478 [info ] [MainThread]: 
[0m17:17:00.903107 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 39.71 seconds (39.71s).
[0m17:17:00.905178 [debug] [MainThread]: Command end result
[0m17:17:00.932878 [info ] [MainThread]: 
[0m17:17:00.933731 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:17:00.934548 [info ] [MainThread]: 
[0m17:17:00.935361 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m17:17:00.938050 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 40.29759, "process_user_time": 2.679926, "process_kernel_time": 0.313556, "process_mem_max_rss": "134742016", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m17:17:00.938810 [debug] [MainThread]: Command `dbt run` succeeded at 17:17:00.938634 after 40.30 seconds
[0m17:17:00.939335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1024c5670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b54d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091ddbb0>]}
[0m17:17:00.939885 [debug] [MainThread]: Flushing usage events
[0m17:20:45.768274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066c6670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087d7160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087e3310>]}


============================== 17:20:45.771358 | df0a9c12-8418-4af3-9f49-ccca3fb15501 ==============================
[0m17:20:45.771358 [info ] [MainThread]: Running with dbt=1.7.1
[0m17:20:45.771731 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:20:45.953016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'df0a9c12-8418-4af3-9f49-ccca3fb15501', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087d7160>]}
[0m17:20:46.001179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'df0a9c12-8418-4af3-9f49-ccca3fb15501', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090529a0>]}
[0m17:20:46.002443 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m17:20:46.012281 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m17:20:46.047711 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:20:46.047981 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:20:46.048375 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m17:20:46.052107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'df0a9c12-8418-4af3-9f49-ccca3fb15501', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098d10d0>]}
[0m17:20:46.089064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'df0a9c12-8418-4af3-9f49-ccca3fb15501', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109311820>]}
[0m17:20:46.089389 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m17:20:46.089596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'df0a9c12-8418-4af3-9f49-ccca3fb15501', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093113d0>]}
[0m17:20:46.090437 [info ] [MainThread]: 
[0m17:20:46.090918 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:20:46.091616 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:20:46.101465 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:20:46.101930 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:20:46.102126 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:20:46.103732 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:20:46.103929 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:20:46.104114 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:20:46.106086 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:20:46.106301 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:20:46.106492 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:20:46.106781 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:20:46.107933 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:20:47.389605 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:20:47.390726 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:20:47.393684 [debug] [ThreadPool]: On list_prod: Close
[0m17:20:47.396581 [debug] [ThreadPool]: On list_prod: Close
[0m17:20:47.401109 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m17:20:47.408607 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m17:20:47.414720 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:20:47.421938 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:20:47.422399 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m17:20:47.422795 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m17:20:47.423155 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:20:47.423500 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:20:47.424021 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:20:47.424504 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:20:47.424903 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:20:47.425277 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:20:48.551575 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:20:48.553651 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:20:48.554822 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:20:48.556029 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:20:48.557183 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m17:20:48.558224 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m17:20:48.836360 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:20:48.838059 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:20:48.844060 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m17:20:48.848547 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m17:20:49.117160 [debug] [ThreadPool]: On list_prod_staging: Close
[0m17:20:49.119090 [debug] [ThreadPool]: On list_prod_public: Close
[0m17:20:49.148274 [debug] [MainThread]: Using redshift connection "master"
[0m17:20:49.149069 [debug] [MainThread]: On master: BEGIN
[0m17:20:49.149816 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:20:49.150592 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:20:49.151153 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:20:50.268227 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:20:50.268824 [debug] [MainThread]: Using redshift connection "master"
[0m17:20:50.269233 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m17:20:50.568410 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:20:50.574223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'df0a9c12-8418-4af3-9f49-ccca3fb15501', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099cdca0>]}
[0m17:20:50.576250 [debug] [MainThread]: On master: ROLLBACK
[0m17:20:50.847898 [debug] [MainThread]: Using redshift connection "master"
[0m17:20:50.848914 [debug] [MainThread]: On master: BEGIN
[0m17:20:50.979633 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:20:50.981043 [debug] [MainThread]: On master: COMMIT
[0m17:20:50.982076 [debug] [MainThread]: Using redshift connection "master"
[0m17:20:50.982734 [debug] [MainThread]: On master: COMMIT
[0m17:20:51.240991 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:20:51.241898 [debug] [MainThread]: On master: Close
[0m17:20:51.243569 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m17:20:51.244172 [info ] [MainThread]: 
[0m17:20:51.249371 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m17:20:51.250376 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m17:20:51.252055 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m17:20:51.253103 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m17:20:51.254815 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m17:20:51.257317 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m17:20:51.259953 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_added_event)
[0m17:20:51.261635 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_deleted_event)
[0m17:20:51.264143 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m17:20:51.265166 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m17:20:51.265941 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m17:20:51.266669 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m17:20:51.274583 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m17:20:51.281001 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:20:51.290381 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:20:51.292235 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 17:20:51.267162 => 17:20:51.291886
[0m17:20:51.292970 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 17:20:51.282585 => 17:20:51.292584
[0m17:20:51.293620 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 17:20:51.275154 => 17:20:51.293322
[0m17:20:51.294192 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m17:20:51.294756 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m17:20:51.296223 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m17:20:51.370647 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m17:20:51.371543 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:20:51.372021 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:20:51.373408 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:20:51.373643 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:20:51.373847 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m17:20:51.374145 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:20:51.374359 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:20:51.375896 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:20:51.376125 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:20:51.376324 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:20:51.376572 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:20:51.376780 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:20:51.378368 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:20:51.378604 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:20:51.378805 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:20:51.379056 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:20:51.379262 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:20:52.496573 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:20:52.498765 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:20:52.500346 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:20:52.501586 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:20:52.503020 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m17:20:52.504134 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m17:20:52.518807 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:20:52.519987 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:20:52.520824 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m17:20:54.773300 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:20:54.777132 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:20:54.778196 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:20:54.778830 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:20:55.029151 [debug] [Thread-2  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:20:55.615572 [debug] [Thread-3  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:20:55.882817 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:20:55.884572 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:20:55.885537 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:20:56.017483 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:20:56.035711 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m17:20:56.043031 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:20:56.043629 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m17:20:56.303739 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:20:56.306385 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:20:56.307598 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:20:56.308550 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:20:57.110190 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:20:57.111244 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:20:57.111886 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:20:57.242389 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:20:57.250449 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:20:57.259456 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:20:57.260388 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:20:57.261122 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m17:20:57.261767 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:20:58.158849 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:20:58.161501 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:20:58.162914 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:20:58.293895 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:20:58.308061 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m17:20:58.311325 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:20:58.312354 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m17:20:58.387681 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:20:58.437017 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:20:58.437971 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:20:58.438456 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:20:58.572089 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:20:58.576414 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:20:58.578119 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:20:58.579423 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:21:00.348233 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:21:00.350299 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:21:00.353569 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:21:00.355101 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:21:00.486135 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:00.493946 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:21:00.496095 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:21:00.496851 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:21:00.497561 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m17:21:00.498265 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:21:01.520666 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:21:01.522335 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:21:01.523376 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:21:01.655688 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:01.668122 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m17:21:01.671871 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:21:01.672806 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m17:21:01.778808 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:21:01.786705 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:21:01.788293 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:21:01.789361 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:21:01.935619 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:01.939695 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:21:01.941325 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:21:01.942735 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:21:03.772238 [debug] [Thread-3  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:21:03.773730 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:21:03.775714 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:21:03.779588 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:21:03.929475 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:03.939922 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:21:03.945301 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:21:03.946255 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:21:03.947133 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m17:21:04.281607 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:04.291800 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m17:21:04.293819 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:21:04.294461 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m17:21:04.616661 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:04.619490 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:21:04.620298 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:21:04.620889 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:21:04.793659 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:04.795350 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:21:04.796110 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:21:04.929455 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:04.933444 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 17:20:51.296730 => 17:21:04.933019
[0m17:21:04.934503 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:21:04.935447 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m17:21:04.936273 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:21:05.048290 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:21:05.053823 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:21:05.054778 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:21:05.055367 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:21:05.254368 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m17:21:05.255291 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:05.264100 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df0a9c12-8418-4af3-9f49-ccca3fb15501', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109afbdf0>]}
[0m17:21:05.267170 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m17:21:05.268357 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 14.01s]
[0m17:21:05.271638 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:21:05.272983 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m17:21:05.273732 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m17:21:05.533086 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:05.536432 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:21:05.537878 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:21:05.539305 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:21:05.947431 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:05.949371 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:21:05.951488 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:21:05.953779 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:21:06.084501 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:06.087563 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 17:20:51.341214 => 17:21:06.087141
[0m17:21:06.089231 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:21:06.090589 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m17:21:06.091931 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:21:06.350535 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:06.352787 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m17:21:06.353648 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m17:21:06.354426 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:21:06.356765 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m17:21:06.359164 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df0a9c12-8418-4af3-9f49-ccca3fb15501', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099c7eb0>]}
[0m17:21:06.360298 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 15.10s]
[0m17:21:06.361072 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m17:21:06.618586 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:06.623255 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:21:06.625030 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:21:06.626399 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:21:06.762911 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:06.765536 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:21:06.766915 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:21:06.897011 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:06.901343 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 17:20:51.310075 => 17:21:06.900508
[0m17:21:06.902820 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m17:21:07.163463 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m17:21:07.168183 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df0a9c12-8418-4af3-9f49-ccca3fb15501', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092afbe0>]}
[0m17:21:07.170584 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 15.90s]
[0m17:21:07.172982 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m17:21:07.175736 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m17:21:07.177493 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m17:21:07.179802 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m17:21:07.180923 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m17:21:07.240941 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:21:07.241355 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:21:07.241644 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m17:21:07.242046 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:21:07.242345 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:21:08.361965 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:21:08.364128 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:21:08.365919 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m17:21:08.735557 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:08.752510 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m17:21:08.755072 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 17:21:07.181533 => 17:21:08.754432
[0m17:21:08.756041 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m17:21:08.769274 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m17:21:08.776138 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:21:08.776822 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        coalesce(cancelled.cancelled_flag, false) as cancelled_flag,
        datediff(minute,appointment_time_start,appointment_time_end) as appointment_lenght_minutes

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m17:21:10.021997 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:21:10.025951 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:21:10.027488 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:21:10.028704 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:21:10.904233 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:21:10.906621 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:21:10.907481 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:21:11.037685 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:11.043627 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m17:21:11.045499 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:21:11.046175 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m17:21:11.307485 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:11.308443 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:21:11.308833 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:21:11.309408 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:21:12.066543 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:21:12.068868 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:21:12.069874 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:21:12.202166 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:12.218969 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:21:12.220320 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m17:21:13.258632 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:21:13.268492 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:21:13.270345 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:21:13.271688 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:21:14.156392 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:21:14.159883 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:21:14.161278 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:21:14.423154 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:14.437237 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m17:21:14.439875 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:21:14.440843 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m17:21:14.703064 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:14.705321 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:21:14.706181 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:21:14.707024 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:21:14.843183 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:14.844373 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:21:14.845133 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:21:14.976016 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:14.978351 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 17:21:08.756535 => 17:21:14.977957
[0m17:21:14.979285 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m17:21:15.240524 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m17:21:15.245284 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df0a9c12-8418-4af3-9f49-ccca3fb15501', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c20460>]}
[0m17:21:15.247858 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 8.07s]
[0m17:21:15.250183 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m17:21:15.255710 [debug] [MainThread]: Using redshift connection "master"
[0m17:21:15.257067 [debug] [MainThread]: On master: BEGIN
[0m17:21:15.257818 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:21:15.259029 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:21:15.259723 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:21:16.359485 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:21:16.359852 [debug] [MainThread]: On master: COMMIT
[0m17:21:16.360139 [debug] [MainThread]: Using redshift connection "master"
[0m17:21:16.360352 [debug] [MainThread]: On master: COMMIT
[0m17:21:16.620198 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:21:16.622186 [debug] [MainThread]: On master: Close
[0m17:21:16.625604 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:21:16.626395 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m17:21:16.627133 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m17:21:16.627847 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m17:21:16.628644 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m17:21:16.629614 [info ] [MainThread]: 
[0m17:21:16.630542 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 30.54 seconds (30.54s).
[0m17:21:16.633922 [debug] [MainThread]: Command end result
[0m17:21:16.657715 [info ] [MainThread]: 
[0m17:21:16.658438 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:21:16.658910 [info ] [MainThread]: 
[0m17:21:16.659589 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m17:21:16.662073 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 30.93008, "process_user_time": 2.643851, "process_kernel_time": 0.300196, "process_mem_max_rss": "128778240", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m17:21:16.662747 [debug] [MainThread]: Command `dbt run` succeeded at 17:21:16.662593 after 30.93 seconds
[0m17:21:16.663196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066c6670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092d4a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090529a0>]}
[0m17:21:16.663678 [debug] [MainThread]: Flushing usage events
[0m17:23:39.455969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102e318e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f22e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f4b700>]}


============================== 17:23:39.458917 | d00f9170-71e3-482f-8354-bd76117b56a7 ==============================
[0m17:23:39.458917 [info ] [MainThread]: Running with dbt=1.7.1
[0m17:23:39.459262 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m17:23:39.636879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd00f9170-71e3-482f-8354-bd76117b56a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f22e20>]}
[0m17:23:39.688283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd00f9170-71e3-482f-8354-bd76117b56a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059797c0>]}
[0m17:23:39.690897 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m17:23:39.700084 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m17:23:39.736629 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:23:39.736895 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:23:39.737299 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m17:23:39.741119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd00f9170-71e3-482f-8354-bd76117b56a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060390d0>]}
[0m17:23:39.777494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd00f9170-71e3-482f-8354-bd76117b56a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a79ee0>]}
[0m17:23:39.777823 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m17:23:39.778032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd00f9170-71e3-482f-8354-bd76117b56a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10597fe80>]}
[0m17:23:39.778879 [info ] [MainThread]: 
[0m17:23:39.779408 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:23:39.780159 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:23:39.790289 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:23:39.790844 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:23:39.791037 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:23:39.792922 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:23:39.793284 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:23:39.793507 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:23:39.795671 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:23:39.795885 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:23:39.796072 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:23:39.796290 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:23:39.797421 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:23:41.099669 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:41.105134 [debug] [ThreadPool]: On list_prod: Close
[0m17:23:41.106139 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:41.109612 [debug] [ThreadPool]: On list_prod: Close
[0m17:23:41.113829 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m17:23:41.121412 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m17:23:41.134387 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:23:41.127834 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:23:41.134913 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m17:23:41.135318 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m17:23:41.135680 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:23:41.136062 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:23:41.136635 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:23:41.137132 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:23:41.137538 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:23:41.137916 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:23:42.260911 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:42.262530 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:42.263543 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:23:42.264244 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:23:42.265008 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m17:23:42.265713 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m17:23:42.545919 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:42.547982 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:42.551965 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m17:23:42.555054 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m17:23:42.822565 [debug] [ThreadPool]: On list_prod_public: Close
[0m17:23:42.824187 [debug] [ThreadPool]: On list_prod_staging: Close
[0m17:23:42.847211 [debug] [MainThread]: Using redshift connection "master"
[0m17:23:42.847763 [debug] [MainThread]: On master: BEGIN
[0m17:23:42.848190 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:23:42.848822 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:23:42.849267 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:23:43.960891 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:43.961595 [debug] [MainThread]: Using redshift connection "master"
[0m17:23:43.962169 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m17:23:44.266817 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:44.272202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd00f9170-71e3-482f-8354-bd76117b56a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106133f40>]}
[0m17:23:44.274082 [debug] [MainThread]: On master: ROLLBACK
[0m17:23:44.548233 [debug] [MainThread]: Using redshift connection "master"
[0m17:23:44.549978 [debug] [MainThread]: On master: BEGIN
[0m17:23:44.681324 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:44.683045 [debug] [MainThread]: On master: COMMIT
[0m17:23:44.684607 [debug] [MainThread]: Using redshift connection "master"
[0m17:23:44.685634 [debug] [MainThread]: On master: COMMIT
[0m17:23:44.946086 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:44.948024 [debug] [MainThread]: On master: Close
[0m17:23:44.951502 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m17:23:44.952437 [info ] [MainThread]: 
[0m17:23:44.958667 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m17:23:44.959549 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m17:23:44.960205 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m17:23:44.960990 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m17:23:44.962064 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m17:23:44.963249 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m17:23:44.964755 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_added_event)
[0m17:23:44.965960 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_deleted_event)
[0m17:23:44.967200 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m17:23:44.967867 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m17:23:44.968465 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m17:23:44.969011 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m17:23:44.974828 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m17:23:44.979856 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:23:44.984381 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:23:44.985441 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 17:23:44.969334 => 17:23:44.985144
[0m17:23:44.985981 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 17:23:44.980310 => 17:23:44.985715
[0m17:23:44.986456 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 17:23:44.975239 => 17:23:44.986226
[0m17:23:44.986865 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m17:23:44.987288 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m17:23:44.987697 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m17:23:45.056508 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:23:45.058543 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:23:45.059418 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m17:23:45.060765 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:23:45.061908 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:23:45.062122 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:23:45.063117 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:23:45.063328 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:23:45.063527 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m17:23:45.063727 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:23:45.063915 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:23:45.064204 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:23:45.064402 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:23:45.064638 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:23:45.064848 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:23:45.065081 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:23:45.065284 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:23:45.066437 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:23:46.187199 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:46.189040 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:46.190176 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:46.191128 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:23:46.191873 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:23:46.192510 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:23:46.193779 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m17:23:46.194915 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m17:23:46.195818 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m17:23:48.462734 [debug] [Thread-3  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:23:48.469447 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:23:48.471369 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:23:48.472642 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:23:48.702362 [debug] [Thread-2  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:23:48.768297 [debug] [Thread-1  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:23:49.470606 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:49.473396 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:23:49.474795 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:23:49.605259 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:49.621678 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m17:23:49.628207 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:23:49.628714 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m17:23:49.889315 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:49.893659 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:23:49.895284 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:23:49.896542 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:23:50.740314 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:50.740975 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:23:50.741370 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:23:50.871345 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:50.878424 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:23:50.880614 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:23:50.881142 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:23:50.881628 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m17:23:50.882068 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:23:52.099267 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:52.100274 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:23:52.100860 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:23:52.229991 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:52.234112 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m17:23:52.235399 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:23:52.235833 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m17:23:52.346041 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:52.367122 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:23:52.367648 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:23:52.368016 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:23:52.498287 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:52.500537 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:23:52.501370 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:23:52.501977 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:23:53.772241 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:53.774258 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:53.776236 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:23:53.778450 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:23:53.908934 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:53.916501 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:23:53.920606 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:23:53.921469 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:23:53.922180 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m17:23:53.922812 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:23:55.001759 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:55.002759 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:23:55.003425 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:23:55.133654 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:55.144769 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m17:23:55.146685 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:23:55.147358 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m17:23:55.259098 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:55.266941 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:23:55.268069 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:23:55.268824 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:23:55.407308 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:55.411328 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:23:55.412363 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:23:55.413002 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:23:56.941633 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:23:56.943763 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:23:56.946655 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:23:56.947754 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:23:57.078353 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:57.086962 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:23:57.089980 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:23:57.090775 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:23:57.091468 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m17:23:57.350418 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:57.355688 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m17:23:57.357498 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:23:57.358172 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m17:23:57.618906 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:57.623305 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:23:57.624894 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:23:57.626179 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:23:57.762820 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:57.764154 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:23:57.764947 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:23:57.894774 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:57.896768 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 17:23:45.006850 => 17:23:57.896396
[0m17:23:57.897609 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:23:57.898357 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m17:23:57.899055 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:23:57.998638 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:58.001698 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:23:58.002406 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:23:58.002942 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:23:58.159242 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m17:23:58.160153 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:58.165742 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m17:23:58.167433 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:23:58.168558 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd00f9170-71e3-482f-8354-bd76117b56a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106128cd0>]}
[0m17:23:58.169153 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m17:23:58.170177 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 13.20s]
[0m17:23:58.171035 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m17:23:58.428396 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:58.432740 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:23:58.433873 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:23:58.434519 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:23:58.974827 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:58.975805 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:23:58.976457 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:23:58.977072 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:23:59.107810 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:59.112179 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 17:23:45.038217 => 17:23:59.111340
[0m17:23:59.113510 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:23:59.114361 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m17:23:59.115172 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:23:59.374235 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m17:23:59.374690 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:59.377530 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m17:23:59.378176 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd00f9170-71e3-482f-8354-bd76117b56a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106042790>]}
[0m17:23:59.379031 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:23:59.379405 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m17:23:59.379835 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 14.41s]
[0m17:23:59.380411 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m17:23:59.637569 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:59.639468 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:23:59.640258 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:23:59.640885 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:23:59.775898 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:59.776767 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:23:59.777319 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:23:59.906430 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:23:59.907847 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 17:23:44.987951 => 17:23:59.907568
[0m17:23:59.908324 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m17:24:00.167647 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m17:24:00.172110 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd00f9170-71e3-482f-8354-bd76117b56a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106133f40>]}
[0m17:24:00.173760 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 15.21s]
[0m17:24:00.175715 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m17:24:00.177225 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m17:24:00.178245 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m17:24:00.179704 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m17:24:00.180330 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m17:24:00.230662 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:24:00.231066 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:24:00.231348 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m17:24:00.231753 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:24:00.232053 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:24:01.348766 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:24:01.350937 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:24:01.352779 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m17:24:01.720793 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:24:01.733184 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m17:24:01.734721 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 17:24:00.180706 => 17:24:01.734300
[0m17:24:01.735381 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m17:24:01.744126 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m17:24:01.749321 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:24:01.749972 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        coalesce(cancelled.cancelled_flag, false) as cancelled_flag,
        datediff(minute,appointment_time_start,appointment_time_end) as appointment_lenght_minutes

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m17:24:02.740825 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:24:02.743779 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:24:02.744731 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:24:02.745392 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:24:03.687779 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:24:03.689836 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:24:03.691029 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:24:03.821826 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:24:03.832190 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m17:24:03.833846 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:24:03.834460 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m17:24:04.096019 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:24:04.099808 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:24:04.101090 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:24:04.101853 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:24:04.959250 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:24:04.961975 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:24:04.962648 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:24:05.093073 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:24:05.105935 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:24:05.106811 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m17:24:06.135196 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:24:06.143999 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:24:06.144909 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:24:06.145495 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:24:07.036677 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:24:07.039384 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:24:07.040672 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:24:07.300811 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:24:07.313610 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m17:24:07.315405 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:24:07.316056 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m17:24:07.574669 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:24:07.577341 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:24:07.578157 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:24:07.578753 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:24:07.716331 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:24:07.718640 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:24:07.719945 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:24:07.850758 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:24:07.854873 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 17:24:01.735762 => 17:24:07.854194
[0m17:24:07.856131 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m17:24:08.117278 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m17:24:08.120258 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd00f9170-71e3-482f-8354-bd76117b56a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106618f10>]}
[0m17:24:08.121614 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 7.94s]
[0m17:24:08.122673 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m17:24:08.126005 [debug] [MainThread]: Using redshift connection "master"
[0m17:24:08.126808 [debug] [MainThread]: On master: BEGIN
[0m17:24:08.127333 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:24:08.128088 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:24:08.128646 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:24:09.230006 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:24:09.230673 [debug] [MainThread]: On master: COMMIT
[0m17:24:09.231243 [debug] [MainThread]: Using redshift connection "master"
[0m17:24:09.231676 [debug] [MainThread]: On master: COMMIT
[0m17:24:09.491368 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:24:09.493565 [debug] [MainThread]: On master: Close
[0m17:24:09.497238 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:24:09.498321 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m17:24:09.499373 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m17:24:09.500360 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m17:24:09.501355 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m17:24:09.502719 [info ] [MainThread]: 
[0m17:24:09.503994 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 29.72 seconds (29.72s).
[0m17:24:09.507481 [debug] [MainThread]: Command end result
[0m17:24:09.533186 [info ] [MainThread]: 
[0m17:24:09.533863 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:24:09.534336 [info ] [MainThread]: 
[0m17:24:09.534850 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m17:24:09.537389 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 30.11519, "process_user_time": 2.50271, "process_kernel_time": 0.290866, "process_mem_max_rss": "129613824", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m17:24:09.538171 [debug] [MainThread]: Command `dbt run` succeeded at 17:24:09.537991 after 30.12 seconds
[0m17:24:09.538686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102e318e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f22e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a79ee0>]}
[0m17:24:09.539230 [debug] [MainThread]: Flushing usage events
[0m17:34:04.114016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106efd910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090319a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109017bb0>]}


============================== 17:34:04.116906 | 5a3ad719-41c7-48e9-ac95-28f2b76daccb ==============================
[0m17:34:04.116906 [info ] [MainThread]: Running with dbt=1.7.1
[0m17:34:04.117323 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'version_check': 'True', 'profiles_dir': '/Users/annaantypenko/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:34:04.300131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5a3ad719-41c7-48e9-ac95-28f2b76daccb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090319a0>]}
[0m17:34:04.347782 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5a3ad719-41c7-48e9-ac95-28f2b76daccb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109896be0>]}
[0m17:34:04.350247 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m17:34:04.359550 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m17:34:04.395381 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:34:04.395644 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:34:04.396024 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m17:34:04.399933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5a3ad719-41c7-48e9-ac95-28f2b76daccb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1050d0>]}
[0m17:34:04.436257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5a3ad719-41c7-48e9-ac95-28f2b76daccb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a4bca0>]}
[0m17:34:04.436588 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m17:34:04.436800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5a3ad719-41c7-48e9-ac95-28f2b76daccb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ab6610>]}
[0m17:34:04.437803 [info ] [MainThread]: 
[0m17:34:04.438358 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:34:04.439100 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:34:04.446032 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:34:04.450351 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:34:04.452577 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:34:04.452874 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:34:04.453074 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:34:04.453252 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:34:04.453417 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:34:04.455342 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:34:04.455589 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:34:04.455776 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:34:04.455957 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:34:05.788442 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:05.790321 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:05.795061 [debug] [ThreadPool]: On list_prod: Close
[0m17:34:05.797072 [debug] [ThreadPool]: On list_prod: Close
[0m17:34:05.801841 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m17:34:05.809535 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m17:34:05.823293 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:34:05.824125 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:34:05.824527 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m17:34:05.824915 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m17:34:05.825287 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:34:05.825634 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:34:05.826186 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:34:05.826685 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:34:05.827079 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:34:05.827453 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:34:06.958008 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:06.960269 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:06.961523 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:34:06.962731 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:34:06.964045 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m17:34:06.965540 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m17:34:07.241781 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:07.242696 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:07.246233 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m17:34:07.248973 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m17:34:07.515673 [debug] [ThreadPool]: On list_prod_staging: Close
[0m17:34:07.520553 [debug] [ThreadPool]: On list_prod_public: Close
[0m17:34:07.542038 [debug] [MainThread]: Using redshift connection "master"
[0m17:34:07.543124 [debug] [MainThread]: On master: BEGIN
[0m17:34:07.543855 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:34:07.545031 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:34:07.545722 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:34:08.656395 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:08.657631 [debug] [MainThread]: Using redshift connection "master"
[0m17:34:08.658297 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m17:34:08.955974 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:08.960285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5a3ad719-41c7-48e9-ac95-28f2b76daccb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a111910>]}
[0m17:34:08.961794 [debug] [MainThread]: On master: ROLLBACK
[0m17:34:09.231194 [debug] [MainThread]: Using redshift connection "master"
[0m17:34:09.231587 [debug] [MainThread]: On master: BEGIN
[0m17:34:09.360887 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:09.362180 [debug] [MainThread]: On master: COMMIT
[0m17:34:09.363262 [debug] [MainThread]: Using redshift connection "master"
[0m17:34:09.363927 [debug] [MainThread]: On master: COMMIT
[0m17:34:09.623101 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:09.624119 [debug] [MainThread]: On master: Close
[0m17:34:09.627542 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m17:34:09.628581 [info ] [MainThread]: 
[0m17:34:09.635335 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m17:34:09.636803 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m17:34:09.637652 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m17:34:09.638543 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m17:34:09.639486 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m17:34:09.640577 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m17:34:09.642454 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_added_event)
[0m17:34:09.644471 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_deleted_event)
[0m17:34:09.646445 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m17:34:09.647360 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m17:34:09.648013 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m17:34:09.648595 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m17:34:09.655794 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m17:34:09.661200 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:34:09.666419 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:34:09.668054 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 17:34:09.656295 => 17:34:09.667750
[0m17:34:09.668630 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 17:34:09.648970 => 17:34:09.668337
[0m17:34:09.669132 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 17:34:09.661632 => 17:34:09.668897
[0m17:34:09.669572 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m17:34:09.670018 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m17:34:09.670444 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m17:34:09.735717 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m17:34:09.737372 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:34:09.738219 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:34:09.739498 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:34:09.739729 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:34:09.739929 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m17:34:09.740217 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:34:09.740427 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:34:09.741915 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:34:09.742136 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:34:09.742355 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:34:09.742607 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:34:09.742818 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:34:09.744691 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:34:09.744913 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:34:09.745112 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:34:09.745363 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:34:09.745573 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:34:10.856615 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:10.857816 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:10.858549 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:10.859438 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:34:10.860250 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:34:10.861084 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:34:10.862074 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m17:34:10.863105 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m17:34:10.864672 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m17:34:13.419480 [debug] [Thread-3  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:34:13.424062 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:34:13.425641 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:34:13.426411 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:34:13.744216 [debug] [Thread-2  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:34:13.977540 [debug] [Thread-1  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:34:14.360271 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:14.363010 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:34:14.364366 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:34:14.494406 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:14.510198 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m17:34:14.519619 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:34:14.520069 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m17:34:14.778628 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:14.783278 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:34:14.785214 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:34:14.786615 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:34:15.617519 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:15.620166 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:34:15.621568 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:34:15.752208 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:15.760213 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:34:15.772143 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:34:15.773553 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:34:15.774412 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m17:34:15.775186 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:34:16.666439 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:16.667562 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:34:16.668245 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:34:16.798715 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:16.809882 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m17:34:16.812617 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:34:16.813847 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m17:34:16.896749 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:16.943236 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:34:16.943810 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:34:16.944126 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:34:17.075815 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:17.078915 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:34:17.079897 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:34:17.080523 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:34:18.483433 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:18.484831 [debug] [Thread-3  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:34:18.486566 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:34:18.488862 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:34:18.618824 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:18.626632 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:34:18.632284 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:34:18.633621 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:34:18.634658 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m17:34:18.635879 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:34:19.662728 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:19.664436 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:34:19.665305 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:34:19.794107 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:19.806492 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m17:34:19.809126 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:34:19.810122 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m17:34:19.898307 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:19.903718 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:34:19.904897 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:34:19.905582 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:34:20.071348 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:20.074497 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:34:20.075807 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:34:20.076607 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:34:21.502822 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:34:21.504999 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:21.508328 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:34:21.509796 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:34:21.640006 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:21.648887 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:34:21.656142 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:34:21.656936 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:34:21.657735 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m17:34:21.917557 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:21.930563 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m17:34:21.933339 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:34:21.934213 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m17:34:22.194013 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:22.199024 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:34:22.200728 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:34:22.202094 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:34:22.338565 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:22.340706 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:34:22.342023 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:34:22.472281 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:22.477222 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 17:34:09.701105 => 17:34:22.476317
[0m17:34:22.479592 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:34:22.481045 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m17:34:22.482211 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:34:22.566928 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:22.572318 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:34:22.573346 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:34:22.573945 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:34:22.743830 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m17:34:22.746104 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:22.755679 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a3ad719-41c7-48e9-ac95-28f2b76daccb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a331e80>]}
[0m17:34:22.761209 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m17:34:22.764012 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:34:22.766090 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m17:34:22.765370 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 13.11s]
[0m17:34:22.768193 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m17:34:23.024489 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:23.027921 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:34:23.029403 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:34:23.030630 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:34:23.567652 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:23.569421 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:34:23.570806 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:34:23.572134 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:23.703332 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:23.707292 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 17:34:09.670708 => 17:34:23.706490
[0m17:34:23.709031 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:34:23.710116 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m17:34:23.711188 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:34:23.971197 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:23.972065 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m17:34:23.977507 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m17:34:23.979493 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:34:23.980362 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m17:34:23.981636 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a3ad719-41c7-48e9-ac95-28f2b76daccb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a111910>]}
[0m17:34:23.982724 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 14.34s]
[0m17:34:23.983794 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m17:34:24.239965 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:24.242144 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:34:24.243236 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:34:24.244065 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:34:24.379583 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:24.381749 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:34:24.382784 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:34:24.513081 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:24.515096 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 17:34:09.682236 => 17:34:24.514690
[0m17:34:24.516037 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m17:34:24.774767 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m17:34:24.778669 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a3ad719-41c7-48e9-ac95-28f2b76daccb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1f71c0>]}
[0m17:34:24.781276 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 15.14s]
[0m17:34:24.783185 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m17:34:24.785175 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m17:34:24.786283 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m17:34:24.788013 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m17:34:24.788922 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m17:34:24.847900 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:34:24.848437 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:34:24.848790 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m17:34:24.849246 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:34:24.849563 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:34:25.959613 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:25.961963 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:34:25.963795 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m17:34:26.329038 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:26.335267 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m17:34:26.336289 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 17:34:24.789388 => 17:34:26.336049
[0m17:34:26.336667 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m17:34:26.341115 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m17:34:26.344164 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:34:26.344533 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        coalesce(cancelled.cancelled_flag, false) as cancelled_flag,
        datediff(minute,appointment_time_start,appointment_time_end) as appointment_lenght_minutes

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m17:34:27.593938 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:27.599229 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:34:27.600494 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:34:27.601363 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:34:28.768897 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:28.771673 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:34:28.772783 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:34:28.901797 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:28.904956 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m17:34:28.905933 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:34:28.906281 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m17:34:29.164873 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:29.166443 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:34:29.167242 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:34:29.167694 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:34:30.024565 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:30.026862 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:34:30.028182 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:34:30.158231 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:30.169678 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:34:30.170559 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m17:34:31.200870 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:31.205471 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:34:31.206764 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:34:31.207704 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:34:32.201542 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:32.203724 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:34:32.204652 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:34:32.463528 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:32.475663 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m17:34:32.479353 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:34:32.480429 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m17:34:32.741003 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:32.745816 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:34:32.747612 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:34:32.749211 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:34:32.885499 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:32.887676 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:34:32.888647 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:34:33.019442 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:33.023768 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 17:34:26.336878 => 17:34:33.022904
[0m17:34:33.025229 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m17:34:33.285365 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m17:34:33.289385 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a3ad719-41c7-48e9-ac95-28f2b76daccb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4bc2b0>]}
[0m17:34:33.290622 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 8.50s]
[0m17:34:33.291788 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m17:34:33.294486 [debug] [MainThread]: Using redshift connection "master"
[0m17:34:33.295166 [debug] [MainThread]: On master: BEGIN
[0m17:34:33.295663 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:34:33.296451 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:34:33.297002 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:34:34.390587 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:34:34.391183 [debug] [MainThread]: On master: COMMIT
[0m17:34:34.391609 [debug] [MainThread]: Using redshift connection "master"
[0m17:34:34.391895 [debug] [MainThread]: On master: COMMIT
[0m17:34:34.649233 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:34:34.650916 [debug] [MainThread]: On master: Close
[0m17:34:34.653684 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:34:34.655171 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m17:34:34.656221 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m17:34:34.657074 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m17:34:34.657967 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m17:34:34.658949 [info ] [MainThread]: 
[0m17:34:34.659892 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 30.22 seconds (30.22s).
[0m17:34:34.662949 [debug] [MainThread]: Command end result
[0m17:34:34.683894 [info ] [MainThread]: 
[0m17:34:34.685016 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:34:34.686061 [info ] [MainThread]: 
[0m17:34:34.686648 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m17:34:34.689803 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 30.609177, "process_user_time": 2.533222, "process_kernel_time": 0.289984, "process_mem_max_rss": "128385024", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m17:34:34.690695 [debug] [MainThread]: Command `dbt run` succeeded at 17:34:34.690521 after 30.61 seconds
[0m17:34:34.691201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106efd910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a64d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a111c10>]}
[0m17:34:34.691959 [debug] [MainThread]: Flushing usage events
[0m17:37:48.779807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104afe8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bf2e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c1b700>]}


============================== 17:37:48.782403 | 4c27452f-60b3-428b-95d7-2f5b35f2a83d ==============================
[0m17:37:48.782403 [info ] [MainThread]: Running with dbt=1.7.1
[0m17:37:48.782747 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'version_check': 'True', 'profiles_dir': '/Users/annaantypenko/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'send_anonymous_usage_stats': 'True'}
[0m17:37:48.956290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4c27452f-60b3-428b-95d7-2f5b35f2a83d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bf2e20>]}
[0m17:37:49.004144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4c27452f-60b3-428b-95d7-2f5b35f2a83d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076477c0>]}
[0m17:37:49.004670 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m17:37:49.014673 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m17:37:49.050569 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:37:49.050854 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:37:49.051309 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m17:37:49.055349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4c27452f-60b3-428b-95d7-2f5b35f2a83d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d090d0>]}
[0m17:37:49.092662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4c27452f-60b3-428b-95d7-2f5b35f2a83d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107749ee0>]}
[0m17:37:49.092993 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m17:37:49.093206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4c27452f-60b3-428b-95d7-2f5b35f2a83d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10764fe80>]}
[0m17:37:49.094052 [info ] [MainThread]: 
[0m17:37:49.094528 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:37:49.095230 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:37:49.105812 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:37:49.106352 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:37:49.106555 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:37:49.108269 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:37:49.108472 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:37:49.108651 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:37:49.110553 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:37:49.110751 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:37:49.110938 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:37:49.111154 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:37:49.112119 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:37:50.391167 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:37:50.392273 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:37:50.395671 [debug] [ThreadPool]: On list_prod: Close
[0m17:37:50.398688 [debug] [ThreadPool]: On list_prod: Close
[0m17:37:50.402783 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m17:37:50.404093 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m17:37:50.423309 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:37:50.423831 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:37:50.424213 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m17:37:50.424597 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m17:37:50.424957 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:37:50.425311 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:37:50.425871 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:37:50.426362 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:37:50.426780 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:37:50.427150 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:37:51.554026 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:37:51.555740 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:37:51.556647 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:37:51.557368 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:37:51.558004 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m17:37:51.558694 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m17:37:51.835825 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:37:51.839612 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m17:37:51.840238 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:37:51.842387 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m17:37:52.106072 [debug] [ThreadPool]: On list_prod_public: Close
[0m17:37:52.107842 [debug] [ThreadPool]: On list_prod_staging: Close
[0m17:37:52.127089 [debug] [MainThread]: Using redshift connection "master"
[0m17:37:52.127824 [debug] [MainThread]: On master: BEGIN
[0m17:37:52.128255 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:37:52.128942 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:37:52.129396 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:37:53.248484 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:37:53.249030 [debug] [MainThread]: Using redshift connection "master"
[0m17:37:53.249435 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m17:37:53.550849 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:37:53.556740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4c27452f-60b3-428b-95d7-2f5b35f2a83d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10764fe80>]}
[0m17:37:53.558632 [debug] [MainThread]: On master: ROLLBACK
[0m17:37:53.832019 [debug] [MainThread]: Using redshift connection "master"
[0m17:37:53.833640 [debug] [MainThread]: On master: BEGIN
[0m17:37:53.963561 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:37:53.965196 [debug] [MainThread]: On master: COMMIT
[0m17:37:53.966715 [debug] [MainThread]: Using redshift connection "master"
[0m17:37:53.967871 [debug] [MainThread]: On master: COMMIT
[0m17:37:54.228297 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:37:54.230201 [debug] [MainThread]: On master: Close
[0m17:37:54.233968 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m17:37:54.234974 [info ] [MainThread]: 
[0m17:37:54.240961 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m17:37:54.241909 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m17:37:54.242633 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m17:37:54.243446 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m17:37:54.244620 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m17:37:54.245544 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m17:37:54.246954 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_added_event)
[0m17:37:54.248402 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_deleted_event)
[0m17:37:54.249746 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m17:37:54.250471 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m17:37:54.251135 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m17:37:54.251721 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m17:37:54.257635 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m17:37:54.262924 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:37:54.267346 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:37:54.268784 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 17:37:54.252042 => 17:37:54.268429
[0m17:37:54.269306 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m17:37:54.269912 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 17:37:54.258182 => 17:37:54.269594
[0m17:37:54.270425 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 17:37:54.263268 => 17:37:54.270179
[0m17:37:54.283503 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m17:37:54.308847 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m17:37:54.316904 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m17:37:54.320220 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:37:54.323248 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:37:54.324832 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:37:54.326211 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:37:54.326434 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:37:54.327478 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:37:54.327704 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:37:54.327923 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m17:37:54.328143 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:37:54.328347 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:37:54.328654 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:37:54.328865 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:37:54.329112 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:37:54.329333 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:37:54.329579 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:37:54.329791 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:37:54.330487 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:37:55.453361 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:37:55.455591 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:37:55.456632 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:37:55.457511 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:37:55.458487 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:37:55.459322 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:37:55.460460 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m17:37:55.461755 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m17:37:55.462579 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m17:37:58.042867 [debug] [Thread-1  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:37:58.049050 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:37:58.050505 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:37:58.051658 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:37:58.239850 [debug] [Thread-2  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:37:58.241859 [debug] [Thread-3  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:37:59.024869 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:37:59.027764 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:37:59.029186 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:37:59.161409 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:37:59.182573 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m17:37:59.189848 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:37:59.190450 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m17:37:59.451656 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:37:59.454075 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:37:59.454983 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:37:59.455604 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:38:00.179036 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:38:00.181456 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:38:00.182785 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:38:00.312172 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:00.320108 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:38:00.326379 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:38:00.329396 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:38:00.329910 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:38:00.330477 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m17:38:01.162457 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:38:01.164472 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:38:01.165799 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:38:01.295660 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:01.307042 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m17:38:01.308825 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:38:01.309356 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m17:38:01.403109 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:38:01.438763 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:38:01.439404 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:38:01.439978 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:38:01.572417 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:01.576267 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:38:01.577585 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:38:01.578334 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:38:02.952778 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:38:02.954490 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:38:02.956602 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:38:02.957396 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:38:03.088592 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:03.096825 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:38:03.100512 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:38:03.101224 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:38:03.101950 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m17:38:03.102615 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:38:04.243796 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:38:04.245850 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:38:04.247118 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:38:04.378334 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:04.386985 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m17:38:04.388871 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:38:04.389527 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m17:38:04.482654 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:38:04.490945 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:38:04.491822 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:38:04.492628 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:38:04.652694 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:04.657080 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:38:04.658775 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:38:04.660095 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:38:06.113730 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:38:06.115643 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:38:06.118222 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:38:06.119274 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:38:06.251096 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:06.260745 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:38:06.263560 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:38:06.264085 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:38:06.264627 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m17:38:06.528273 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:06.537722 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m17:38:06.539478 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:38:06.540017 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m17:38:06.798292 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:06.802160 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:38:06.802962 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:38:06.803798 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:38:06.940569 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:06.942632 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:38:06.943931 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:38:07.074760 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:07.077446 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 17:37:54.270673 => 17:38:07.077004
[0m17:38:07.078418 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:38:07.079344 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m17:38:07.080205 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:38:07.177933 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:38:07.185100 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:38:07.186152 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:38:07.187037 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:38:07.338051 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m17:38:07.339759 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:07.347758 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c27452f-60b3-428b-95d7-2f5b35f2a83d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074e6af0>]}
[0m17:38:07.349579 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m17:38:07.350587 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 13.10s]
[0m17:38:07.352315 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:38:07.353282 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m17:38:07.353926 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m17:38:07.614906 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:07.619964 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:38:07.621477 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:38:07.622323 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:38:08.089289 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:08.091682 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:38:08.093060 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:38:08.094119 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:38:08.226327 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:08.231357 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 17:37:54.317092 => 17:38:08.230521
[0m17:38:08.233029 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:38:08.234085 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m17:38:08.235176 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:38:08.495060 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m17:38:08.496194 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c27452f-60b3-428b-95d7-2f5b35f2a83d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10764fe80>]}
[0m17:38:08.496718 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:08.497351 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 14.25s]
[0m17:38:08.500682 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m17:38:08.501305 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m17:38:08.502328 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:38:08.502873 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m17:38:08.763935 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:08.768961 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:38:08.770786 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:38:08.772108 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:38:08.908184 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:08.909957 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:38:08.911227 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:38:09.044182 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:09.049402 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 17:37:54.320396 => 17:38:09.048542
[0m17:38:09.050749 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m17:38:09.315242 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m17:38:09.320065 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c27452f-60b3-428b-95d7-2f5b35f2a83d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107df7f10>]}
[0m17:38:09.321978 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 15.07s]
[0m17:38:09.323341 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m17:38:09.325472 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m17:38:09.326921 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m17:38:09.328721 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m17:38:09.329409 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m17:38:09.381265 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:38:09.381715 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:38:09.382029 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m17:38:09.382474 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:38:09.382784 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:38:10.496612 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:38:10.498905 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:38:10.501159 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m17:38:10.870851 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:10.883578 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m17:38:10.885172 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 17:38:09.329804 => 17:38:10.884753
[0m17:38:10.885844 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m17:38:10.894438 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m17:38:10.899661 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:38:10.900308 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        coalesce(cancelled.cancelled_flag, false) as cancelled_flag,
        datediff(minute,appointment_time_start,appointment_time_end) as appointment_lenght_minutes

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m17:38:11.558314 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:38:11.563887 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:38:11.565490 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:38:11.566779 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:38:12.848997 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:38:12.851768 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:38:12.853080 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:38:12.984779 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:12.996997 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m17:38:12.998766 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:38:12.999329 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m17:38:13.259420 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:13.264371 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:38:13.266046 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:38:13.267303 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:38:14.261654 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:38:14.264366 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:38:14.265385 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:38:14.395425 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:14.406132 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:38:14.407020 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m17:38:15.437612 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:38:15.447457 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:38:15.448454 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:38:15.449087 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:38:16.310689 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:38:16.314208 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:38:16.315540 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:38:16.576193 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:16.591620 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m17:38:16.595370 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:38:16.595908 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m17:38:16.856309 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:16.860717 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:38:16.862326 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:38:16.863598 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:38:17.000038 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:17.001930 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:38:17.002872 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:38:17.132570 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:17.137554 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 17:38:10.886234 => 17:38:17.136676
[0m17:38:17.139004 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m17:38:17.398989 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m17:38:17.403752 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c27452f-60b3-428b-95d7-2f5b35f2a83d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108094af0>]}
[0m17:38:17.405703 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 8.08s]
[0m17:38:17.407563 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m17:38:17.410525 [debug] [MainThread]: Using redshift connection "master"
[0m17:38:17.411113 [debug] [MainThread]: On master: BEGIN
[0m17:38:17.411616 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:38:17.412360 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:38:17.412911 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:38:18.505038 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:38:18.505424 [debug] [MainThread]: On master: COMMIT
[0m17:38:18.505755 [debug] [MainThread]: Using redshift connection "master"
[0m17:38:18.506005 [debug] [MainThread]: On master: COMMIT
[0m17:38:18.764389 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:38:18.766094 [debug] [MainThread]: On master: Close
[0m17:38:18.769558 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:38:18.770387 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m17:38:18.771133 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m17:38:18.771827 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m17:38:18.772402 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m17:38:18.773270 [info ] [MainThread]: 
[0m17:38:18.774330 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 29.68 seconds (29.68s).
[0m17:38:18.776310 [debug] [MainThread]: Command end result
[0m17:38:18.797708 [info ] [MainThread]: 
[0m17:38:18.798304 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:38:18.798717 [info ] [MainThread]: 
[0m17:38:18.799257 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m17:38:18.801562 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 30.053917, "process_user_time": 2.574067, "process_kernel_time": 0.267237, "process_mem_max_rss": "128466944", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m17:38:18.802295 [debug] [MainThread]: Command `dbt run` succeeded at 17:38:18.802148 after 30.05 seconds
[0m17:38:18.802761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104afe8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e02940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076477c0>]}
[0m17:38:18.803217 [debug] [MainThread]: Flushing usage events
[0m17:39:16.969121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107070c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109164e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10918b700>]}


============================== 17:39:16.971417 | 75408f54-fae4-4b66-a972-138d30abc712 ==============================
[0m17:39:16.971417 [info ] [MainThread]: Running with dbt=1.7.1
[0m17:39:16.971763 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:39:17.135767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '75408f54-fae4-4b66-a972-138d30abc712', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109164e20>]}
[0m17:39:17.184248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '75408f54-fae4-4b66-a972-138d30abc712', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10913edf0>]}
[0m17:39:17.184771 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m17:39:17.193203 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m17:39:17.221482 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:39:17.221733 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:39:17.222106 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m17:39:17.225827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '75408f54-fae4-4b66-a972-138d30abc712', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2780d0>]}
[0m17:39:17.259875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '75408f54-fae4-4b66-a972-138d30abc712', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109cb9d90>]}
[0m17:39:17.260211 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m17:39:17.260422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '75408f54-fae4-4b66-a972-138d30abc712', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109cb91f0>]}
[0m17:39:17.261263 [info ] [MainThread]: 
[0m17:39:17.261758 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:39:17.262453 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:39:17.272181 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:39:17.272393 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:39:17.272568 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:39:17.274410 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:39:17.274619 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:39:17.275757 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:39:17.277378 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:39:17.277589 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:39:17.277765 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:39:17.277990 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:39:17.278178 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:39:18.593080 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:18.594868 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:18.600951 [debug] [ThreadPool]: On list_prod: Close
[0m17:39:18.605359 [debug] [ThreadPool]: On list_prod: Close
[0m17:39:18.611522 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m17:39:18.613005 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m17:39:18.636199 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:39:18.641222 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:39:18.641610 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m17:39:18.641985 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m17:39:18.642336 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:39:18.642672 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:39:18.643229 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:39:18.643705 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:39:18.644096 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:39:18.644455 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:39:19.775360 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:19.777357 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:19.778615 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:39:19.779846 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:39:19.781072 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m17:39:19.782366 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m17:39:20.064316 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:20.066021 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:20.071785 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m17:39:20.075270 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m17:39:20.347421 [debug] [ThreadPool]: On list_prod_public: Close
[0m17:39:20.349311 [debug] [ThreadPool]: On list_prod_staging: Close
[0m17:39:20.377940 [debug] [MainThread]: Using redshift connection "master"
[0m17:39:20.378728 [debug] [MainThread]: On master: BEGIN
[0m17:39:20.379267 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:39:20.380055 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:39:20.380626 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:39:21.500017 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:21.502253 [debug] [MainThread]: Using redshift connection "master"
[0m17:39:21.503683 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m17:39:21.805472 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:21.810204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '75408f54-fae4-4b66-a972-138d30abc712', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a35f8e0>]}
[0m17:39:21.811956 [debug] [MainThread]: On master: ROLLBACK
[0m17:39:22.086813 [debug] [MainThread]: Using redshift connection "master"
[0m17:39:22.087740 [debug] [MainThread]: On master: BEGIN
[0m17:39:22.218761 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:22.220180 [debug] [MainThread]: On master: COMMIT
[0m17:39:22.221229 [debug] [MainThread]: Using redshift connection "master"
[0m17:39:22.221896 [debug] [MainThread]: On master: COMMIT
[0m17:39:22.482788 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:22.484304 [debug] [MainThread]: On master: Close
[0m17:39:22.486963 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m17:39:22.487747 [info ] [MainThread]: 
[0m17:39:22.491092 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m17:39:22.491862 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m17:39:22.492723 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m17:39:22.493875 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m17:39:22.494809 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m17:39:22.495740 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m17:39:22.497523 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_added_event)
[0m17:39:22.499248 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_deleted_event)
[0m17:39:22.500942 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m17:39:22.501659 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m17:39:22.502331 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m17:39:22.502969 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m17:39:22.509262 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m17:39:22.512898 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:39:22.515666 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:39:22.516465 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 17:39:22.509598 => 17:39:22.516258
[0m17:39:22.516843 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 17:39:22.503343 => 17:39:22.516641
[0m17:39:22.517150 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 17:39:22.513191 => 17:39:22.517002
[0m17:39:22.517422 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m17:39:22.518053 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m17:39:22.518846 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m17:39:22.586698 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:39:22.588236 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m17:39:22.588531 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:39:22.589889 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:39:22.590110 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:39:22.590310 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:39:22.590599 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:39:22.590813 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:39:22.592243 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:39:22.592465 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:39:22.592662 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m17:39:22.592910 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:39:22.593119 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:39:22.595185 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:39:22.595418 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:39:22.595618 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:39:22.595868 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:39:22.596075 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:39:23.720078 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:23.721017 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:23.721786 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:23.722442 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:39:23.723137 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:39:23.723902 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:39:23.724726 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m17:39:23.725528 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m17:39:23.726314 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m17:39:25.588725 [debug] [Thread-3  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:39:25.593613 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:39:25.595188 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:39:25.596418 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:39:25.969200 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:39:26.587956 [debug] [Thread-1  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:39:26.615299 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:26.615712 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:39:26.615941 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:39:26.744918 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:26.759431 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m17:39:26.764169 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:39:26.764548 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m17:39:27.026291 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:27.030040 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:39:27.031594 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:39:27.032656 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:39:27.959486 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:27.960754 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:39:27.961390 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:39:28.090774 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:28.098069 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:39:28.106173 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:39:28.107614 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:39:28.108319 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:39:28.109219 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m17:39:29.047338 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:29.048368 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:39:29.048993 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:39:29.179055 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:29.189356 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m17:39:29.191384 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:39:29.192323 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m17:39:29.262501 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:29.308356 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:39:29.309089 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:39:29.309551 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:39:29.451997 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:29.454698 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:39:29.455800 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:39:29.456733 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:39:30.977678 [debug] [Thread-3  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:39:30.979671 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:39:30.982870 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:39:30.984304 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:39:31.115821 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:31.124220 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:39:31.132178 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:39:31.133233 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:39:31.134055 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m17:39:31.134909 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:39:32.035562 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:32.038298 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:39:32.039739 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:39:32.170274 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:32.188309 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m17:39:32.191521 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:39:32.192341 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m17:39:32.266432 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:32.276572 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:39:32.278377 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:39:32.279706 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:39:32.452806 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:32.457504 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:39:32.459316 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:39:32.460671 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:39:34.083269 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:39:34.085086 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:39:34.087941 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:39:34.089291 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:39:34.220548 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:34.229567 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:39:34.237883 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:39:34.238948 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:39:34.239788 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m17:39:34.499259 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:34.511750 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m17:39:34.514619 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:39:34.515458 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m17:39:34.776368 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:34.781285 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:39:34.783100 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:39:34.784400 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:39:34.923070 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:34.925729 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:39:34.927120 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:39:35.058656 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:35.063882 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 17:39:22.575625 => 17:39:35.062982
[0m17:39:35.065834 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:39:35.067295 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m17:39:35.068736 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:39:35.144084 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:35.154275 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:39:35.156168 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:39:35.157485 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:39:35.329193 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:35.331381 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m17:39:35.341234 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m17:39:35.343589 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75408f54-fae4-4b66-a972-138d30abc712', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4aca90>]}
[0m17:39:35.346045 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:39:35.348230 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m17:39:35.347550 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 12.84s]
[0m17:39:35.350523 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m17:39:35.609416 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:35.614187 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:39:35.616132 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:39:35.617418 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:39:36.305271 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:36.307293 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:36.310548 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:39:36.311902 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:39:36.442313 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:36.443135 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 17:39:22.519061 => 17:39:36.442983
[0m17:39:36.443492 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:39:36.443788 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m17:39:36.444055 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:39:36.703225 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m17:39:36.705081 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:36.714363 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75408f54-fae4-4b66-a972-138d30abc712', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c88a60>]}
[0m17:39:36.720256 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m17:39:36.724636 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:39:36.721958 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 14.22s]
[0m17:39:36.725609 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m17:39:36.726666 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m17:39:36.987354 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:36.991577 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:39:36.993368 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:39:36.994663 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:39:37.130727 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:37.132888 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:39:37.134323 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:39:37.266368 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:37.271141 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 17:39:22.531746 => 17:39:37.270327
[0m17:39:37.272541 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m17:39:37.532536 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m17:39:37.537347 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75408f54-fae4-4b66-a972-138d30abc712', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a366100>]}
[0m17:39:37.539773 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 15.04s]
[0m17:39:37.542273 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m17:39:37.545286 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m17:39:37.547134 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m17:39:37.549705 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m17:39:37.550929 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m17:39:37.611929 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:39:37.612304 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:39:37.612589 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m17:39:37.612986 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:39:37.613285 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:39:38.729974 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:38.731193 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:39:38.732349 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m17:39:39.102108 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:39.113303 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m17:39:39.114640 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 17:39:37.551538 => 17:39:39.114316
[0m17:39:39.115122 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m17:39:39.121905 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m17:39:39.125863 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:39:39.126325 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        coalesce(cancelled.cancelled_flag, false) as cancelled_flag,
        datediff(minute,appointment_time_start,appointment_time_end) as appointment_lenght_minutes

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m17:39:39.907802 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:39.912675 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:39:39.913761 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:39:39.914409 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:39:40.810331 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:40.813047 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:39:40.814423 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:39:40.946772 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:40.960819 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m17:39:40.964498 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:39:40.965597 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m17:39:41.228554 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:41.233601 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:39:41.235483 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:39:41.236869 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:39:41.999539 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:42.002199 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:39:42.003531 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:39:42.135723 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:42.149253 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:39:42.150227 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m17:39:43.187524 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:43.197319 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:39:43.199163 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:39:43.200488 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:39:44.210559 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:44.214255 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:39:44.215568 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:39:44.477533 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:44.493553 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m17:39:44.496629 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:39:44.497543 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m17:39:44.760212 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:44.763151 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:39:44.764161 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:39:44.765069 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:39:44.902895 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:44.905504 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:39:44.907090 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:39:45.041024 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:45.046098 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 17:39:39.115403 => 17:39:45.045268
[0m17:39:45.047571 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m17:39:45.309063 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m17:39:45.313818 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75408f54-fae4-4b66-a972-138d30abc712', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a366100>]}
[0m17:39:45.316028 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 7.77s]
[0m17:39:45.320507 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m17:39:45.325402 [debug] [MainThread]: Using redshift connection "master"
[0m17:39:45.326427 [debug] [MainThread]: On master: BEGIN
[0m17:39:45.327222 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:39:45.328620 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:39:45.329379 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:39:46.427750 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:39:46.428306 [debug] [MainThread]: On master: COMMIT
[0m17:39:46.428740 [debug] [MainThread]: Using redshift connection "master"
[0m17:39:46.429057 [debug] [MainThread]: On master: COMMIT
[0m17:39:46.687772 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:39:46.689160 [debug] [MainThread]: On master: Close
[0m17:39:46.691290 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:39:46.691843 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m17:39:46.692330 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m17:39:46.692786 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m17:39:46.693246 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m17:39:46.693958 [info ] [MainThread]: 
[0m17:39:46.694613 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 29.43 seconds (29.43s).
[0m17:39:46.698984 [debug] [MainThread]: Command end result
[0m17:39:46.724276 [info ] [MainThread]: 
[0m17:39:46.725134 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:39:46.725712 [info ] [MainThread]: 
[0m17:39:46.726514 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m17:39:46.729085 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 29.79124, "process_user_time": 2.691433, "process_kernel_time": 0.276111, "process_mem_max_rss": "129155072", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m17:39:46.729873 [debug] [MainThread]: Command `dbt run` succeeded at 17:39:46.729700 after 29.79 seconds
[0m17:39:46.730395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107070c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109cc6be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6a2190>]}
[0m17:39:46.730940 [debug] [MainThread]: Flushing usage events
[0m17:40:28.115368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104345940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106447be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10646d520>]}


============================== 17:40:28.117768 | 9b098a68-2d67-4c18-847e-96edf0843743 ==============================
[0m17:40:28.117768 [info ] [MainThread]: Running with dbt=1.7.1
[0m17:40:28.118110 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:40:28.279195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9b098a68-2d67-4c18-847e-96edf0843743', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106447be0>]}
[0m17:40:28.327197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9b098a68-2d67-4c18-847e-96edf0843743', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e8b490>]}
[0m17:40:28.327634 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m17:40:28.336286 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m17:40:28.366615 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:40:28.366843 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:40:28.367222 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m17:40:28.370798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9b098a68-2d67-4c18-847e-96edf0843743', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10754d0d0>]}
[0m17:40:28.404001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9b098a68-2d67-4c18-847e-96edf0843743', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ee84c0>]}
[0m17:40:28.404305 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m17:40:28.404510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b098a68-2d67-4c18-847e-96edf0843743', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106eef130>]}
[0m17:40:28.405416 [info ] [MainThread]: 
[0m17:40:28.405917 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:40:28.406671 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:40:28.416553 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:40:28.416781 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:40:28.416964 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:40:28.418839 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:40:28.419049 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:40:28.420152 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:40:28.421720 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:40:28.421922 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:40:28.422094 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:40:28.422315 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:40:28.422493 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:40:29.639576 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:29.640759 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:29.643500 [debug] [ThreadPool]: On list_prod: Close
[0m17:40:29.645695 [debug] [ThreadPool]: On list_prod: Close
[0m17:40:29.652408 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m17:40:29.654395 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m17:40:29.671336 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:40:29.679029 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:40:29.679521 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m17:40:29.679974 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m17:40:29.680396 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:40:29.680782 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:40:29.681336 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:40:29.681822 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:40:29.682206 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:40:29.682575 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:40:30.815954 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:30.818012 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:30.819206 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:40:30.820486 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:40:30.821762 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m17:40:30.823227 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m17:40:31.106567 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:31.108348 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:31.114129 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m17:40:31.118186 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m17:40:31.388052 [debug] [ThreadPool]: On list_prod_staging: Close
[0m17:40:31.390041 [debug] [ThreadPool]: On list_prod_public: Close
[0m17:40:31.416381 [debug] [MainThread]: Using redshift connection "master"
[0m17:40:31.417237 [debug] [MainThread]: On master: BEGIN
[0m17:40:31.417765 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:40:31.418567 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:40:31.419104 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:40:32.543995 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:32.544736 [debug] [MainThread]: Using redshift connection "master"
[0m17:40:32.545447 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m17:40:32.851413 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:32.856590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b098a68-2d67-4c18-847e-96edf0843743', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10762d6d0>]}
[0m17:40:32.858702 [debug] [MainThread]: On master: ROLLBACK
[0m17:40:33.133959 [debug] [MainThread]: Using redshift connection "master"
[0m17:40:33.135818 [debug] [MainThread]: On master: BEGIN
[0m17:40:33.266812 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:33.268649 [debug] [MainThread]: On master: COMMIT
[0m17:40:33.270261 [debug] [MainThread]: Using redshift connection "master"
[0m17:40:33.271347 [debug] [MainThread]: On master: COMMIT
[0m17:40:33.533815 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:33.535918 [debug] [MainThread]: On master: Close
[0m17:40:33.539717 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m17:40:33.541018 [info ] [MainThread]: 
[0m17:40:33.547484 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m17:40:33.549326 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m17:40:33.550337 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m17:40:33.551464 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m17:40:33.552679 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m17:40:33.553919 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m17:40:33.555814 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_added_event)
[0m17:40:33.557055 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_deleted_event)
[0m17:40:33.558792 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m17:40:33.559769 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m17:40:33.560588 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m17:40:33.561358 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m17:40:33.568665 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m17:40:33.574010 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:40:33.579054 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:40:33.580253 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 17:40:33.574394 => 17:40:33.579916
[0m17:40:33.580824 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 17:40:33.569084 => 17:40:33.580557
[0m17:40:33.581296 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 17:40:33.561849 => 17:40:33.581068
[0m17:40:33.581715 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m17:40:33.582154 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m17:40:33.582563 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m17:40:33.643438 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:40:33.644742 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:40:33.646361 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m17:40:33.647588 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:40:33.647816 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:40:33.648918 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:40:33.649922 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:40:33.650124 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m17:40:33.650347 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:40:33.650575 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:40:33.650875 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:40:33.651084 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:40:33.651286 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:40:33.651504 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:40:33.651761 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:40:33.652001 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:40:33.652771 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:40:33.653013 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:40:34.769377 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:34.771754 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:34.773199 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:40:34.774542 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:34.775659 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:40:34.776859 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m17:40:34.777935 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:40:34.779050 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m17:40:34.780477 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m17:40:37.049144 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:40:37.055638 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:40:37.057143 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:40:37.058132 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:40:37.195161 [debug] [Thread-3  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:40:37.438448 [debug] [Thread-2  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:40:38.073295 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:38.075985 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:40:38.077332 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:40:38.210043 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:38.237136 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m17:40:38.247989 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:40:38.248874 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m17:40:38.512076 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:38.516452 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:40:38.518117 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:40:38.519388 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:40:39.669963 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:39.672471 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:40:39.673801 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:40:39.804469 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:39.813319 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:40:39.820760 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:40:39.828801 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:40:39.829734 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:40:39.830643 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m17:40:40.724578 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:40.727278 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:40:40.728691 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:40:40.859671 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:40.869832 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m17:40:40.872509 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:40:40.873465 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m17:40:40.953240 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:40.989111 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:40:40.989523 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:40:40.990103 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:40:41.135149 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:41.137034 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:40:41.137775 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:40:41.138356 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:40:42.742645 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:40:42.743429 [debug] [Thread-3  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:40:42.744624 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:40:42.745220 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:40:42.874811 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:42.881245 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:40:42.881828 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:40:42.882604 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:40:42.883216 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m17:40:42.883850 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:40:44.022117 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:44.024023 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:40:44.025354 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:40:44.155935 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:44.165025 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m17:40:44.167765 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:40:44.169388 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m17:40:44.255535 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:44.261084 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:40:44.262267 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:40:44.262865 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:40:44.430498 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:44.434476 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:40:44.435948 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:40:44.436952 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:40:45.741558 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:45.742962 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:45.744555 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:40:45.746690 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:40:45.877410 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:45.884569 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:40:45.886721 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:40:45.887707 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:40:45.888643 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m17:40:46.150764 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:46.159092 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m17:40:46.162365 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:40:46.163334 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m17:40:46.429826 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:46.433391 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:40:46.434827 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:40:46.435586 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:40:46.572700 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:46.574387 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:40:46.575027 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:40:46.705450 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:46.708853 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 17:40:33.614187 => 17:40:46.708119
[0m17:40:46.710389 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:40:46.711644 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m17:40:46.712664 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:40:46.792227 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:46.797661 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:40:46.798576 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:40:46.799568 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:40:46.973072 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m17:40:46.974735 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:46.984694 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m17:40:46.986130 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b098a68-2d67-4c18-847e-96edf0843743', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107816c70>]}
[0m17:40:46.987905 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:40:46.989398 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m17:40:46.988873 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 13.43s]
[0m17:40:46.990969 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m17:40:47.250956 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:47.252957 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:40:47.254085 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:40:47.254678 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:40:47.618123 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:47.618955 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:47.619710 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:40:47.620692 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:40:47.751093 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:47.752957 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 17:40:33.582831 => 17:40:47.752595
[0m17:40:47.753965 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:40:47.755231 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m17:40:47.756509 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:40:48.015814 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m17:40:48.017474 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:48.022835 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m17:40:48.024728 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:40:48.026128 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b098a68-2d67-4c18-847e-96edf0843743', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10763c2b0>]}
[0m17:40:48.026786 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m17:40:48.027841 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 14.47s]
[0m17:40:48.029173 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m17:40:48.286971 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:48.290229 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:40:48.291596 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:40:48.292385 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:40:48.427802 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:48.429602 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:40:48.430246 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:40:48.560419 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:48.563481 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 17:40:33.601676 => 17:40:48.563071
[0m17:40:48.564366 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m17:40:48.823473 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m17:40:48.825931 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b098a68-2d67-4c18-847e-96edf0843743', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107645730>]}
[0m17:40:48.827518 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 15.27s]
[0m17:40:48.829355 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m17:40:48.830846 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m17:40:48.831711 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m17:40:48.833408 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m17:40:48.834591 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m17:40:48.875844 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:40:48.876285 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:40:48.876541 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m17:40:48.876885 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:40:48.877115 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:40:50.058849 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:50.060965 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:40:50.062937 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m17:40:50.436814 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:50.450772 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m17:40:50.453062 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 17:40:48.835010 => 17:40:50.452548
[0m17:40:50.453943 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m17:40:50.466342 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m17:40:50.472629 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:40:50.473298 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        coalesce(cancelled.cancelled_flag, false) as cancelled_flag,
        datediff(minute,appointment_time_start,appointment_time_end) as appointment_lenght_minutes

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m17:40:51.344344 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:51.349906 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:40:51.351080 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:40:51.351971 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:40:52.325960 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:52.327588 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:40:52.328883 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:40:52.459871 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:52.471581 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m17:40:52.475713 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:40:52.476978 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m17:40:52.738615 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:52.740470 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:40:52.741252 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:40:52.741848 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:40:53.555473 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:53.558159 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:40:53.559482 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:40:53.690424 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:53.700699 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:40:53.702517 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m17:40:54.732445 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:54.739306 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:40:54.740954 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:40:54.742030 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:40:55.643640 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:55.647170 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:40:55.648870 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:40:55.910059 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:55.926884 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m17:40:55.930042 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:40:55.931140 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m17:40:56.191353 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:56.196195 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:40:56.198504 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:40:56.199898 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:40:56.337236 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:56.339519 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:40:56.340500 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:40:56.472073 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:56.475894 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 17:40:50.454609 => 17:40:56.475284
[0m17:40:56.477185 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m17:40:56.737543 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m17:40:56.740488 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b098a68-2d67-4c18-847e-96edf0843743', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079a4ca0>]}
[0m17:40:56.742653 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 7.91s]
[0m17:40:56.744807 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m17:40:56.748934 [debug] [MainThread]: Using redshift connection "master"
[0m17:40:56.749715 [debug] [MainThread]: On master: BEGIN
[0m17:40:56.750274 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:40:56.751292 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:40:56.752122 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:40:57.857094 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:40:57.858845 [debug] [MainThread]: On master: COMMIT
[0m17:40:57.860064 [debug] [MainThread]: Using redshift connection "master"
[0m17:40:57.860956 [debug] [MainThread]: On master: COMMIT
[0m17:40:58.119394 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:40:58.119804 [debug] [MainThread]: On master: Close
[0m17:40:58.120615 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:40:58.120897 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m17:40:58.121164 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m17:40:58.121425 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m17:40:58.121672 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m17:40:58.121975 [info ] [MainThread]: 
[0m17:40:58.122293 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 29.72 seconds (29.72s).
[0m17:40:58.123216 [debug] [MainThread]: Command end result
[0m17:40:58.132264 [info ] [MainThread]: 
[0m17:40:58.132583 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:40:58.132900 [info ] [MainThread]: 
[0m17:40:58.133225 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m17:40:58.134614 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 30.052032, "process_user_time": 2.602105, "process_kernel_time": 0.280783, "process_mem_max_rss": "129138688", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m17:40:58.135067 [debug] [MainThread]: Command `dbt run` succeeded at 17:40:58.134967 after 30.05 seconds
[0m17:40:58.135361 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104345940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106eb3790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e8b490>]}
[0m17:40:58.135656 [debug] [MainThread]: Flushing usage events
[0m17:43:38.517720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104301670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10640f160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10641b310>]}


============================== 17:43:38.520141 | c31b4e05-46b9-4e93-97c6-8049c05bfffd ==============================
[0m17:43:38.520141 [info ] [MainThread]: Running with dbt=1.7.1
[0m17:43:38.520746 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'debug': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:43:38.685722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c31b4e05-46b9-4e93-97c6-8049c05bfffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10640f160>]}
[0m17:43:38.733139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c31b4e05-46b9-4e93-97c6-8049c05bfffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c909d0>]}
[0m17:43:38.734000 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m17:43:38.744512 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m17:43:38.774914 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:43:38.775187 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:43:38.775592 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m17:43:38.779232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c31b4e05-46b9-4e93-97c6-8049c05bfffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075090d0>]}
[0m17:43:38.816798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c31b4e05-46b9-4e93-97c6-8049c05bfffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f49820>]}
[0m17:43:38.817138 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m17:43:38.817345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c31b4e05-46b9-4e93-97c6-8049c05bfffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f493d0>]}
[0m17:43:38.818189 [info ] [MainThread]: 
[0m17:43:38.818667 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:43:38.819349 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:43:38.829725 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:43:38.829989 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:43:38.830452 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:43:38.830649 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:43:38.832335 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:43:38.834262 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:43:38.834470 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:43:38.834659 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:43:38.834827 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:43:38.835916 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:43:38.836116 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:43:40.118520 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:40.120754 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:40.125718 [debug] [ThreadPool]: On list_prod: Close
[0m17:43:40.127916 [debug] [ThreadPool]: On list_prod: Close
[0m17:43:40.132722 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m17:43:40.140425 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m17:43:40.147056 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:43:40.154044 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:43:40.154441 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m17:43:40.154824 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m17:43:40.155181 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:43:40.155531 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:43:40.156087 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:43:40.156562 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:43:40.156952 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:43:40.157322 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:43:41.287048 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:41.288999 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:41.290135 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:43:41.291324 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:43:41.292600 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m17:43:41.293646 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m17:43:41.571680 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:41.573518 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:41.577697 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m17:43:41.580876 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m17:43:41.847913 [debug] [ThreadPool]: On list_prod_public: Close
[0m17:43:41.849547 [debug] [ThreadPool]: On list_prod_staging: Close
[0m17:43:41.872384 [debug] [MainThread]: Using redshift connection "master"
[0m17:43:41.872956 [debug] [MainThread]: On master: BEGIN
[0m17:43:41.873407 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:43:41.874068 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:43:41.874527 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:43:42.998284 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:43.000037 [debug] [MainThread]: Using redshift connection "master"
[0m17:43:43.001333 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m17:43:43.307109 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:43.313093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c31b4e05-46b9-4e93-97c6-8049c05bfffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075f1970>]}
[0m17:43:43.314908 [debug] [MainThread]: On master: ROLLBACK
[0m17:43:43.589691 [debug] [MainThread]: Using redshift connection "master"
[0m17:43:43.591754 [debug] [MainThread]: On master: BEGIN
[0m17:43:43.723257 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:43.725353 [debug] [MainThread]: On master: COMMIT
[0m17:43:43.726994 [debug] [MainThread]: Using redshift connection "master"
[0m17:43:43.727907 [debug] [MainThread]: On master: COMMIT
[0m17:43:43.990623 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:43.991703 [debug] [MainThread]: On master: Close
[0m17:43:43.993331 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m17:43:43.993949 [info ] [MainThread]: 
[0m17:43:43.998083 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m17:43:43.998995 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m17:43:43.999648 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m17:43:44.000418 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m17:43:44.001308 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m17:43:44.002130 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m17:43:44.003432 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_added_event)
[0m17:43:44.004783 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_deleted_event)
[0m17:43:44.006029 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m17:43:44.006674 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m17:43:44.007287 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m17:43:44.007877 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m17:43:44.013790 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m17:43:44.019204 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:43:44.024208 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:43:44.025391 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 17:43:44.008254 => 17:43:44.025093
[0m17:43:44.026001 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 17:43:44.014287 => 17:43:44.025679
[0m17:43:44.026472 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m17:43:44.026994 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 17:43:44.019626 => 17:43:44.026733
[0m17:43:44.027561 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m17:43:44.047082 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m17:43:44.083741 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:43:44.084193 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m17:43:44.087224 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:43:44.088662 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:43:44.089939 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:43:44.090165 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:43:44.091207 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:43:44.091427 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:43:44.091635 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:43:44.091839 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:43:44.092034 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:43:44.092333 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:43:44.092542 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m17:43:44.092790 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:43:44.093005 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:43:44.093248 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:43:44.093460 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:43:44.094177 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:43:45.217317 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:45.219161 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:45.220143 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:45.221090 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:43:45.221889 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:43:45.222660 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:43:45.224168 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m17:43:45.225210 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m17:43:45.226188 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m17:43:47.316181 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:43:47.322931 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:43:47.324823 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:43:47.326199 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:43:47.573207 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:43:47.685499 [debug] [Thread-3  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:43:48.324428 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:48.327054 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:43:48.328055 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:43:48.459187 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:48.478042 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m17:43:48.485248 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:43:48.485822 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m17:43:48.748993 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:48.752848 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:43:48.754056 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:43:48.755315 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:43:49.628492 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:49.629662 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:43:49.630286 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:43:49.759747 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:49.766804 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:43:49.768307 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:43:49.768583 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:43:49.768822 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m17:43:49.769036 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:43:50.903066 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:50.905453 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:43:50.906227 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:43:51.037908 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:51.047510 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m17:43:51.049063 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:43:51.049607 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m17:43:51.144267 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:51.181305 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:43:51.182092 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:43:51.182555 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:43:51.313867 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:51.317480 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:43:51.318645 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:43:51.319559 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:43:52.620552 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:52.621803 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:52.623615 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:43:52.624422 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:43:52.757524 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:52.765239 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:43:52.766965 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:43:52.768196 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:43:52.768980 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m17:43:52.769602 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:43:53.740068 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:53.742305 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:43:53.743656 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:43:53.874267 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:53.883487 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m17:43:53.885422 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:43:53.886093 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m17:43:53.998520 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:54.004461 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:43:54.005394 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:43:54.005987 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:43:54.146427 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:54.150545 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:43:54.151888 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:43:54.152803 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:43:55.501667 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:55.503500 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:55.505538 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:43:55.507765 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:43:55.638648 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:55.648045 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:43:55.652299 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:43:55.652995 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:43:55.653645 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m17:43:55.915432 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:55.924245 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m17:43:55.926065 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:43:55.926704 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m17:43:56.187825 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:56.192100 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:43:56.193689 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:43:56.194945 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:43:56.333892 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:56.336154 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:43:56.337450 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:43:56.468893 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:56.473022 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 17:43:44.027887 => 17:43:56.472183
[0m17:43:56.474345 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:43:56.475201 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m17:43:56.476256 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:43:56.556199 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:56.561292 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:43:56.562836 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:43:56.563909 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:43:56.737632 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m17:43:56.739716 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:56.748646 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c31b4e05-46b9-4e93-97c6-8049c05bfffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10774cd60>]}
[0m17:43:56.750846 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m17:43:56.753397 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:43:56.751804 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 12.75s]
[0m17:43:56.754219 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m17:43:56.755132 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m17:43:57.017493 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:57.021980 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:43:57.023489 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:43:57.024478 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:43:57.592438 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:57.594490 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:43:57.596961 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:43:57.598127 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:43:57.730496 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:57.735134 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 17:43:44.065711 => 17:43:57.734294
[0m17:43:57.736657 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:43:57.737362 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m17:43:57.738243 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:43:57.999976 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:58.001494 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m17:43:58.009572 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m17:43:58.011792 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:43:58.013115 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c31b4e05-46b9-4e93-97c6-8049c05bfffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076013d0>]}
[0m17:43:58.013788 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m17:43:58.014753 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 14.01s]
[0m17:43:58.015791 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m17:43:58.275692 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:58.279373 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:43:58.280592 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:43:58.281244 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:43:58.417274 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:58.420045 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:43:58.421348 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:43:58.552455 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:43:58.557692 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 17:43:44.084334 => 17:43:58.556846
[0m17:43:58.558807 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m17:43:58.817984 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m17:43:58.822687 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c31b4e05-46b9-4e93-97c6-8049c05bfffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10779be20>]}
[0m17:43:58.824611 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 14.82s]
[0m17:43:58.826400 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m17:43:58.827863 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m17:43:58.828816 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m17:43:58.830299 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m17:43:58.830969 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m17:43:58.881463 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:43:58.882012 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:43:58.882541 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m17:43:58.883141 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:43:58.883509 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:44:00.002694 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:44:00.005740 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:44:00.007646 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m17:44:00.381648 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:44:00.391987 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m17:44:00.394970 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 17:43:58.831356 => 17:44:00.394555
[0m17:44:00.395656 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m17:44:00.403576 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m17:44:00.408582 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:44:00.409177 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        coalesce(cancelled.cancelled_flag, false) as cancelled_flag,
        datediff(minute,appointment_time_start,appointment_time_end) as appointment_lenght_minutes

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m17:44:01.255457 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:44:01.260730 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:44:01.262313 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:44:01.263575 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:44:02.421542 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:44:02.424034 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:44:02.425307 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:44:02.556870 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:44:02.565348 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m17:44:02.567440 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:44:02.568132 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m17:44:02.829050 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:44:02.830050 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:44:02.830444 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:44:02.830743 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:44:03.692514 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:44:03.695343 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:44:03.696632 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:44:03.828505 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:44:03.839269 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:44:03.840139 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m17:44:04.872587 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:44:04.882155 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:44:04.882993 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:44:04.883570 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:44:05.820214 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:44:05.822842 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:44:05.823638 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:44:06.084223 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:44:06.097640 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m17:44:06.099422 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:44:06.100085 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m17:44:06.359400 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:44:06.363686 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:44:06.365248 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:44:06.366493 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:44:06.503712 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:44:06.505711 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:44:06.506598 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:44:06.637286 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:44:06.641620 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 17:44:00.396053 => 17:44:06.640773
[0m17:44:06.643107 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m17:44:06.904642 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m17:44:06.908688 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c31b4e05-46b9-4e93-97c6-8049c05bfffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10795bd30>]}
[0m17:44:06.910371 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 8.08s]
[0m17:44:06.912148 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m17:44:06.914975 [debug] [MainThread]: Using redshift connection "master"
[0m17:44:06.915666 [debug] [MainThread]: On master: BEGIN
[0m17:44:06.916197 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:44:06.916994 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:44:06.917553 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:44:08.019843 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:44:08.020228 [debug] [MainThread]: On master: COMMIT
[0m17:44:08.020556 [debug] [MainThread]: Using redshift connection "master"
[0m17:44:08.020804 [debug] [MainThread]: On master: COMMIT
[0m17:44:08.280647 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:44:08.282282 [debug] [MainThread]: On master: Close
[0m17:44:08.285756 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:44:08.286578 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m17:44:08.287305 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m17:44:08.288026 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m17:44:08.288750 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m17:44:08.289740 [info ] [MainThread]: 
[0m17:44:08.290661 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 29.47 seconds (29.47s).
[0m17:44:08.292592 [debug] [MainThread]: Command end result
[0m17:44:08.311760 [info ] [MainThread]: 
[0m17:44:08.312331 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:44:08.312741 [info ] [MainThread]: 
[0m17:44:08.313258 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m17:44:08.315652 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 29.831335, "process_user_time": 2.568655, "process_kernel_time": 0.26211, "process_mem_max_rss": "128860160", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m17:44:08.316349 [debug] [MainThread]: Command `dbt run` succeeded at 17:44:08.316200 after 29.83 seconds
[0m17:44:08.316803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104301670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e6bd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10779be20>]}
[0m17:44:08.317264 [debug] [MainThread]: Flushing usage events
[0m17:44:49.359196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064708e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11067ae20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106a3700>]}


============================== 17:44:49.361896 | 0ac862fd-005d-4820-a7c7-853306f1d932 ==============================
[0m17:44:49.361896 [info ] [MainThread]: Running with dbt=1.7.1
[0m17:44:49.362242 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'send_anonymous_usage_stats': 'True'}
[0m17:44:49.550470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0ac862fd-005d-4820-a7c7-853306f1d932', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11067ae20>]}
[0m17:44:49.600504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0ac862fd-005d-4820-a7c7-853306f1d932', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111bcb7c0>]}
[0m17:44:49.602030 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m17:44:49.611409 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m17:44:49.649210 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:44:49.649608 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:44:49.650047 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m17:44:49.654360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0ac862fd-005d-4820-a7c7-853306f1d932', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123cd0d0>]}
[0m17:44:49.695925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0ac862fd-005d-4820-a7c7-853306f1d932', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11215dee0>]}
[0m17:44:49.696257 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m17:44:49.696473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0ac862fd-005d-4820-a7c7-853306f1d932', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111bd3e80>]}
[0m17:44:49.697458 [info ] [MainThread]: 
[0m17:44:49.698139 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:44:49.699150 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:44:49.706059 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m17:44:49.710224 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:44:49.711902 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m17:44:49.712169 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:44:49.712381 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m17:44:49.712568 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:44:49.712741 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:44:49.714850 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:44:49.715168 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:44:49.715375 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:44:49.715791 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:44:50.944880 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:44:50.946749 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:44:50.951973 [debug] [ThreadPool]: On list_prod: Close
[0m17:44:50.954919 [debug] [ThreadPool]: On list_prod: Close
[0m17:44:50.960711 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m17:44:50.962588 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m17:44:50.985845 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:44:50.992897 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m17:44:50.992401 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:44:50.993565 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:44:50.993954 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m17:44:50.994484 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:44:50.994848 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:44:50.995242 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:44:50.995702 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:44:50.997843 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:44:52.142385 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:44:52.143279 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m17:44:52.143822 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m17:44:52.144408 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m17:44:52.144992 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m17:44:52.145640 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m17:44:52.426882 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:44:52.428779 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m17:44:52.434342 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m17:44:52.437685 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m17:44:52.703261 [debug] [ThreadPool]: On list_prod_staging: Close
[0m17:44:52.711046 [debug] [ThreadPool]: On list_prod_public: Close
[0m17:44:52.733699 [debug] [MainThread]: Using redshift connection "master"
[0m17:44:52.734069 [debug] [MainThread]: On master: BEGIN
[0m17:44:52.734304 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:44:52.734662 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:44:52.734919 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:44:53.850084 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:44:53.851125 [debug] [MainThread]: Using redshift connection "master"
[0m17:44:53.851816 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m17:44:54.157565 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:44:54.161174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0ac862fd-005d-4820-a7c7-853306f1d932', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111bd3e80>]}
[0m17:44:54.162380 [debug] [MainThread]: On master: ROLLBACK
[0m17:44:54.438740 [debug] [MainThread]: Using redshift connection "master"
[0m17:44:54.440678 [debug] [MainThread]: On master: BEGIN
[0m17:44:54.572870 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:44:54.574863 [debug] [MainThread]: On master: COMMIT
[0m17:44:54.576409 [debug] [MainThread]: Using redshift connection "master"
[0m17:44:54.577524 [debug] [MainThread]: On master: COMMIT
[0m17:44:54.841167 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:44:54.843254 [debug] [MainThread]: On master: Close
[0m17:44:54.846838 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m17:44:54.848323 [info ] [MainThread]: 
[0m17:44:54.854730 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m17:44:54.856678 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m17:44:54.857663 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m17:44:54.858832 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m17:44:54.860021 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m17:44:54.861126 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m17:44:54.863259 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_added_event)
[0m17:44:54.865176 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_deleted_event)
[0m17:44:54.867569 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m17:44:54.868427 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m17:44:54.869061 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m17:44:54.869797 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m17:44:54.878694 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m17:44:54.884300 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:44:54.889415 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:44:54.890917 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 17:44:54.879142 => 17:44:54.890572
[0m17:44:54.891634 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 17:44:54.870826 => 17:44:54.891247
[0m17:44:54.892259 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 17:44:54.884689 => 17:44:54.891954
[0m17:44:54.892823 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m17:44:54.893388 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m17:44:54.893814 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m17:44:54.952863 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m17:44:54.956706 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m17:44:54.957145 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m17:44:54.958411 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:44:54.958632 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:44:54.958839 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m17:44:54.959130 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:44:54.959339 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:44:54.960838 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:44:54.961060 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:44:54.962226 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:44:54.962425 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:44:54.962656 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:44:54.962937 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:44:54.963164 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:44:54.963388 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:44:54.963675 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:44:54.964368 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:44:56.075808 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:44:56.077900 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:44:56.079462 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:44:56.080948 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:44:56.082503 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m17:44:56.085892 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m17:44:56.087674 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:44:56.089179 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:44:56.090271 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m17:44:58.385017 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:44:58.390954 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:44:58.392391 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:44:58.393333 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:44:58.713902 [debug] [Thread-2  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:44:58.897789 [debug] [Thread-3  ]: SQL status: SUCCESS in 3.0 seconds
[0m17:44:59.264426 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:44:59.266797 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:44:59.268167 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:44:59.400672 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:44:59.415718 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m17:44:59.425538 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:44:59.426045 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m17:44:59.685610 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:44:59.687423 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:44:59.688156 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:44:59.688738 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:45:00.504496 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:45:00.507129 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:45:00.508721 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:45:00.639476 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:00.647656 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:45:00.660526 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:45:00.662804 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:45:00.663792 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:45:00.665019 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m17:45:01.583982 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:45:01.586677 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:45:01.587995 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:45:01.720476 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:01.734617 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m17:45:01.737555 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:45:01.738380 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m17:45:01.821541 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:45:01.871362 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:45:01.872287 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:45:01.872763 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:45:02.004109 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:02.009079 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:45:02.010877 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:45:02.012388 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:45:03.495847 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:45:03.497983 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:45:03.501250 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:45:03.502640 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:45:03.636552 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:03.645087 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:45:03.653459 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:45:03.654364 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:45:03.655171 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m17:45:03.655976 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:45:04.600866 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:45:04.603986 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:45:04.605460 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:45:04.735836 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:04.751197 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m17:45:04.754726 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:45:04.755729 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m17:45:04.859930 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:45:04.870042 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:45:04.871949 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:45:04.873275 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:45:05.017228 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:05.022085 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:45:05.023911 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:45:05.025243 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:45:06.444994 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m17:45:06.447211 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:45:06.450587 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:45:06.451926 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:45:06.582547 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:06.592490 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:45:06.599681 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:45:06.600437 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:45:06.601084 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m17:45:06.861803 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:06.877137 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m17:45:06.881004 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:45:06.882054 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m17:45:07.141831 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:07.147035 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:45:07.148897 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:45:07.150235 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m17:45:07.289174 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:07.291843 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m17:45:07.293170 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m17:45:07.423784 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:07.429020 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 17:44:54.912608 => 17:45:07.428171
[0m17:45:07.431045 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:45:07.432565 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m17:45:07.433873 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:45:07.503468 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:45:07.513406 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:45:07.515153 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:45:07.516407 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:45:07.693135 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m17:45:07.694454 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:07.702688 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m17:45:07.704566 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ac862fd-005d-4820-a7c7-853306f1d932', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1125d9940>]}
[0m17:45:07.706647 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:45:07.707965 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 12.84s]
[0m17:45:07.708738 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m17:45:07.709999 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m17:45:07.972075 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:07.977139 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:45:07.978959 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:45:07.980240 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m17:45:08.336433 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:45:08.338520 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:08.341824 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m17:45:08.343285 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m17:45:08.475973 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:08.481063 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 17:44:54.894077 => 17:45:08.480130
[0m17:45:08.483025 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:45:08.484592 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m17:45:08.485975 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:45:08.745393 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:08.751171 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m17:45:08.751976 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m17:45:08.753804 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:45:08.754600 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m17:45:08.755914 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ac862fd-005d-4820-a7c7-853306f1d932', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114914e50>]}
[0m17:45:08.756758 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 13.89s]
[0m17:45:08.757799 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m17:45:09.014640 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:09.019882 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:45:09.021768 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:45:09.023082 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m17:45:09.159173 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:09.161924 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m17:45:09.163286 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m17:45:09.293191 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:09.298186 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 17:44:54.937049 => 17:45:09.297365
[0m17:45:09.299850 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m17:45:09.558886 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m17:45:09.563910 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ac862fd-005d-4820-a7c7-853306f1d932', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11215d7f0>]}
[0m17:45:09.566366 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 14.70s]
[0m17:45:09.568845 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m17:45:09.571677 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m17:45:09.573499 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m17:45:09.576175 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m17:45:09.577360 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m17:45:09.638802 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:45:09.639209 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:45:09.639499 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m17:45:09.639898 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:45:09.640197 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:45:10.841073 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:45:10.842975 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:45:10.844802 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m17:45:11.216108 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:11.234326 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m17:45:11.236780 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 17:45:09.577973 => 17:45:11.236158
[0m17:45:11.237871 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m17:45:11.252294 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m17:45:11.259247 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:45:11.260021 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        coalesce(cancelled.cancelled_flag, false) as cancelled_flag,
        datediff(minute,appointment_time_start,appointment_time_end) as appointment_lenght_minutes

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m17:45:12.341535 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:45:12.347283 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:45:12.349113 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:45:12.350429 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:45:13.283748 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:45:13.286148 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:45:13.287462 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:45:13.419160 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:13.434293 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m17:45:13.437433 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:45:13.438444 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m17:45:13.701224 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:13.705866 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:45:13.707603 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:45:13.708860 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:45:14.471779 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:45:14.474624 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:45:14.475963 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:45:14.607534 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:14.624173 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:45:14.625800 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m17:45:15.656331 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:45:15.665568 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:45:15.667061 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:45:15.668007 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:45:16.564307 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m17:45:16.567942 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:45:16.569394 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:45:16.831886 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:16.850194 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m17:45:16.853229 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:45:16.854060 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m17:45:17.114459 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:17.119411 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:45:17.121142 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:45:17.122428 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m17:45:17.260411 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:17.263184 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m17:45:17.264559 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m17:45:17.395937 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:17.400710 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 17:45:11.238477 => 17:45:17.399888
[0m17:45:17.402226 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m17:45:17.664527 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m17:45:17.669374 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ac862fd-005d-4820-a7c7-853306f1d932', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1125d34c0>]}
[0m17:45:17.671833 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 8.09s]
[0m17:45:17.674187 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m17:45:17.678420 [debug] [MainThread]: Using redshift connection "master"
[0m17:45:17.679214 [debug] [MainThread]: On master: BEGIN
[0m17:45:17.679846 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:45:17.680902 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m17:45:17.681576 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m17:45:18.792693 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m17:45:18.793152 [debug] [MainThread]: On master: COMMIT
[0m17:45:18.793500 [debug] [MainThread]: Using redshift connection "master"
[0m17:45:18.793749 [debug] [MainThread]: On master: COMMIT
[0m17:45:19.053534 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m17:45:19.055727 [debug] [MainThread]: On master: Close
[0m17:45:19.059383 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:45:19.060455 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m17:45:19.061516 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m17:45:19.062544 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m17:45:19.063507 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m17:45:19.064810 [info ] [MainThread]: 
[0m17:45:19.066258 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 29.37 seconds (29.37s).
[0m17:45:19.070654 [debug] [MainThread]: Command end result
[0m17:45:19.098743 [info ] [MainThread]: 
[0m17:45:19.099482 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:45:19.099993 [info ] [MainThread]: 
[0m17:45:19.100474 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m17:45:19.102912 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 29.7781, "process_user_time": 2.789638, "process_kernel_time": 0.309607, "process_mem_max_rss": "129351680", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m17:45:19.103655 [debug] [MainThread]: Command `dbt run` succeeded at 17:45:19.103483 after 29.78 seconds
[0m17:45:19.104186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064708e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1125cd070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11215dee0>]}
[0m17:45:19.104739 [debug] [MainThread]: Flushing usage events
[0m23:29:57.004585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a42910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e7d9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e63bb0>]}


============================== 23:29:57.007378 | 32435598-9118-474d-ad1c-111d34650a3d ==============================
[0m23:29:57.007378 [info ] [MainThread]: Running with dbt=1.7.1
[0m23:29:57.007718 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:29:57.205589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '32435598-9118-474d-ad1c-111d34650a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e41b50>]}
[0m23:29:57.257729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '32435598-9118-474d-ad1c-111d34650a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8debe0>]}
[0m23:29:57.258395 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m23:29:57.267895 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m23:29:57.305614 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:29:57.306083 [debug] [MainThread]: Partial parsing: updated file: dbt_remote://models/acuity_scheduling/schema.yml
[0m23:29:57.508526 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m23:29:57.512189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '32435598-9118-474d-ad1c-111d34650a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b55b0d0>]}
[0m23:29:57.519284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '32435598-9118-474d-ad1c-111d34650a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b223910>]}
[0m23:29:57.519584 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m23:29:57.519789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '32435598-9118-474d-ad1c-111d34650a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2238e0>]}
[0m23:29:57.520633 [info ] [MainThread]: 
[0m23:29:57.521149 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m23:29:57.521905 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m23:29:57.528216 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m23:29:57.532850 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m23:29:57.534603 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m23:29:57.534818 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m23:29:57.535008 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m23:29:57.535205 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:29:57.535387 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:29:57.537374 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:29:57.537644 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:29:57.537850 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:29:57.538043 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:29:58.871376 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m23:29:58.872567 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m23:29:58.876757 [debug] [ThreadPool]: On list_prod: Close
[0m23:29:58.879020 [debug] [ThreadPool]: On list_prod: Close
[0m23:29:58.881147 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m23:29:58.881735 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m23:29:58.886880 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m23:29:58.892569 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m23:29:58.893051 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m23:29:58.893564 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m23:29:58.894047 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:29:58.894472 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:29:58.895075 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:29:58.895622 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:29:58.896088 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:29:58.896511 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:30:22.244931 [debug] [ThreadPool]: SQL status: SUCCESS in 23.0 seconds
[0m23:30:22.246320 [debug] [ThreadPool]: SQL status: SUCCESS in 23.0 seconds
[0m23:30:22.247159 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m23:30:22.247712 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m23:30:22.248316 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m23:30:22.249172 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m23:30:22.530905 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:22.535248 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m23:30:22.536774 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:22.539252 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m23:30:22.803402 [debug] [ThreadPool]: On list_prod_public: Close
[0m23:30:22.807678 [debug] [ThreadPool]: On list_prod_staging: Close
[0m23:30:22.831293 [debug] [MainThread]: Using redshift connection "master"
[0m23:30:22.831672 [debug] [MainThread]: On master: BEGIN
[0m23:30:22.831924 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:30:22.832399 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:30:22.832660 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:30:23.944591 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:23.945692 [debug] [MainThread]: Using redshift connection "master"
[0m23:30:23.946348 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m23:30:24.255174 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:24.261322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '32435598-9118-474d-ad1c-111d34650a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2236a0>]}
[0m23:30:24.263094 [debug] [MainThread]: On master: ROLLBACK
[0m23:30:24.536055 [debug] [MainThread]: Using redshift connection "master"
[0m23:30:24.537719 [debug] [MainThread]: On master: BEGIN
[0m23:30:24.669476 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:24.671603 [debug] [MainThread]: On master: COMMIT
[0m23:30:24.673198 [debug] [MainThread]: Using redshift connection "master"
[0m23:30:24.674289 [debug] [MainThread]: On master: COMMIT
[0m23:30:24.934735 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:24.936870 [debug] [MainThread]: On master: Close
[0m23:30:24.940679 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m23:30:24.941936 [info ] [MainThread]: 
[0m23:30:24.949440 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m23:30:24.950593 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m23:30:24.952272 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m23:30:24.953545 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m23:30:24.954846 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m23:30:24.956077 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m23:30:24.958097 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_added_event)
[0m23:30:24.959515 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_deleted_event)
[0m23:30:24.960801 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m23:30:24.961474 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m23:30:24.962128 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m23:30:24.962832 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m23:30:24.970879 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m23:30:24.976885 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m23:30:24.981905 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m23:30:24.984113 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 23:30:24.963257 => 23:30:24.983723
[0m23:30:24.984793 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 23:30:24.977285 => 23:30:24.984462
[0m23:30:24.985382 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 23:30:24.971372 => 23:30:24.985068
[0m23:30:24.985862 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m23:30:24.986343 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m23:30:24.986796 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m23:30:25.037210 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m23:30:25.038092 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m23:30:25.040911 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m23:30:25.042659 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m23:30:25.042916 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m23:30:25.044101 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m23:30:25.044347 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m23:30:25.044598 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m23:30:25.045658 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m23:30:25.045974 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:30:25.046198 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m23:30:25.046408 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m23:30:25.046621 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:30:25.046870 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:30:25.047072 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m23:30:25.047784 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:30:25.048062 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:30:25.048741 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:30:26.168419 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:26.169607 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:26.170215 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m23:30:26.170901 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m23:30:26.171648 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m23:30:26.172404 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:26.173044 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m23:30:26.182980 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m23:30:26.183940 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m23:30:28.518978 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m23:30:28.520417 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m23:30:28.524418 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m23:30:28.527494 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m23:30:28.528242 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m23:30:28.764009 [debug] [Thread-3  ]: SQL status: SUCCESS in 3.0 seconds
[0m23:30:29.424558 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:29.425988 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m23:30:29.427645 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m23:30:29.557319 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:29.575097 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m23:30:29.583625 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m23:30:29.584127 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m23:30:29.845069 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:29.849806 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m23:30:29.852983 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m23:30:29.855635 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m23:30:30.806416 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:30.807676 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m23:30:30.808682 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m23:30:30.966321 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:30.974453 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m23:30:30.979297 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m23:30:30.980124 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m23:30:30.980666 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m23:30:30.981082 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m23:30:31.893464 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:31.896427 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m23:30:31.897281 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m23:30:32.052214 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:32.059833 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m23:30:32.062952 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m23:30:32.063862 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m23:30:32.164886 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:32.213047 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m23:30:32.213877 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m23:30:32.214417 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m23:30:32.378018 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:32.380548 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m23:30:32.381519 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m23:30:32.382391 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m23:30:33.983682 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m23:30:33.987941 [debug] [Thread-2  ]: SQL status: SUCCESS in 2.0 seconds
[0m23:30:33.989139 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m23:30:33.990386 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m23:30:34.142357 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:34.150484 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m23:30:34.155736 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m23:30:34.156910 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m23:30:34.158864 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m23:30:34.160626 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m23:30:35.045717 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:35.048092 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m23:30:35.049588 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m23:30:35.212769 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:35.228001 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m23:30:35.231222 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m23:30:35.232391 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m23:30:35.347268 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:35.355958 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m23:30:35.358066 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m23:30:35.359640 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m23:30:35.538331 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:35.548615 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m23:30:35.550227 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m23:30:35.550838 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m23:30:36.847140 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:36.848135 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:36.849640 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m23:30:36.850285 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m23:30:37.005495 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:37.013803 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m23:30:37.020873 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m23:30:37.021883 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m23:30:37.022633 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m23:30:37.331900 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:37.340043 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m23:30:37.342679 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m23:30:37.343737 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m23:30:37.626808 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:37.629234 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m23:30:37.630979 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m23:30:37.632326 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m23:30:37.770755 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:37.772659 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m23:30:37.773933 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m23:30:37.908812 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:37.911493 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 23:30:25.038233 => 23:30:37.911071
[0m23:30:37.912461 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m23:30:37.913247 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m23:30:37.913987 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m23:30:38.020729 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:38.030377 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m23:30:38.032324 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m23:30:38.033278 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m23:30:38.202668 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m23:30:38.204702 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:38.217219 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '32435598-9118-474d-ad1c-111d34650a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb06f10>]}
[0m23:30:38.224582 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m23:30:38.227584 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m23:30:38.230270 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m23:30:38.229370 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 13.26s]
[0m23:30:38.232107 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m23:30:38.490687 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:38.494791 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m23:30:38.496827 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m23:30:38.498117 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m23:30:39.017741 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:39.019247 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m23:30:39.020372 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m23:30:39.021044 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:39.152934 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:39.157611 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 23:30:24.987080 => 23:30:39.156823
[0m23:30:39.159630 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m23:30:39.161377 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m23:30:39.163006 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m23:30:39.423732 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m23:30:39.425707 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '32435598-9118-474d-ad1c-111d34650a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b223550>]}
[0m23:30:39.426445 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:39.427480 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 14.47s]
[0m23:30:39.432733 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m23:30:39.433695 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m23:30:39.435311 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m23:30:39.435985 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m23:30:39.696837 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:39.700957 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m23:30:39.702601 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m23:30:39.703855 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m23:30:39.843452 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:39.847171 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m23:30:39.848102 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m23:30:39.979771 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:39.984160 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 23:30:25.013427 => 23:30:39.983355
[0m23:30:39.985933 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m23:30:40.250155 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m23:30:40.255082 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '32435598-9118-474d-ad1c-111d34650a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5d3df0>]}
[0m23:30:40.257389 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 15.29s]
[0m23:30:40.260259 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m23:30:40.263355 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m23:30:40.265490 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m23:30:40.268137 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m23:30:40.269246 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m23:30:40.314380 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m23:30:40.314941 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m23:30:40.315334 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m23:30:40.315898 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:30:40.316290 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:30:41.438253 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:41.440283 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m23:30:41.442491 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m23:30:41.840703 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:41.858527 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m23:30:41.861380 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 23:30:40.269851 => 23:30:41.860713
[0m23:30:41.862263 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m23:30:41.876624 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m23:30:41.882521 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m23:30:41.883172 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        coalesce(cancelled.cancelled_flag, false) as cancelled_flag,
        datediff(minute,appointment_time_start,appointment_time_end) as appointment_lenght_minutes

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m23:30:42.633082 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:42.639455 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m23:30:42.641532 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m23:30:42.643003 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m23:30:46.817743 [debug] [Thread-4  ]: SQL status: SUCCESS in 4.0 seconds
[0m23:30:46.819838 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m23:30:46.820809 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m23:30:46.951401 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:46.967451 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m23:30:46.970454 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m23:30:46.971331 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m23:30:47.234842 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:47.239705 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m23:30:47.241636 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m23:30:47.243072 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m23:30:48.087790 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:48.090066 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m23:30:48.091551 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m23:30:48.224601 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:48.238130 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m23:30:48.239586 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m23:30:49.273297 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:49.283529 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m23:30:49.285420 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m23:30:49.286382 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m23:30:50.092565 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:50.096267 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m23:30:50.097790 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m23:30:50.360803 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:50.374923 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m23:30:50.377930 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m23:30:50.378926 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m23:30:50.639699 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:50.644353 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m23:30:50.646318 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m23:30:50.647682 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m23:30:50.786863 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:50.789492 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m23:30:50.790799 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m23:30:50.921730 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:50.924675 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 23:30:41.862743 => 23:30:50.924180
[0m23:30:50.925514 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m23:30:51.187216 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m23:30:51.191950 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '32435598-9118-474d-ad1c-111d34650a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5f4be0>]}
[0m23:30:51.194588 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 10.92s]
[0m23:30:51.197136 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m23:30:51.202017 [debug] [MainThread]: Using redshift connection "master"
[0m23:30:51.202875 [debug] [MainThread]: On master: BEGIN
[0m23:30:51.203490 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:30:51.204655 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:30:51.205360 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:30:52.312063 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m23:30:52.312436 [debug] [MainThread]: On master: COMMIT
[0m23:30:52.312761 [debug] [MainThread]: Using redshift connection "master"
[0m23:30:52.313009 [debug] [MainThread]: On master: COMMIT
[0m23:30:52.573167 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:30:52.574813 [debug] [MainThread]: On master: Close
[0m23:30:52.577940 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:30:52.579217 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m23:30:52.580227 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m23:30:52.580959 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m23:30:52.581680 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m23:30:52.582708 [info ] [MainThread]: 
[0m23:30:52.583664 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 55.06 seconds (55.06s).
[0m23:30:52.586904 [debug] [MainThread]: Command end result
[0m23:30:52.612556 [info ] [MainThread]: 
[0m23:30:52.613206 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:30:52.613676 [info ] [MainThread]: 
[0m23:30:52.614148 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m23:30:52.616723 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 55.646805, "process_user_time": 2.808363, "process_kernel_time": 0.308974, "process_mem_max_rss": "134987776", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m23:30:52.617448 [debug] [MainThread]: Command `dbt run` succeeded at 23:30:52.617278 after 55.65 seconds
[0m23:30:52.617949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a42910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be65610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa66220>]}
[0m23:30:52.618473 [debug] [MainThread]: Flushing usage events
[0m01:46:41.585426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065d9c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086cae50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086f3670>]}


============================== 01:46:41.588300 | dff0a1ae-e577-4fa0-8506-bf163b740cda ==============================
[0m01:46:41.588300 [info ] [MainThread]: Running with dbt=1.7.1
[0m01:46:41.588687 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/annaantypenko/Desktop/Code/publishing-dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/annaantypenko/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run -s +fact_apointment_schedule', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m01:46:41.773498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dff0a1ae-e577-4fa0-8506-bf163b740cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086cae50>]}
[0m01:46:41.821554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dff0a1ae-e577-4fa0-8506-bf163b740cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f8cc10>]}
[0m01:46:41.822234 [info ] [MainThread]: Registered adapter: redshift=1.7.0
[0m01:46:41.831467 [debug] [MainThread]: checksum: ad428e6dc3b353dcb23d0c4ebea8b20b180e94b873271ac2a054a8e446dac0e2, vars: {}, profile: , target: , version: 1.7.1
[0m01:46:41.870980 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:46:41.871253 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:46:41.871648 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_remote.example
[0m01:46:41.875318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dff0a1ae-e577-4fa0-8506-bf163b740cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097e10d0>]}
[0m01:46:41.916276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dff0a1ae-e577-4fa0-8506-bf163b740cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10922eeb0>]}
[0m01:46:41.916642 [info ] [MainThread]: Found 4 models, 2 tests, 3 sources, 0 exposures, 0 metrics, 570 macros, 0 groups, 0 semantic models
[0m01:46:41.916859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dff0a1ae-e577-4fa0-8506-bf163b740cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091d5e20>]}
[0m01:46:41.917735 [info ] [MainThread]: 
[0m01:46:41.918225 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:46:41.918928 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m01:46:41.928902 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m01:46:41.929134 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m01:46:41.929322 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:46:41.931263 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:46:41.931492 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:46:41.932812 [debug] [ThreadPool]: Acquiring new redshift connection 'list_prod'
[0m01:46:41.935057 [debug] [ThreadPool]: Using redshift connection "list_prod"
[0m01:46:41.935497 [debug] [ThreadPool]: On list_prod: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod"} */

    select distinct nspname from pg_namespace
[0m01:46:41.935720 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:46:41.936044 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:46:41.936239 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:46:43.676155 [debug] [ThreadPool]: SQL status: SUCCESS in 2.0 seconds
[0m01:46:43.677252 [debug] [ThreadPool]: SQL status: SUCCESS in 2.0 seconds
[0m01:46:43.679856 [debug] [ThreadPool]: On list_prod: Close
[0m01:46:43.682139 [debug] [ThreadPool]: On list_prod: Close
[0m01:46:43.687107 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_staging)
[0m01:46:43.694746 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_prod, now list_prod_public)
[0m01:46:43.708380 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m01:46:43.701339 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m01:46:43.709013 [debug] [ThreadPool]: On list_prod_public: BEGIN
[0m01:46:43.709392 [debug] [ThreadPool]: On list_prod_staging: BEGIN
[0m01:46:43.709747 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:46:43.710090 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:46:43.710633 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:46:43.711092 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:46:43.711465 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:46:43.711827 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:46:44.885939 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m01:46:44.887416 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m01:46:44.888130 [debug] [ThreadPool]: Using redshift connection "list_prod_public"
[0m01:46:44.889183 [debug] [ThreadPool]: Using redshift connection "list_prod_staging"
[0m01:46:44.890237 [debug] [ThreadPool]: On list_prod_public: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_public"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'public'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'public'
[0m01:46:44.891031 [debug] [ThreadPool]: On list_prod_staging: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "list_prod_staging"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'staging'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'staging'
[0m01:46:45.172913 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:45.173643 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:45.175464 [debug] [ThreadPool]: On list_prod_public: ROLLBACK
[0m01:46:45.177133 [debug] [ThreadPool]: On list_prod_staging: ROLLBACK
[0m01:46:45.444078 [debug] [ThreadPool]: On list_prod_public: Close
[0m01:46:45.446397 [debug] [ThreadPool]: On list_prod_staging: Close
[0m01:46:45.461312 [debug] [MainThread]: Using redshift connection "master"
[0m01:46:45.461931 [debug] [MainThread]: On master: BEGIN
[0m01:46:45.462350 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:46:45.462941 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:46:45.463415 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:46:46.560357 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m01:46:46.561176 [debug] [MainThread]: Using redshift connection "master"
[0m01:46:46.561874 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m01:46:46.865852 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:46.870309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dff0a1ae-e577-4fa0-8506-bf163b740cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086f3670>]}
[0m01:46:46.871643 [debug] [MainThread]: On master: ROLLBACK
[0m01:46:47.145332 [debug] [MainThread]: Using redshift connection "master"
[0m01:46:47.147143 [debug] [MainThread]: On master: BEGIN
[0m01:46:47.276422 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:47.277388 [debug] [MainThread]: On master: COMMIT
[0m01:46:47.278158 [debug] [MainThread]: Using redshift connection "master"
[0m01:46:47.278719 [debug] [MainThread]: On master: COMMIT
[0m01:46:47.538481 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:47.539326 [debug] [MainThread]: On master: Close
[0m01:46:47.540860 [info ] [MainThread]: Concurrency: 4 threads (target='prod')
[0m01:46:47.541478 [info ] [MainThread]: 
[0m01:46:47.545961 [debug] [Thread-1  ]: Began running node model.dbt_remote.stg_appointment_added_event
[0m01:46:47.547136 [debug] [Thread-2  ]: Began running node model.dbt_remote.stg_appointment_deleted_event
[0m01:46:47.547853 [debug] [Thread-3  ]: Began running node model.dbt_remote.stg_appointment_edited_event
[0m01:46:47.548650 [info ] [Thread-1  ]: 1 of 4 START sql table model staging.stg_appointment_added_event ............... [RUN]
[0m01:46:47.549531 [info ] [Thread-2  ]: 2 of 4 START sql table model staging.stg_appointment_deleted_event ............. [RUN]
[0m01:46:47.550230 [info ] [Thread-3  ]: 3 of 4 START sql table model staging.stg_appointment_edited_event .............. [RUN]
[0m01:46:47.551709 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_prod_staging, now model.dbt_remote.stg_appointment_added_event)
[0m01:46:47.552836 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list_prod_public, now model.dbt_remote.stg_appointment_deleted_event)
[0m01:46:47.553963 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.dbt_remote.stg_appointment_edited_event'
[0m01:46:47.554559 [debug] [Thread-1  ]: Began compiling node model.dbt_remote.stg_appointment_added_event
[0m01:46:47.555077 [debug] [Thread-2  ]: Began compiling node model.dbt_remote.stg_appointment_deleted_event
[0m01:46:47.555573 [debug] [Thread-3  ]: Began compiling node model.dbt_remote.stg_appointment_edited_event
[0m01:46:47.561129 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_added_event"
[0m01:46:47.566216 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_deleted_event"
[0m01:46:47.571007 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_remote.stg_appointment_edited_event"
[0m01:46:47.572895 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (compile): 01:46:47.561580 => 01:46:47.572565
[0m01:46:47.573416 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (compile): 01:46:47.555896 => 01:46:47.573171
[0m01:46:47.573850 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (compile): 01:46:47.566696 => 01:46:47.573634
[0m01:46:47.574229 [debug] [Thread-2  ]: Began executing node model.dbt_remote.stg_appointment_deleted_event
[0m01:46:47.574655 [debug] [Thread-1  ]: Began executing node model.dbt_remote.stg_appointment_added_event
[0m01:46:47.575026 [debug] [Thread-3  ]: Began executing node model.dbt_remote.stg_appointment_edited_event
[0m01:46:47.642023 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_edited_event"
[0m01:46:47.643389 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_deleted_event"
[0m01:46:47.644471 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_remote.stg_appointment_added_event"
[0m01:46:47.645864 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m01:46:47.646958 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m01:46:47.647169 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m01:46:47.647394 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m01:46:47.648538 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m01:46:47.648731 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m01:46:47.648946 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m01:46:47.649168 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m01:46:47.649467 [debug] [Thread-3  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:46:47.649731 [debug] [Thread-2  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:46:47.649930 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:46:47.650144 [debug] [Thread-3  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:46:47.650352 [debug] [Thread-2  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:46:47.650595 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:46:47.651876 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:46:48.766901 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:46:48.769211 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:46:48.770645 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:46:48.771860 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m01:46:48.772679 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m01:46:48.773492 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m01:46:48.774322 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_deleted_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_deleted_event"
  );
[0m01:46:48.775097 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_edited_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date,
    appointment_time_start::time,
    appointment_time_end::time,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_edited_event"
  );
[0m01:46:48.776384 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */

  
    

  create  table
    "prod"."staging"."stg_appointment_added_event__dbt_tmp"
    
    diststyle even
    
  as (
    
select
    appointment_id,
    first_name,
    last_name,
    email,
    appointment_date::date as appointment_date,
    appointment_time_start::time as appointment_time_start,
    appointment_time_end::time as appointment_time_end,
    appointment_type,
    calendar_name,
    appointment_created_at::timestamp as appointment_created_at,
    timestamp 'epoch' + cast(ingested_at AS bigint) * interval '1 second' as ingested_at_timestamp
from "prod"."raw"."appointment_added_event"
  );
[0m01:46:51.177593 [debug] [Thread-3  ]: SQL status: SUCCESS in 2.0 seconds
[0m01:46:51.179645 [debug] [Thread-1  ]: SQL status: SUCCESS in 2.0 seconds
[0m01:46:51.184759 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m01:46:51.188614 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m01:46:51.189297 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m01:46:51.458943 [debug] [Thread-2  ]: SQL status: SUCCESS in 3.0 seconds
[0m01:46:52.116963 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:46:52.118282 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m01:46:52.118917 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m01:46:52.249733 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:52.264303 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event"
[0m01:46:52.272196 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m01:46:52.273011 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event" cascade
[0m01:46:52.535104 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:52.538281 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m01:46:52.539459 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m01:46:52.540194 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m01:46:53.246778 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:46:53.248983 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m01:46:53.250266 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m01:46:53.382063 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:53.390146 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m01:46:53.397537 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m01:46:53.399155 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m01:46:53.399785 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m01:46:53.400430 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
alter table "prod"."staging"."stg_appointment_edited_event__dbt_tmp" rename to "stg_appointment_edited_event"
[0m01:46:54.285442 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:46:54.287386 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m01:46:54.288678 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m01:46:54.420035 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:54.431791 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event"
[0m01:46:54.433612 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m01:46:54.434270 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event" cascade
[0m01:46:54.525384 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:46:54.561449 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m01:46:54.562032 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m01:46:54.562413 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m01:46:54.695705 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:54.699478 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m01:46:54.700516 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m01:46:54.701489 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m01:46:56.051389 [debug] [Thread-3  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:46:56.053071 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:46:56.055140 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m01:46:56.055912 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m01:46:56.187625 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:56.195759 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m01:46:56.199672 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m01:46:56.200522 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m01:46:56.201220 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
alter table "prod"."staging"."stg_appointment_added_event__dbt_tmp" rename to "stg_appointment_added_event"
[0m01:46:56.201899 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m01:46:57.160177 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:46:57.162451 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m01:46:57.163371 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m01:46:57.295118 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:57.306074 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event"
[0m01:46:57.308077 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m01:46:57.308751 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event" cascade
[0m01:46:57.395592 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:46:57.404859 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m01:46:57.406121 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m01:46:57.407206 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m01:46:57.569324 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:57.573835 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m01:46:57.575302 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m01:46:57.576273 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m01:46:58.850874 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:46:58.853382 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m01:46:58.854181 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:46:58.854970 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m01:46:58.988425 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:58.997291 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m01:46:59.001664 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m01:46:59.002285 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m01:46:59.002971 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
alter table "prod"."staging"."stg_appointment_deleted_event__dbt_tmp" rename to "stg_appointment_deleted_event"
[0m01:46:59.262334 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:59.272412 [debug] [Thread-3  ]: Applying DROP to: "prod"."staging"."stg_appointment_edited_event__dbt_backup"
[0m01:46:59.274258 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m01:46:59.274949 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_edited_event"} */
drop table if exists "prod"."staging"."stg_appointment_edited_event__dbt_backup" cascade
[0m01:46:59.536678 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:59.540612 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m01:46:59.541603 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m01:46:59.542304 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: COMMIT
[0m01:46:59.679647 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:59.681078 [debug] [Thread-3  ]: Using redshift connection "model.dbt_remote.stg_appointment_edited_event"
[0m01:46:59.681749 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: BEGIN
[0m01:46:59.812627 [debug] [Thread-3  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:46:59.816824 [debug] [Thread-3  ]: Timing info for model.dbt_remote.stg_appointment_edited_event (execute): 01:46:47.606675 => 01:46:59.816138
[0m01:46:59.818186 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m01:46:59.819073 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: ROLLBACK
[0m01:46:59.820038 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m01:46:59.908574 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:46:59.915690 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m01:46:59.916628 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m01:46:59.917668 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m01:47:00.080434 [debug] [Thread-3  ]: On model.dbt_remote.stg_appointment_edited_event: Close
[0m01:47:00.082310 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:47:00.091403 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dff0a1ae-e577-4fa0-8506-bf163b740cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a7b760>]}
[0m01:47:00.094471 [debug] [Thread-1  ]: Applying DROP to: "prod"."staging"."stg_appointment_added_event__dbt_backup"
[0m01:47:00.097137 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m01:47:00.095530 [info ] [Thread-3  ]: 3 of 4 OK created sql table model staging.stg_appointment_edited_event ......... [[32mSUCCESS[0m in 12.54s]
[0m01:47:00.097970 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_added_event"} */
drop table if exists "prod"."staging"."stg_appointment_added_event__dbt_backup" cascade
[0m01:47:00.098880 [debug] [Thread-3  ]: Finished running node model.dbt_remote.stg_appointment_edited_event
[0m01:47:00.364873 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:47:00.370093 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m01:47:00.371940 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m01:47:00.373250 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: COMMIT
[0m01:47:01.043724 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:47:01.045985 [debug] [Thread-1  ]: Using redshift connection "model.dbt_remote.stg_appointment_added_event"
[0m01:47:01.047306 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: BEGIN
[0m01:47:01.049781 [debug] [Thread-2  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:47:01.178010 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:47:01.178927 [debug] [Thread-1  ]: Timing info for model.dbt_remote.stg_appointment_added_event (execute): 01:46:47.587898 => 01:47:01.178759
[0m01:47:01.179317 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m01:47:01.179661 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: ROLLBACK
[0m01:47:01.179955 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m01:47:01.440470 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:47:01.442763 [debug] [Thread-1  ]: On model.dbt_remote.stg_appointment_added_event: Close
[0m01:47:01.453394 [debug] [Thread-2  ]: Applying DROP to: "prod"."staging"."stg_appointment_deleted_event__dbt_backup"
[0m01:47:01.455630 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m01:47:01.456809 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dff0a1ae-e577-4fa0-8506-bf163b740cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a3d160>]}
[0m01:47:01.457361 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.stg_appointment_deleted_event"} */
drop table if exists "prod"."staging"."stg_appointment_deleted_event__dbt_backup" cascade
[0m01:47:01.458414 [info ] [Thread-1  ]: 1 of 4 OK created sql table model staging.stg_appointment_added_event .......... [[32mSUCCESS[0m in 13.91s]
[0m01:47:01.459320 [debug] [Thread-1  ]: Finished running node model.dbt_remote.stg_appointment_added_event
[0m01:47:01.720538 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:47:01.725510 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m01:47:01.727302 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m01:47:01.728680 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: COMMIT
[0m01:47:01.865400 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:47:01.866939 [debug] [Thread-2  ]: Using redshift connection "model.dbt_remote.stg_appointment_deleted_event"
[0m01:47:01.867587 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: BEGIN
[0m01:47:01.998702 [debug] [Thread-2  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:47:02.003316 [debug] [Thread-2  ]: Timing info for model.dbt_remote.stg_appointment_deleted_event (execute): 01:46:47.575253 => 01:47:02.002747
[0m01:47:02.004299 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: ROLLBACK
[0m01:47:02.265361 [debug] [Thread-2  ]: On model.dbt_remote.stg_appointment_deleted_event: Close
[0m01:47:02.269784 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dff0a1ae-e577-4fa0-8506-bf163b740cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a126a0>]}
[0m01:47:02.271717 [info ] [Thread-2  ]: 2 of 4 OK created sql table model staging.stg_appointment_deleted_event ........ [[32mSUCCESS[0m in 14.72s]
[0m01:47:02.273481 [debug] [Thread-2  ]: Finished running node model.dbt_remote.stg_appointment_deleted_event
[0m01:47:02.274934 [debug] [Thread-4  ]: Began running node model.dbt_remote.fact_apointment_schedule
[0m01:47:02.275933 [info ] [Thread-4  ]: 4 of 4 START sql table model public.fact_apointment_schedule ................... [RUN]
[0m01:47:02.277516 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.dbt_remote.fact_apointment_schedule'
[0m01:47:02.278217 [debug] [Thread-4  ]: Began compiling node model.dbt_remote.fact_apointment_schedule
[0m01:47:02.327740 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m01:47:02.328151 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m01:47:02.328440 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m01:47:02.328850 [debug] [Thread-4  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:47:02.329149 [debug] [Thread-4  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:47:03.447493 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:47:03.449509 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m01:47:03.451363 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'stg_appointment_added_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'stg_appointment_added_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'staging'
        and tablename = 'stg_appointment_added_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'staging'
    
    order by ordinal_position
[0m01:47:03.824842 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:47:03.836428 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_remote.fact_apointment_schedule"
[0m01:47:03.837945 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (compile): 01:47:02.278605 => 01:47:03.837543
[0m01:47:03.838633 [debug] [Thread-4  ]: Began executing node model.dbt_remote.fact_apointment_schedule
[0m01:47:03.846938 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_remote.fact_apointment_schedule"
[0m01:47:03.852595 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m01:47:03.853212 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */

  
    

  create  table
    "prod"."public"."fact_apointment_schedule__dbt_tmp"
    
    diststyle even
    
  as (
    


with added_and_edited as (

    select * from "prod"."staging"."stg_appointment_added_event"
    union all
    select * from "prod"."staging"."stg_appointment_edited_event"
),

find_dublicates as (
select 
    *,
    row_number() over (partition by appointment_id order by ingested_at_timestamp desc) as rnk
from added_and_edited),

cancelled as (
    select appointment_id, true as cancelled_flag
    from "prod"."staging"."stg_appointment_deleted_event"
)

select find_dublicates."appointment_id",
  find_dublicates."first_name",
  find_dublicates."last_name",
  find_dublicates."email",
  find_dublicates."appointment_date",
  find_dublicates."appointment_time_start",
  find_dublicates."appointment_time_end",
  find_dublicates."appointment_type",
  find_dublicates."calendar_name",
  find_dublicates."appointment_created_at",
  find_dublicates."ingested_at_timestamp",
        coalesce(cancelled.cancelled_flag, false) as cancelled_flag,
        datediff(minute,appointment_time_start,appointment_time_end) as appointment_lenght_minutes

 from find_dublicates

left join cancelled
on cancelled.appointment_id = find_dublicates.appointment_id
where rnk = 1
  );
[0m01:47:04.857574 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:47:04.861136 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m01:47:04.862240 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m01:47:04.862957 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m01:47:05.755250 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:47:05.757517 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m01:47:05.758526 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m01:47:05.890709 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:47:05.901039 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule"
[0m01:47:05.903109 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m01:47:05.903798 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule" cascade
[0m01:47:06.164060 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:47:06.165148 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m01:47:06.165584 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m01:47:06.165909 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m01:47:06.901159 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:47:06.903916 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m01:47:06.905229 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m01:47:07.037846 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:47:07.048559 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m01:47:07.049434 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
alter table "prod"."public"."fact_apointment_schedule__dbt_tmp" rename to "fact_apointment_schedule"
[0m01:47:08.078557 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:47:08.087176 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m01:47:08.088267 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m01:47:08.088869 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m01:47:08.869424 [debug] [Thread-4  ]: SQL status: SUCCESS in 1.0 seconds
[0m01:47:08.870945 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m01:47:08.871787 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m01:47:09.135058 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:47:09.146550 [debug] [Thread-4  ]: Applying DROP to: "prod"."public"."fact_apointment_schedule__dbt_backup"
[0m01:47:09.148383 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m01:47:09.149076 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: /* {"app": "dbt", "dbt_version": "1.7.1", "profile_name": "dbt_remote", "target_name": "prod", "node_id": "model.dbt_remote.fact_apointment_schedule"} */
drop table if exists "prod"."public"."fact_apointment_schedule__dbt_backup" cascade
[0m01:47:09.407639 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:47:09.411077 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m01:47:09.412055 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m01:47:09.412787 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: COMMIT
[0m01:47:09.549671 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:47:09.551505 [debug] [Thread-4  ]: Using redshift connection "model.dbt_remote.fact_apointment_schedule"
[0m01:47:09.552507 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: BEGIN
[0m01:47:09.684605 [debug] [Thread-4  ]: SQL status: SUCCESS in 0.0 seconds
[0m01:47:09.689087 [debug] [Thread-4  ]: Timing info for model.dbt_remote.fact_apointment_schedule (execute): 01:47:03.839015 => 01:47:09.688354
[0m01:47:09.690171 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: ROLLBACK
[0m01:47:09.950729 [debug] [Thread-4  ]: On model.dbt_remote.fact_apointment_schedule: Close
[0m01:47:09.954889 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dff0a1ae-e577-4fa0-8506-bf163b740cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10995fa60>]}
[0m01:47:09.956648 [info ] [Thread-4  ]: 4 of 4 OK created sql table model public.fact_apointment_schedule .............. [[32mSUCCESS[0m in 7.68s]
[0m01:47:09.958070 [debug] [Thread-4  ]: Finished running node model.dbt_remote.fact_apointment_schedule
[0m01:47:09.961258 [debug] [MainThread]: Using redshift connection "master"
[0m01:47:09.961885 [debug] [MainThread]: On master: BEGIN
[0m01:47:09.962381 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:47:09.963134 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m01:47:09.963679 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m01:47:11.060326 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m01:47:11.062557 [debug] [MainThread]: On master: COMMIT
[0m01:47:11.064260 [debug] [MainThread]: Using redshift connection "master"
[0m01:47:11.064985 [debug] [MainThread]: On master: COMMIT
[0m01:47:11.322696 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m01:47:11.323463 [debug] [MainThread]: On master: Close
[0m01:47:11.324881 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:47:11.325402 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_added_event' was properly closed.
[0m01:47:11.325882 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_deleted_event' was properly closed.
[0m01:47:11.326343 [debug] [MainThread]: Connection 'model.dbt_remote.stg_appointment_edited_event' was properly closed.
[0m01:47:11.326814 [debug] [MainThread]: Connection 'model.dbt_remote.fact_apointment_schedule' was properly closed.
[0m01:47:11.327408 [info ] [MainThread]: 
[0m01:47:11.328126 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 29.41 seconds (29.41s).
[0m01:47:11.329989 [debug] [MainThread]: Command end result
[0m01:47:11.347235 [info ] [MainThread]: 
[0m01:47:11.347809 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:47:11.348314 [info ] [MainThread]: 
[0m01:47:11.348740 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m01:47:11.350841 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 29.796732, "process_user_time": 2.527216, "process_kernel_time": 0.29444, "process_mem_max_rss": "126353408", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:47:11.351528 [debug] [MainThread]: Command `dbt run` succeeded at 01:47:11.351368 after 29.80 seconds
[0m01:47:11.351979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065d9c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f890a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f8cc10>]}
[0m01:47:11.352444 [debug] [MainThread]: Flushing usage events
